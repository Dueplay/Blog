[{"content":"catch2用法 定义测试案例 测试案例在 Catch2 中通过 TEST_CASE 宏定义。TEST_CASE 宏接受两个参数：测试案例的名称和一个可选的标签。\n#define CATCH_CONFIG_MAIN // 这行让 Catch 自己提供一个 main() 函数 #include \u0026lt;catch2/catch.hpp\u0026gt; TEST_CASE(\u0026#34;A test case\u0026#34;, \u0026#34;[tag]\u0026#34;) { REQUIRE(1 == 1); } 如果你有多个测试文件，只需要在一个文件中定义 CATCH_CONFIG_MAIN。\n断言 Catch2 提供了多种断言宏，最常用的是 REQUIRE 和 CHECK：\nREQUIRE：如果断言失败，当前的测试案例会立即停止。 CHECK：即使断言失败，当前的测试案例也会继续运行，允许多个断言失败。 TEST_CASE(\u0026#34;Testing addition\u0026#34;) { REQUIRE(1 + 1 == 2); CHECK(2 + 2 == 4); } 测试固件 测试固件允许你在每个测试案例之前和之后运行一些代码。测试固件允许你设置和清理测试环境，这对于需要在多个测试案例中重用相同的初始化和清理逻辑非常有用。测试固件通过定义一个结构体或类来实现，你可以在其中定义构造函数（用于设置）和析构函数（用于清理）。然后，使用 TEST_CASE_METHOD 宏来指定哪个固件类应该被用于哪个测试案例。\nstruct DatabaseFixture { Database db; DatabaseFixture() : db(\u0026#34;my_database\u0026#34;) { // 初始化代码，比如打开数据库连接 db.connect(); } ~DatabaseFixture() { // 清理代码，比如关闭数据库连接 db.disconnect(); } }; // 一旦定义了测试固件，就可以在 TEST_CASE_METHOD 宏中使用它 TEST_CASE_METHOD(DatabaseFixture, \u0026#34;Test database connection\u0026#34;, \u0026#34;[database]\u0026#34;) { REQUIRE(db.isConnected() == true); } TEST_CASE_METHOD(DatabaseFixture, \u0026#34;Test database query\u0026#34;, \u0026#34;[database]\u0026#34;) { REQUIRE(db.query(\u0026#34;SELECT * FROM users\u0026#34;).size() \u0026gt; 0); } 在上述代码中，每个 TEST_CASE_METHOD 调用都会创建 DatabaseFixture 的一个新实例，这意味着每个测试案例都会开始于一个已连接的数据库状态。测试完成后，析构函数会被调用以断开连接，保证了每个测试都是独立的。\n分节 Catch2 允许你在单个测试案例中定义分节（Section），这些分节可以共享设置代码，但是每个分节会独立运行。\n这意味着在进入每个 SECTION 前，TEST_CASE 中定义的代码会被执行，为每个 SECTION 提供了一个共同的起点或环境。\n#define CATCH_CONFIG_MAIN #include \u0026lt;catch2/catch.hpp\u0026gt; TEST_CASE(\u0026#34;Testing with shared setup code\u0026#34;, \u0026#34;[example]\u0026#34;) { // 这里是共享的设置代码 int value = 42; SECTION(\u0026#34;Test part 1\u0026#34;) { // 第一个测试部分可以使用共享的设置代码 REQUIRE(value == 42); } SECTION(\u0026#34;Test part 2\u0026#34;) { // 第二个测试部分也可以使用相同的设置代码 value += 58; REQUIRE(value == 100); } } 变量 value 的初始化就是所谓的“设置代码”，它在两个不同的测试节中被共享。每个 SECTION 都独立执行，这意味着每个 SECTION 都会从 TEST_CASE 的开始处执行，包括共享的设置代码。因此，即便是在不同的测试节中，value 也总是从初始值 42 开始。\n参数化测试 Catch2 支持参数化测试，使得你可以用不同的输入重复运行同一测试案例。GENERATE 宏能够为测试案例生成一系列的值。在每次测试迭代中，GENERATE 会提供一个值，然后测试案例会使用这个值执行。这意味着相同的测试逻辑会被重复执行，但每次都使用不同的输入值。\n#define CATCH_CONFIG_MAIN #include \u0026lt;catch2/catch.hpp\u0026gt; TEST_CASE(\u0026#34;Parameterized tests with GENERATE\u0026#34;, \u0026#34;[example]\u0026#34;) { // 使用 GENERATE 宏生成一系列测试数据 int input = GENERATE(1, 2, 3, 4, 5); // 使用生成的数据执行测试逻辑 REQUIRE(input \u0026lt; 6); } 在这个例子中，GENERATE(1, 2, 3, 4, 5) 会依次为变量 input 生成 1 到 5 的值。对于每个生成的值，REQUIRE(input \u0026lt; 6) 断言都会被执行一次。因此，这个测试案例会被执行五次，每次使用不同的 input 值。\n集成catch2到cmake v2.xx的版本只需要catch2.hpp这个头文件就行了\nv3.xx的版本的用法：链接到Catch2::Catch2WithMain\ncmake_minimum_required(VERSION 3.14) # 确保使用的是 FetchContent 可用的 CMake 版本 project(MyProject VERSION 1.0) include_directories(${PROJECT_SOURCE_DIR}/include) # 包含 FetchContent 模块 include(FetchContent) # 使用 FetchContent_Declare 声明 Catch2 作为外部依赖项 FetchContent_Declare( Catch2 GIT_REPOSITORY https://github.com/catchorg/Catch2.git GIT_TAG v3.3.0 # or a later release ) # 使 Catch2 可用 FetchContent_MakeAvailable(Catch2) # 添加你的项目文件（示例） add_executable(my_project src/main.cpp src/sub.cpp) # 如果你有测试代码，可以像这样设置 enable_testing() # 启用测试 # 添加测试可执行文件 add_executable( my_test test/test1.cpp test/test2.cpp # 添加其他测试文件 ) # 链接 Catch2 到测试可执行文件 target_link_libraries(my_test PRIVATE Catch2::Catch2WithMain) # 为 Catch2 配置测试发现 LIST(APPEND CMAKE_MODULE_PATH ${catch2_SOURCE_DIR}/extras) include(CTest) include(Catch) CATCH_DISCOVER_TESTS(my_test) ","permalink":"http://localhost:1313/posts/catch2/","summary":"catch2用法 定义测试案例 测试案例在 Catch2 中通过 TEST_CASE 宏定义。TEST_CASE 宏接受两个参数：测试案例的名称和一个可选的标签。\n#define CATCH_CONFIG_MAIN // 这行让 Catch 自己提供一个 main() 函数 #include \u0026lt;catch2/catch.hpp\u0026gt; TEST_CASE(\u0026#34;A test case\u0026#34;, \u0026#34;[tag]\u0026#34;) { REQUIRE(1 == 1); } 如果你有多个测试文件，只需要在一个文件中定义 CATCH_CONFIG_MAIN。\n断言 Catch2 提供了多种断言宏，最常用的是 REQUIRE 和 CHECK：\nREQUIRE：如果断言失败，当前的测试案例会立即停止。 CHECK：即使断言失败，当前的测试案例也会继续运行，允许多个断言失败。 TEST_CASE(\u0026#34;Testing addition\u0026#34;) { REQUIRE(1 + 1 == 2); CHECK(2 + 2 == 4); } 测试固件 测试固件允许你在每个测试案例之前和之后运行一些代码。测试固件允许你设置和清理测试环境，这对于需要在多个测试案例中重用相同的初始化和清理逻辑非常有用。测试固件通过定义一个结构体或类来实现，你可以在其中定义构造函数（用于设置）和析构函数（用于清理）。然后，使用 TEST_CASE_METHOD 宏来指定哪个固件类应该被用于哪个测试案例。\nstruct DatabaseFixture { Database db; DatabaseFixture() : db(\u0026#34;my_database\u0026#34;) { // 初始化代码，比如打开数据库连接 db.connect(); } ~DatabaseFixture() { // 清理代码，比如关闭数据库连接 db.","title":"catch2测试框架"},{"content":"文件目录结构 $ tree . ├── add.c ├── div.c ├── head.h ├── main.c ├── mult.c └── sub.c # 指定使用的 cmake 的最低版本，可选，非必须，如果不加可能会有警告 cmake_minimum_required(VERSION 3.0) # 定义工程名称，并可指定工程的版本、工程描述、web主页地址、支持的语言 project(CALC) # 定义工程会生成一个可执行程序，语法add_executable(可执行程序名 源文件名称) add_executable(app add.c div.c main.c mult.c sub.c) # 定义变量，语法: set(VAR VALUE [CACHE TYPE DOCSTRING [FORCE]]).[]里是可选的 # eg.将文件名对应字符串存起来。 # 方式1: 各个源文件之间使用空格间隔 # set(SRC_LIST add.c div.c main.c mult.c sub.c) # 方式2: 各个源文件之间使用分号 ; 间隔 set(SRC_LIST add.c;div.c;main.c;mult.c;sub.c) add_executable(app ${SRC_LIST}) # 指定c++标准 # 使用g++时: $ g++ *.cpp -std=c++11 -o app # C++标准对应有一宏叫做DCMAKE_CXX_STANDARD，在CMake中想要指定C++标准有两种方式： # 在cmakelists.txt中通过 set 命令指定 # 增加-std=c++11 set(CMAKE_CXX_STANDARD 11) # 增加-std=c++14 set(CMAKE_CXX_STANDARD 14) # 增加-std=c++17 set(CMAKE_CXX_STANDARD 17) # 在执行 cmake 命令的时候指定出这个宏的值，-D表示定义宏 #增加-std=c++11 cmake CMakeLists.txt文件路径 -DCMAKE_CXX_STANDARD=11 #增加-std=c++14 cmake CMakeLists.txt文件路径 -DCMAKE_CXX_STANDARD=14 #增加-std=c++17 cmake CMakeLists.txt文件路径 -DCMAKE_CXX_STANDARD=17 # 指定输出的路径，在CMake中指定可执行程序输出的路径，也对应一个宏，叫做EXECUTABLE_OUTPUT_PATH，它的值还是通过set命令进行设置 set(HOME /home/gxj/Linux/Sort) set(EXECUTABLE_OUTPUT_PATH ${HOME}/bin) # 第一行：定义一个变量用于存储一个绝对路径 # 第二行：将拼接好的路径值设置给EXECUTABLE_OUTPUT_PATH宏 # 如果这个路径中的子目录不存在，会自动生成，无需自己手动创建 # 使用相对路径时，./表示生成的makefile所在目录 # 搜索文件 # 如果一个项目里边的源文件很多，在编写CMakeLists.txt文件的时候不可能将项目目录的各个文件一一罗列出来，这样太麻烦也不现实。所以，在CMake中为我们提供了搜索文件的命令，可以使用aux_source_directory命令或者file命令。 # 使用aux_source_directory 命令可以查找某个路径下的所有源文件，命令格式为： aux_source_directory(\u0026lt; dir \u0026gt; \u0026lt; variable \u0026gt;) dir：要搜索的目录 variable：将从dir目录下搜索到的源文件列表存储到该变量中 # 搜索 src 目录下的源文件 aux_source_directory(${CMAKE_CURRENT_SOURCE_DIR}/src SRC_LIST) add_executable(app ${SRC_LIST}) # 使用file 命令 (当然，除了搜索以外通过 file 还可以做其他事情) file(GLOB/GLOB_RECURSE 变量名 要搜索的文件路径和文件类型) GLOB: 将指定目录下搜索到的满足条件的所有文件名生成一个列表，并将其存储到变量中。 GLOB_RECURSE：递归搜索指定目录，将搜索到的满足条件的文件名生成一个列表，并将其存储到变量中。 搜索当前目录的src目录下所有的源文件，并存储到变量中 file(GLOB MAIN_SRC ${CMAKE_CURRENT_SOURCE_DIR}/src/*.cpp) file(GLOB MAIN_HEAD ${CMAKE_CURRENT_SOURCE_DIR}/include/*.h) CMAKE_CURRENT_SOURCE_DIR 宏表示当前访问的 CMakeLists.txt 文件所在的路径。 要搜索的文件路径和类型可加双引号，也可不加: file(GLOB MAIN_HEAD \u0026#34;${CMAKE_CURRENT_SOURCE_DIR}/src/*.h\u0026#34;) # 包含头文件 # 在编译项目源文件的时候，很多时候都需要将源文件对应的头文件路径指定出来，这样才能保证在编译过程中编译器能够找到这些头文件，并顺利通过编译。在CMake中设置要包含的目录也很简单，通过include_directories命令 include_directories(headpath) # 指定就是头文件的路径为项目根目录下面的include include_directories(${PROJECT_SOURCE_DIR}/include) PROJECT_SOURCE_DIR宏对应的值就是我们在使用cmake命令时，后面紧跟的目录，一般是工程的根目录。 # 制作动态库或静态库，源代码并不需要将他们编译生成可执行程序，而是生成一些静态库或动态库提供给第三方使用，下面来是在cmake中生成这两类库文件的方法。 # 在cmake中，如果要制作静态库，需要使用的命令如下：静态库名字分为三部分：lib+库名字+.a，此处只需要指定出库的名字就可以了 add_library(库名称 STATIC 源文件1 [源文件2] ...) # eg include_directories(${PROJECT_SOURCE_DIR}/include) file(GLOB SRC_LIST \u0026#34;${CMAKE_CURRENT_SOURCE_DIR}/src/*.cpp\u0026#34;) add_library(calc STATIC ${SRC_LIST}) # 要制作动态库，需要使用的命令如下，动态库名字分为三部分：lib+库名字+.so，此处只需要指定出库的名字就可以了，另外两部分在生成该文件的时候会自动填充。 add_library(库名称 SHARED 源文件1 [源文件2] ...) add_library(calc SHARED ${SRC_LIST}) # 指定库输出的路径 # 方式1 - 适用于动态库 对于生成的库文件来说和可执行程序一样都可以指定输出路径。由于在Linux下生成的动态库默认是有执行权限的，所以可以按照生成可执行程序的方式去指定它生成的目录： # 设置动态库生成路径，其实就是通过set命令给EXECUTABLE_OUTPUT_PATH宏设置了一个路径，这个路径就是可执行文件生成的路径 set(EXECUTABLE_OUTPUT_PATH ${PROJECT_SOURCE_DIR}/lib) add_library(calc SHARED ${SRC_LIST}) # 方式2 - 都适用 由于在Linux下生成的静态库默认不具有可执行权限，所以在指定静态库生成的路径的时候就不能使用EXECUTABLE_OUTPUT_PATH宏了，而应该使用LIBRARY_OUTPUT_PATH，这个宏对应静态库文件和动态库文件都适用。 # 设置动态库/静态库生成路径 set(LIBRARY_OUTPUT_PATH ${PROJECT_SOURCE_DIR}/lib) # 生成动态库 #add_library(calc SHARED ${SRC_LIST}) # 生成静态库 add_library(calc STATIC ${SRC_LIST}) # 包含库文件 # 链接静态库的命令如下：参数1：指定出要链接的静态库的名字，可以是全名 libxxx.a，也可以是掐头（lib）去尾（.a）之后的名字 xxx。参数2-N：要链接的其它静态库的名字 link_libraries(\u0026lt;static lib\u0026gt; [\u0026lt;static lib\u0026gt;...]) 如果该静态库不是系统提供的（自己制作或者使用第三方提供的静态库）可能出现静态库找不到的情况，此时可以将静态库的路径也指定出来： link_directories(\u0026lt;lib path\u0026gt;) # 包含静态库路径 link_directories(${PROJECT_SOURCE_DIR}/lib) # 链接静态库 link_libraries(calc) # 链接动态库，使用 target_link_libraries 命令就可以链接动态库，也可以链接静态库文件。 target_link_libraries( \u0026lt;target\u0026gt; \u0026lt;PRIVATE|PUBLIC|INTERFACE\u0026gt; \u0026lt;item\u0026gt;... [\u0026lt;PRIVATE|PUBLIC|INTERFACE\u0026gt; \u0026lt;item\u0026gt;...]...) target：指定要加载动态库的文件的名字该文件可能是一个源文件,or动态库文件or可执行文件 PRIVATE|PUBLIC|INTERFACE：动态库的访问权限，默认为PUBLIC 如果各个动态库之间没有依赖关系，无需做任何设置，三者没有没有区别，一般无需指定，使用默认的 PUBLIC 即可。 PUBLIC：在public后面的库会被Link到前面的target中，并且里面的符号也会被导出，提供给第三方使用。 PRIVATE：在private后面的库仅被link到前面的target中，并且终结掉，第三方不能感知你调了啥库 INTERFACE：在interface后面引入的库不会被链接到前面的target中，只会导出符号。 动态库的链接和静态库是完全不同的： 静态库会在生成可执行程序的链接阶段被打包到可执行程序中，所以可执行程序启动，静态库就被加载到内存中了。 动态库在生成可执行程序的链接阶段不会被打包到可执行程序中，当可执行程序被启动并且调用了动态库中的函数的时候，动态库才会被加载到内存 因此，在cmake中指定要链接的动态库的时候，应该将命令写到生成了可执行文件之后： # 添加并指定最终生成的可执行程序名 add_executable(app ${SRC_LIST}) # 指定可执行程序要链接的动态库名字 target_link_libraries(app pthread) app: 对应的是最终生成的可执行程序的名字 pthread：这是可执行程序要加载的动态库，这个库是系统提供的线程库，全名为libpthread.so，在指定的时候一般会掐头（lib）去尾（.so）。 # 链接第三方动态库，假设在测试文件main.cpp中既使用了自己制作的动态库libcalc.so又使用了系统提供的线程库，此时CMakeLists.txt文件可以这样写：、 cmake_minimum_required(VERSION 3.0) project(TEST) file(GLOB SRC_LIST ${CMAKE_CURRENT_SOURCE_DIR}/*.cpp) include_directories(${PROJECT_SOURCE_DIR}/include) add_executable(app ${SRC_LIST}) target_link_libraries(app pthread calc) pthread、calc都是可执行程序app要链接的动态库的名字。当可执行程序app生成之后并执行该文件，会提示有如下错误信息： error while loading shared libraries: libcalc.so: cannot open shared object file: No such file or directory 这是因为可执行程序启动之后，去加载calc这个动态库，但是不知道这个动态库被放到了什么位置，所以就加载失败了，在 CMake 中可以在生成可执行程序之前，通过命令指定出要链接的动态库的位置，指定静态库位置使用的也是这个命令： link_directories(path) 修改之后的CMakeLists.txt文件应该是这样的： cmake_minimum_required(VERSION 3.0) project(TEST) file(GLOB SRC_LIST ${CMAKE_CURRENT_SOURCE_DIR}/*.cpp) # 指定源文件或者动态库对应的头文件路径 include_directories(${PROJECT_SOURCE_DIR}/include) # 指定要链接的动态库的路径 link_directories(${PROJECT_SOURCE_DIR}/lib) # 添加并生成一个可执行程序 add_executable(app ${SRC_LIST}) # 指定要链接的动态库 target_link_libraries(app pthread calc) # 日志，在CMake中可以用message显示一条消息 message([STATUS|WARNING|AUTHOR_WARNING|FATAL_ERROR|SEND_ERROR] \u0026#34;message to display\u0026#34; ...) (无) ：重要消息 STATUS ：非重要消息 WARNING：CMake 警告, 会继续执行 AUTHOR_WARNING：CMake 警告 (dev), 会继续执行 SEND_ERROR：CMake 错误, 继续执行，但是会跳过生成的步骤 FATAL_ERROR：CMake 错误, 终止所有处理过程 CMake的命令行工具会在stdout上显示STATUS消息，在stderr上显示其他所有消息。CMake的GUI会在它的log区域显示所有消息。 CMake警告和错误消息的文本显示使用的是一种简单的标记语言。文本没有缩进，超过长度的行会回卷，段落之间以新行做为分隔符。 # 输出一般日志信息 message(STATUS \u0026#34;source path: ${PROJECT_SOURCE_DIR}\u0026#34;) # 输出警告信息 message(WARNING \u0026#34;source path: ${PROJECT_SOURCE_DIR}\u0026#34;) # 输出错误信息 message(FATAL_ERROR \u0026#34;source path: ${PROJECT_SOURCE_DIR}\u0026#34;) # 变量操作 # 追加 -使用set拼接 如果使用set进行字符串拼接，对应的命令格式如下： set(变量名1 ${变量名1} ${变量名2} ...) 将从第二个参数开始往后所有的字符串进行拼接，最后将结果存储到第一个参数中，如果第一个参数中原来有数据会对原数据就行覆盖。 # eg set(TEMP \u0026#34;hello,world\u0026#34;) file(GLOB SRC_1 ${PROJECT_SOURCE_DIR}/src1/*.cpp) file(GLOB SRC_2 ${PROJECT_SOURCE_DIR}/src2/*.cpp) # 追加(拼接),将src1，src2，temp拼接为一个str存到src1中 set(SRC_1 ${SRC_1} ${SRC_2} ${TEMP}) message(STATUS \u0026#34;message: ${SRC_1}\u0026#34;) # 使用list拼接 list(APPEND \u0026lt;list\u0026gt; [\u0026lt;element\u0026gt; ...]) list命令的功能比set要强大，字符串拼接只是它的其中一个功能，所以需要在它第一个参数的位置指定出我们要做的操作，APPEND表示进行数据追加，后边的参数和set就一样了。 # 追加(拼接),APPEND后面同set的参数一致 list(APPEND SRC_1 ${SRC_1} ${SRC_2} ${TEMP}) message(STATUS \u0026#34;message: ${SRC_1}\u0026#34;) 使用set命令可以创建一个list。一个在list内部是一个由分号;分割的一组字符串。例如，set(var a b c d e)命令将会创建一个list:a;b;c;d;e，但是最终打印变量值的时候得到的是abcde。 set(tmp1 a;b;c;d;e) set(tmp2 a b c d e) message(${tmp1}) message(${tmp2}) 输出的结果: abcde abcde # 字符串移除 在当前这么目录有五个源文件，其中main.cpp是一个测试文件。如果我们想要把计算器相关的源文件生成一个动态库给别人使用，那么只需要add.cpp、div.cp、mult.cpp、sub.cpp这四个源文件就可以了。此时，就需要将main.cpp从搜索到的数据中剔除出去，想要实现这个功能，也可以使用list list(REMOVE_ITEM \u0026lt;list\u0026gt; \u0026lt;value\u0026gt; [\u0026lt;value\u0026gt; ...]) 通过上面的命令原型可以看到删除和追加数据类似，只不过是第一个参数变成了REMOVE_ITEM。 cmake_minimum_required(VERSION 3.0) project(TEST) set(TEMP \u0026#34;hello,world\u0026#34;) file(GLOB SRC_1 ${PROJECT_SOURCE_DIR}/*.cpp) # 移除前日志 message(STATUS \u0026#34;message: ${SRC_1}\u0026#34;) # 移除 main.cpp list(REMOVE_ITEM SRC_1 ${PROJECT_SOURCE_DIR}/main.cpp) # 移除后日志 message(STATUS \u0026#34;message: ${SRC_1}\u0026#34;) 可以看到，在第8行把将要移除的文件的名字指定给list就可以了。但是一定要注意通过 file 命令搜索源文件的时候得到的是文件的绝对路径（在list中每个文件对应的路径都是一个item，并且都是绝对路径），那么在移除的时候也要将该文件的绝对路径指定出来才可以，否是移除操作不会成功。 关于list命令还有其它功能，但是并不常用，在此就不一一进行举例介绍了。 获取 list 的长度。 list(LENGTH \u0026lt;list\u0026gt; \u0026lt;output variable\u0026gt;) LENGTH：子命令LENGTH用于读取列表长度 \u0026lt;list\u0026gt;：当前操作的列表 \u0026lt;output variable\u0026gt;：新创建的变量，用于存储列表的长度。 读取列表中指定索引的的元素，可以指定多个索引 list(GET \u0026lt;list\u0026gt; \u0026lt;element index\u0026gt; [\u0026lt;element index\u0026gt; ...] \u0026lt;output variable\u0026gt;) \u0026lt;list\u0026gt;：当前操作的列表 \u0026lt;element index\u0026gt;：列表元素的索引 从0开始编号，索引0的元素为列表中的第一个元素； 索引也可以是负数，-1表示列表的最后一个元素，-2表示列表倒数第二个元素，以此类推 当索引（不管是正还是负）超过列表的长度，运行会报错 \u0026lt;output variable\u0026gt;：新创建的变量，存储指定索引元素的返回结果，也是一个列表。 将列表中的元素用连接符（字符串）连接起来组成一个字符串 list (JOIN \u0026lt;list\u0026gt; \u0026lt;glue\u0026gt; \u0026lt;output variable\u0026gt;) \u0026lt;list\u0026gt;：当前操作的列表 \u0026lt;glue\u0026gt;：指定的连接符（字符串） \u0026lt;output variable\u0026gt;：新创建的变量，存储返回的字符串 查找列表是否存在指定的元素，若果未找到，返回-1 list(FIND \u0026lt;list\u0026gt; \u0026lt;value\u0026gt; \u0026lt;output variable\u0026gt;) \u0026lt;list\u0026gt;：当前操作的列表 \u0026lt;value\u0026gt;：需要再列表中搜索的元素 \u0026lt;output variable\u0026gt;：新创建的变量 如果列表\u0026lt;list\u0026gt;中存在\u0026lt;value\u0026gt;，那么返回\u0026lt;value\u0026gt;在列表中的索引 如果未找到则返回-1。 将元素追加到列表中 list (APPEND \u0026lt;list\u0026gt; [\u0026lt;element\u0026gt; ...]) 在list中指定的位置插入若干元素 list(INSERT \u0026lt;list\u0026gt; \u0026lt;element_index\u0026gt; \u0026lt;element\u0026gt; [\u0026lt;element\u0026gt; ...]) 将元素插入到列表的0索引位置 list (PREPEND \u0026lt;list\u0026gt; [\u0026lt;element\u0026gt; ...]) 将列表中最后元素移除 list (POP_BACK \u0026lt;list\u0026gt; [\u0026lt;out-var\u0026gt;...]) 将列表中第一个元素移除 list (POP_FRONT \u0026lt;list\u0026gt; [\u0026lt;out-var\u0026gt;...]) 将指定的元素从列表中移除 list (REMOVE_ITEM \u0026lt;list\u0026gt; \u0026lt;value\u0026gt; [\u0026lt;value\u0026gt; ...]) 将指定索引的元素从列表中移除 list (REMOVE_AT \u0026lt;list\u0026gt; \u0026lt;index\u0026gt; [\u0026lt;index\u0026gt; ...]) 移除列表中的重复元素 list (REMOVE_DUPLICATES \u0026lt;list\u0026gt;) 列表翻转 list(REVERSE \u0026lt;list\u0026gt;) 列表排序 list (SORT \u0026lt;list\u0026gt; [COMPARE \u0026lt;compare\u0026gt;] [CASE \u0026lt;case\u0026gt;] [ORDER \u0026lt;order\u0026gt;]) COMPARE：指定排序方法。有如下几种值可选： STRING:按照字母顺序进行排序，为默认的排序方法 FILE_BASENAME：如果是一系列路径名，会使用basename进行排序 NATURAL：使用自然数顺序排序 CASE：指明是否大小写敏感。有如下几种值可选： SENSITIVE: 按照大小写敏感的方式进行排序，为默认值 INSENSITIVE：按照大小写不敏感方式进行排序 ORDER：指明排序的顺序。有如下几种值可选： ASCENDING:按照升序排列，为默认值 DESCENDING：按照降序排列 # 宏定义 #ifdef DEBUG printf(\u0026#34;我是一个程序猿, 我不会爬树...\\n\u0026#34;); #endif 为了让测试更灵活，我们可以不在代码中定义所需定义的宏，而是在测试的时候去把它定义出来，其中一种方式就是在gcc/g++命令中去指定 $ gcc test.c -DDEBUG -o app 在gcc/g++命令中通过参数 -D指定出要定义的宏的名字，这样就相当于在代码中定义了一个宏，其名字为DEBUG。 在CMake中我们也可以做类似的事情，对应的命令叫做add_definitions: add_definitions(-D宏名称) # 自定义 DEBUG 宏 add_definitions(-DDEBUG) add_executable(app ./test.c) # cmake预定义宏 宏\t功能 PROJECT_SOURCE_DIR\t使用cmake命令后紧跟的目录，一般是工程的根目录 PROJECT_BINARY_DIR\t执行cmake命令的目录 CMAKE_CURRENT_SOURCE_DIR\t当前处理的CMakeLists.txt所在的路径 CMAKE_CURRENT_BINARY_DIR\ttarget 编译目录 EXECUTABLE_OUTPUT_PATH\t重新定义目标二进制可执行文件的存放位置 LIBRARY_OUTPUT_PATH\t重新定义目标链接库文件的存放位置 PROJECT_NAME\t返回通过PROJECT指令定义的项目名称 CMAKE_BINARY_DIR\t项目实际构建路径，假设在build目录进行的构建，那么得到的就是这个目录的路径 执行cmake # 在CMakeLists.txt所在目录执行 $ cmake . # 在build目录执行 $ cmake .. CMake 3.11 FetchContent模块 FetchContent 是 CMake 3.11 及以上版本中引入的一个功能，它允许你在构建时自动从外部获取依赖项，而不需要手动下载或预先安装它们。\n编写cmake： cmake_minimum_required(VERSION 3.14) # 确保使用了足够新的 CMake 版本 project(MyProject VERSION 1.0) # 包含 FetchContent 模块 include(FetchContent) # 声明 GoogleTest 作为外部依赖项 FetchContent_Declare( googletest GIT_REPOSITORY https://github.com/google/googletest.git GIT_TAG release-1.10.0 # GIT_TAG 参数可以是分支名或标签，不是必须的，但它是推荐的做法，不指定下载默认分支 ) # 使外部依赖项（GoogleTest）可用 FetchContent_MakeAvailable(googletest) # 添加你的项目文件（替换为你的源文件） add_executable(my_project main.cpp) # 定义一个测试目标 enable_testing() # 添加测试可执行文件 add_executable( my_test tests/test1.cpp tests/test2.cpp ) # 链接 GoogleTest 到测试可执行文件 target_link_libraries( my_test gtest_main ) # 包含 GoogleTest 的测试 include(GoogleTest) gtest_discover_tests(my_test) 在这个示例中：\n使用 FetchContent_Declare 声明了 GoogleTest 作为一个外部依赖项，指定了其 Git 仓库地址和要使用的标签（在这个例子中是 release-1.10.0）。 通过 FetchContent_MakeAvailable 自动下载（如果需要的话）、配置和构建 GoogleTest。 创建了两个可执行文件目标：一个是主项目 my_project，另一个是测试项目 my_test。 my_test 测试可执行文件链接了 GoogleTest，并使用 gtest_discover_tests 自动发现和注册 GoogleTest 测试。 第二步：编写测试 在 tests 目录下创建测试文件（例如，test1.cpp 和 test2.cpp），并使用 GoogleTest 编写测试。\n第三步：构建和运行测试 创建一个构建目录并进入：\nmkdir build \u0026amp;\u0026amp; cd build 使用 CMake 配置项目并构建：\ncmake --build . 运行测试：\nctest 使用catch2 v3.x版本的测试cmake cmake_minimum_required(VERSION 3.14) # 确保使用的是 FetchContent 可用的 CMake 版本 project(MyProject VERSION 1.0) include_directories(${PROJECT_SOURCE_DIR}/include) # 包含 FetchContent 模块 include(FetchContent) # 使用 FetchContent_Declare 声明 Catch2 作为外部依赖项 FetchContent_Declare( Catch2 GIT_REPOSITORY https://github.com/catchorg/Catch2.git GIT_TAG v3.3.0 # or a later release ) # 使 Catch2 可用 FetchContent_MakeAvailable(Catch2) # 添加你的项目文件（示例） add_executable(my_project src/main.cpp src/sub.cpp) # 如果你有测试代码，可以像这样设置 enable_testing() # 启用测试 # 添加测试可执行文件 add_executable( my_test test/test1.cpp src/sub.cpp # 添加其他测试文件 ) # 链接 Catch2 到测试可执行文件 target_link_libraries(my_test PRIVATE Catch2::Catch2WithMain) # 为 Catch2 配置测试发现 LIST(APPEND CMAKE_MODULE_PATH ${catch2_SOURCE_DIR}/extras) include(CTest) include(Catch) CATCH_DISCOVER_TESTS(my_test) ","permalink":"http://localhost:1313/posts/cmake/","summary":"文件目录结构 $ tree . ├── add.c ├── div.c ├── head.h ├── main.c ├── mult.c └── sub.c # 指定使用的 cmake 的最低版本，可选，非必须，如果不加可能会有警告 cmake_minimum_required(VERSION 3.0) # 定义工程名称，并可指定工程的版本、工程描述、web主页地址、支持的语言 project(CALC) # 定义工程会生成一个可执行程序，语法add_executable(可执行程序名 源文件名称) add_executable(app add.c div.c main.c mult.c sub.c) # 定义变量，语法: set(VAR VALUE [CACHE TYPE DOCSTRING [FORCE]]).[]里是可选的 # eg.将文件名对应字符串存起来。 # 方式1: 各个源文件之间使用空格间隔 # set(SRC_LIST add.c div.c main.c mult.c sub.c) # 方式2: 各个源文件之间使用分号 ; 间隔 set(SRC_LIST add.c;div.c;main.c;mult.c;sub.c) add_executable(app ${SRC_LIST}) # 指定c++标准 # 使用g++时: $ g++ *.cpp -std=c++11 -o app # C++标准对应有一宏叫做DCMAKE_CXX_STANDARD，在CMake中想要指定C++标准有两种方式： # 在cmakelists.","title":"cmake Tutorial"},{"content":"为什么使用Protocol Buffer? 想象一下我们需要序列化/反序列化一个数据结构，有几种可行的方法：\n将原始内存数据结构保存为二进制形式。 但这是一种脆弱的方法，因为它要求读取端必须遵守完全相同的内存布局，并禁止数据格式的扩展。 编写我们自己的编码策略，例如以冒号为分隔的字符串“12:3:-23:67”，这需要我们编写编码和解析代码，这也带来了运行时开销。 将数据序列化为 XML 形式。 这是广泛使用的人类可读格式。 然而，XML 由于冗长而需要大量的存储空间。 Protocol Buffer ：灵活、高效、自动化的解决方案 定义Message syntax = \u0026#34;proto3\u0026#34;; // 版本 // 相当于c++中的namespace package tutorial; // 相当于c++中的class/struct message Person { // optional 修饰符表明该字段可能被设置，也可能不被设置。当从未设置的字段中检索值时，return系统默认值，整数为0，字符串为空等。 optional string name = 1; optional int32 id = 2; optional string email =3; // 对于枚举类型，默认值是枚举类型中定义的第一个值 enum PhoneType { MOBILE = 0; HOME = 1; WORK = 2; } message PhoneNumber { optional string number = 1; optional PhoneType type = 2; } // repeated 修饰符相当于数组 repeated PhoneNumber phones = 4; } message AddressBook { repeated Person people = 1; } protobuf buffer message格式定义非常接近 C/C++ 中的类/结构定义。 有相当多的原始数据类型可用，例如int32、string，并且我们可以嵌套自定义数据类型，例如嵌套在PhoneNumber中的PhoneType，以及嵌套在AddressBook中的Person。\n编译Message 安装protocol buffer.在Ubuntu 22.04 LTS,通过下面方式安装\n$ sudo apt install -y protobuf-compiler 检查它的版本是否是最新的\n$ protoc --version libprotoc 3.12.4 现在我们可以将 protobuf message 格式编译成 cpp 文件。 让编译器为我们生成代码。\n$ ls addressbook.proto $ protoc --experimental_allow_proto3_optional --cpp_out=. addressbook.proto // 编译到当前目录 $ ls addressbook.pb.cc addressbook.pb.h addressbook.proto 编译器为我们生成了addressbook.ph.h和addressbook.ph.cc。 代码里包含很多我们上面刚刚定义的消息格式的 getter 和 setter 函数。\n常用的message方法 在所有版本的 protobuf 中都有一些常用的方法。\nbool IsInitialized() const: checks if all the required fields have been set. string DebugString() const: returns a human-readable representation of the message, particularly useful for debugging. void CopyFrom(const Person\u0026amp; from): overwrites the message with the given message’s values. void Clear(): clears all the elements back to the empty state. bool SerializeToString(string* output) const: serializes the message and stores the bytes in the given string. Note that the bytes are binary, not text; we only use the string class as a convenient container. bool ParseFromString(const string\u0026amp; data): parses a message from the given string. bool SerializeToOstream(ostream* output) const: writes the message to the given C++ ostream. bool ParseFromIstream(istream* input): parses a message from the given C++ istream. 例子 一个简单的程序，将新的地址信息附加到数据文件中。\n#include \u0026lt;iostream\u0026gt; #include \u0026lt;fstream\u0026gt; #include \u0026lt;string\u0026gt; #include \u0026#34;addressbook.pb.h\u0026#34; void PromptForAddress(tutorial::Person *person) { std::cout \u0026lt;\u0026lt; \u0026#34;Enter person ID number: \u0026#34;; int id; std::cin \u0026gt;\u0026gt; id; person-\u0026gt;set_id(id); std::cin.ignore(256, \u0026#39;\\n\u0026#39;); std::cout \u0026lt;\u0026lt; \u0026#34;Enter name: \u0026#34;; getline(std::cin, *person-\u0026gt;mutable_name()); std::cout \u0026lt;\u0026lt; \u0026#34;Enter email address (blank for none): \u0026#34;; std::string email; getline(std::cin, email); if (!email.empty()) { person-\u0026gt;set_email(email); } while(true) { std::cout \u0026lt;\u0026lt; \u0026#34;Enter a phone number (or leave blank to finish): \u0026#34;; std::string number; getline(std::cin, number); if (number.empty()) { break; } tutorial::Person::PhoneNumber *phone_number = person-\u0026gt;add_phones(); phone_number-\u0026gt;set_number(number); std::cout \u0026lt;\u0026lt; \u0026#34;Is this a mobile, home, or work phone? \u0026#34;; std::string type; getline(std::cin, type); if (type == \u0026#34;mobile\u0026#34;) { phone_number-\u0026gt;set_type(tutorial::Person::MOBILE); } else if (type == \u0026#34;home\u0026#34;) { phone_number-\u0026gt;set_type(tutorial::Person::HOME); } else if (type == \u0026#34;work\u0026#34;) { phone_number-\u0026gt;set_type(tutorial::Person::WORK); } else { std::cout \u0026lt;\u0026lt; \u0026#34;Unknown phone type. Using default.\u0026#34; \u0026lt;\u0026lt; std::endl; } } } // 从文件中读取整个地址簿，根据用户输入添加一个人，然后将其写回到同一文件中。 int main(int argc, char* argv[]) { // 验证我们链接的库的版本是否与我们编译的header的版本兼容。 GOOGLE_PROTOBUF_VERIFY_VERSION; if (argc != 2) { std::cerr \u0026lt;\u0026lt; \u0026#34;Usage : \u0026#34; \u0026lt;\u0026lt; argv[0] \u0026lt;\u0026lt; \u0026#34; ADDRESSBOOK_FILE\u0026#34; \u0026lt;\u0026lt; std::endl; return -1; } tutorial::AddressBook address_book; std::fstream ifs(argv[1], std::ios::in | std::ios::binary); if (!ifs) { std::cout \u0026lt;\u0026lt; argv[1] \u0026lt;\u0026lt; \u0026#34;: File not found. Creating a new file.\u0026#34; \u0026lt;\u0026lt; std::endl; } else if (!address_book.ParseFromIstream(\u0026amp;ifs)) { std::cerr \u0026lt;\u0026lt; \u0026#34;Failed to parse address book.\u0026#34; \u0026lt;\u0026lt; std::endl; return -1; } // Add an address. PromptForAddress(address_book.add_people()); // Write the new address book back to disk. std::fstream ofs(argv[1], std::ios::out | std::ios::binary | std::ios::trunc); if (!address_book.SerializeToOstream(\u0026amp;ofs)) { std::cerr \u0026lt;\u0026lt; \u0026#34;Failed to serialize address book.\u0026#34; \u0026lt;\u0026lt; std::endl; return -1; } // 可选: 删除 libprotobuf 分配的所有全局对象。 google::protobuf::ShutdownProtobufLibrary(); return 0; } 读二进制文件中的消息\n读上面写的数据文件并展示里面包含的所有信息.\n#include \u0026lt;iostream\u0026gt; #include \u0026lt;fstream\u0026gt; #include \u0026lt;string\u0026gt; #include \u0026#34;addressbook.pb.h\u0026#34; void ListPeople(tutorial::AddressBook\u0026amp; address_book) { for (int i = 0; i \u0026lt; address_book.people_size(); i++) { const tutorial::Person\u0026amp; person = address_book.people(i); std::cout \u0026lt;\u0026lt; \u0026#34;Person ID: \u0026#34; \u0026lt;\u0026lt; person.id() \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; \u0026#34; Name: \u0026#34; \u0026lt;\u0026lt; person.name() \u0026lt;\u0026lt; std::endl; if (person.has_email()) { std::cout \u0026lt;\u0026lt; \u0026#34; email address: \u0026#34; \u0026lt;\u0026lt; person.email() \u0026lt;\u0026lt; std::endl; } for (int j = 0; j \u0026lt; person.phones_size(); j++) { const tutorial::Person::PhoneNumber\u0026amp; phone_number = person.phones(j); switch (phone_number.type()) { case tutorial::Person::MOBILE: std::cout \u0026lt;\u0026lt; \u0026#34; Mobile phone #: \u0026#34;; break; case tutorial::Person::HOME: std::cout \u0026lt;\u0026lt; \u0026#34; Home phone #: \u0026#34;; break; case tutorial::Person::WORK: std::cout \u0026lt;\u0026lt; \u0026#34; Work phone #: \u0026#34;; break; } std::cout \u0026lt;\u0026lt; phone_number.number() \u0026lt;\u0026lt; std::endl; } } } // 从文件中读取整个地址簿并打印其中的所有信息。 int main(int argc, char* argv[]) { // 验证我们链接的库的版本是否与我们编译的header的版本兼容。 GOOGLE_PROTOBUF_VERIFY_VERSION; if (argc != 2) { std::cerr \u0026lt;\u0026lt; \u0026#34;Usage : \u0026#34; \u0026lt;\u0026lt; argv[0] \u0026lt;\u0026lt; \u0026#34; ADDRESSBOOK_FILE\u0026#34; \u0026lt;\u0026lt; std::endl; return -1; } tutorial::AddressBook address_book; std::fstream ifs(argv[1], std::ios::in | std::ios::binary); if (!address_book.ParseFromIstream(\u0026amp;ifs)) { std::cerr \u0026lt;\u0026lt; \u0026#34;Failed to parse address book.\u0026#34; \u0026lt;\u0026lt; std::endl; return -1; } ListPeople(address_book); // 可选: 删除 libprotobuf 分配的所有全局对象。 google::protobuf::ShutdownProtobufLibrary(); return 0; } 编译运行 $ g++ -std=c++14 writer.cpp addressbook.pb.cc -o writer -lpthread -lprotobuf $ g++ -std=c++14 reader.cpp addressbook.pb.cc -o reader -lpthread -lprotobuf ","permalink":"http://localhost:1313/posts/protocol-buffer/","summary":"为什么使用Protocol Buffer? 想象一下我们需要序列化/反序列化一个数据结构，有几种可行的方法：\n将原始内存数据结构保存为二进制形式。 但这是一种脆弱的方法，因为它要求读取端必须遵守完全相同的内存布局，并禁止数据格式的扩展。 编写我们自己的编码策略，例如以冒号为分隔的字符串“12:3:-23:67”，这需要我们编写编码和解析代码，这也带来了运行时开销。 将数据序列化为 XML 形式。 这是广泛使用的人类可读格式。 然而，XML 由于冗长而需要大量的存储空间。 Protocol Buffer ：灵活、高效、自动化的解决方案 定义Message syntax = \u0026#34;proto3\u0026#34;; // 版本 // 相当于c++中的namespace package tutorial; // 相当于c++中的class/struct message Person { // optional 修饰符表明该字段可能被设置，也可能不被设置。当从未设置的字段中检索值时，return系统默认值，整数为0，字符串为空等。 optional string name = 1; optional int32 id = 2; optional string email =3; // 对于枚举类型，默认值是枚举类型中定义的第一个值 enum PhoneType { MOBILE = 0; HOME = 1; WORK = 2; } message PhoneNumber { optional string number = 1; optional PhoneType type = 2; } // repeated 修饰符相当于数组 repeated PhoneNumber phones = 4; } message AddressBook { repeated Person people = 1; } protobuf buffer message格式定义非常接近 C/C++ 中的类/结构定义。 有相当多的原始数据类型可用，例如int32、string，并且我们可以嵌套自定义数据类型，例如嵌套在PhoneNumber中的PhoneType，以及嵌套在AddressBook中的Person。","title":"Protocol Buffer的使用"},{"content":"知识点中转站！\n分布式 Raft：\n论文 翻译 Paxos：\nOpenACID Blog 最终一致性：\nDDIA 线性一致性：\nDDIA PingCAP：Raft与线性一致性 线性一致性与可串行化 CAP 定理：\nCAP定理没有帮助 顺序：\nDDIA 全序广播：\nDDIA 2PC：\nDDIA 3PC：\nDDIA ","permalink":"http://localhost:1313/posts/database-and-distributed-system-tags/","summary":"知识点中转站！\n分布式 Raft：\n论文 翻译 Paxos：\nOpenACID Blog 最终一致性：\nDDIA 线性一致性：\nDDIA PingCAP：Raft与线性一致性 线性一致性与可串行化 CAP 定理：\nCAP定理没有帮助 顺序：\nDDIA 全序广播：\nDDIA 2PC：\nDDIA 3PC：\nDDIA ","title":"Database and Distributed System TAGS"},{"content":"安装 ubuntu系统默认的shell是bash，可以使用echo $SHELL命令来查看当前使用的shell，zsh是bash的一个替代品，它的功能更加强大和丰富，可以使用cat /etc/shells来查看支持的shell\n如果结果中没有zsh的话就需要使用下面的命令来安装一下：\nsudo apt install zsh -y 安装字体 这里安装powerlevel10k主题推荐使用的MesloLGS-Nerd字体。\n一般在初次安装配置主题的时候会默认提示安装，但是如果没有正常安装的话也可以使用下面的内容来手动安装一下： MesloLGS字体ttf文件下载地址：\nwget https://github.com/romkatv/powerlevel10k-media/raw/master/MesloLGS%20NF%20Regular.ttf \u0026amp;\u0026amp; wget https://github.com/romkatv/powerlevel10k-media/raw/master/MesloLGS%20NF%20Bold.ttf \u0026amp;\u0026amp; wget https://github.com/romkatv/powerlevel10k-media/raw/master/MesloLGS%20NF%20Italic.ttf \u0026amp;\u0026amp; wget https://github.com/romkatv/powerlevel10k-media/raw/master/MesloLGS%20NF%20Bold%20Italic.ttf 安装完成之后在系统设置或者各个软件比如终端或者VSCode上把字体设置为MesloLGS NF就可以了。\n# 将下载的字体拷贝至truetype sudo cp ttf/*.ttf /usr/share/fonts/truetype/ # 安装fontconfig sudo apt install fontconfig # 刷新字体缓存 fc-cache -fv 安装Oh-My-Zsh sh -c \u0026#34;$(curl -fsSL https://raw.githubusercontent.com/ohmyzsh/ohmyzsh/master/tools/install.sh)\u0026#34; 慢或者失败的小伙伴可以换成国内源:\nwget https://gitee.com/mirrors/oh-my-zsh/raw/master/tools/install.sh 下载之后给install.sh添加执行权限：\nchmod +x install.sh 然后还需要修改一下安装脚本中的远程仓库地址：\n打开install.sh文件，找到以下部分：\n# Default settings ZSH=${ZSH:-~/.oh-my-zsh} REPO=${REPO:-ohmyzsh/ohmyzsh} REMOTE=${REMOTE:-https://github.com/${REPO}.git} BRANCH=${BRANCH:-master} 将中间两行修改为下面这样，使用gitee镜像：\nREPO=${REPO:-mirrors/ohmyzsh} REMOTE=${REMOTE:-https://gitee.com/${REPO}.git} 然后保存退出，再执行一下，一般就应该安装好了。\n将系统默认shell切换为zsh\n# 切换默认shell chsh -s $(which zsh) # 确认是否切换成功 echo $SHELL 安装Zsh主题和插件 # powerlevel10k主题 git clone https://github.com/romkatv/powerlevel10k.git $ZSH_CUSTOM/themes/powerlevel10k # zsh-autosuggestions自动提示插件 git clone https://github.com/zsh-users/zsh-autosuggestions ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/zsh-autosuggestions # zsh-syntax-highlighting语法高亮插件 git clone https://github.com/zsh-users/zsh-syntax-highlighting.git ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/zsh-syntax-highlighting # 配置powerlevel10k，选择各种样式 p10k configure 在~/.zshrc文件启用插件和主题\n# 修改主题 ZSH_THEME=\u0026#34;powerlevel10k/powerlevel10k\u0026#34; # 启用插件 plugins=( git zsh-autosuggestions zsh-syntax-highlighting ) [参考文档](Linux终端环境配置 | GeekHour)\n","permalink":"http://localhost:1313/posts/zsh/","summary":"安装 ubuntu系统默认的shell是bash，可以使用echo $SHELL命令来查看当前使用的shell，zsh是bash的一个替代品，它的功能更加强大和丰富，可以使用cat /etc/shells来查看支持的shell\n如果结果中没有zsh的话就需要使用下面的命令来安装一下：\nsudo apt install zsh -y 安装字体 这里安装powerlevel10k主题推荐使用的MesloLGS-Nerd字体。\n一般在初次安装配置主题的时候会默认提示安装，但是如果没有正常安装的话也可以使用下面的内容来手动安装一下： MesloLGS字体ttf文件下载地址：\nwget https://github.com/romkatv/powerlevel10k-media/raw/master/MesloLGS%20NF%20Regular.ttf \u0026amp;\u0026amp; wget https://github.com/romkatv/powerlevel10k-media/raw/master/MesloLGS%20NF%20Bold.ttf \u0026amp;\u0026amp; wget https://github.com/romkatv/powerlevel10k-media/raw/master/MesloLGS%20NF%20Italic.ttf \u0026amp;\u0026amp; wget https://github.com/romkatv/powerlevel10k-media/raw/master/MesloLGS%20NF%20Bold%20Italic.ttf 安装完成之后在系统设置或者各个软件比如终端或者VSCode上把字体设置为MesloLGS NF就可以了。\n# 将下载的字体拷贝至truetype sudo cp ttf/*.ttf /usr/share/fonts/truetype/ # 安装fontconfig sudo apt install fontconfig # 刷新字体缓存 fc-cache -fv 安装Oh-My-Zsh sh -c \u0026#34;$(curl -fsSL https://raw.githubusercontent.com/ohmyzsh/ohmyzsh/master/tools/install.sh)\u0026#34; 慢或者失败的小伙伴可以换成国内源:\nwget https://gitee.com/mirrors/oh-my-zsh/raw/master/tools/install.sh 下载之后给install.sh添加执行权限：\nchmod +x install.sh 然后还需要修改一下安装脚本中的远程仓库地址：\n打开install.sh文件，找到以下部分：\n# Default settings ZSH=${ZSH:-~/.oh-my-zsh} REPO=${REPO:-ohmyzsh/ohmyzsh} REMOTE=${REMOTE:-https://github.com/${REPO}.git} BRANCH=${BRANCH:-master} 将中间两行修改为下面这样，使用gitee镜像：\nREPO=${REPO:-mirrors/ohmyzsh} REMOTE=${REMOTE:-https://gitee.com/${REPO}.git} 然后保存退出，再执行一下，一般就应该安装好了。\n将系统默认shell切换为zsh","title":"zsh安装与配置"},{"content":"Introduction 摸了一段时间的鱼，去尝试用 SpringBoot + Vue 搭建一个前后端分离的 Web 应用。都说 CS 的学生不能只会用框架 CRUD，但更不能不会用框架 CRUD。大概做出来一个小 demo 后就没有再继续了。接着来做 6.824。\nLab3 和 Lab2 各有各的难处。Lab2 是 Raft 的核心，需要小心地处理各种 corner case。但好在有 Figure2 的引导，最终也是按照其严格的规定成功实现。Lab3 编码难度不如 Lab2，但没有详细的引导，留给个人自由发挥的空间更大 (更有可能不知道从何下手)。\nLab3 需要在 Raft 层上实现一个 fault-tolerant key-value service，满足强一致性，也就是线性一致性 (Linearizable Consistency)。线性一致性保证整个系统看起来好像只有一个副本，其中所有的操作都是原子性的。简单地说，线性一致性系统的读写操作有以下特征：\n读写并不能瞬间完成，而是在一个时间段内进行。 读在写开始前完成，读到的一定是旧值；读在写完成之后开始，读到的一定是新值。(读写操作无重合部分) 读写并发进行，即有重合部分时，既可能读到新值，也可能读到旧值。 一旦有一个客户端读取到了新值，那么之后的客户端一定也都会读取到新值。 关于线性一致性更加详细的定义和解析，可以阅读《数据密集型应用系统》(DDIA) 相关章节。\n先来看看整个系统的架构：\n整个 KV Service 由多个 Server 组成，每个 Server 包含一个 State Machine，具体在 lab 中是一个 KV 数据库；Server 还包含一个 Raft 节点。需要注意的是，各 Server 之间并不会直接通信，而是靠其 Raft 节点进行通信。\n整个系统的理想运行流程是：\nClient 通过 RPC 向 KV Service 发送请求，例如 Put(x,1) KV Service 将请求转发给当前拥有 Leader Raft 节点的 Server Leader Server 将请求包含的 command 传递给 Raft 层 Raft 层对 command 进行共识，生成相同的 log replica 在达成共识后，Raft 层将 command Apply 回 Server Server 收到 Raft 层的 Apply 后，将 command 应用到状态机，即状态机此时状态为 {x: 1} 成功应用至状态机后，Server 对 Client 的 RPC 进行回复，返回结果和错误码。 当系统能够正常运行时，一切看起来都很清晰美好。但是一旦出现问题，如节点挂掉、RPC丢包、网络分区等等，情况就变得比较复杂了。\nImplement 在 Lab3 中，我们主要需要实现的部分是 Client 、 Server 和 Server KV Database。\nKV Database 在 lab 中，KV 数据库并不是主要内容。因此直接用 Hashmap 模拟即可。键值均为 String。\ntype kvdb struct { m map[string]string } func (db *kvdb) put(key string, value string) { db.m[key] = value } func (db *kvdb) append(key string, value string) { db.m[key] += value } func (db *kvdb) get(key string) (string, Err) { if _, ok := db.m[key]; !ok { return \u0026#34;\u0026#34;, ErrNoKey } return db.m[key], OK } 在这里，我没有在 KV db 中使用单独的锁。因为这些操作在后续代码中都是互斥进行的，无需额外加锁。\nClient Client 也相对简单。Client 可向 Server 发送三种不同的 RPC：Put(key,value)， Append(key,arg)和 Get(key)。Put 和 Append 均为写请求，Get 为读请求。\n一开始，Client 并不知道 Leader Server 是哪台 Server。Client 可向随机一台 Server 发送 RPC 请求。假如请求的 Server 不是当前的 Leader Server，或者由于网络中断、Server Crash 等原因，无法与 Server 取得联系，则无限地尝试更换 Server 重新发送请求，直到请求成功被处理。这里有一个小优化，在得知 Leader Server 后，Client 可以保存 Leader 的 id，避免下次发起请求时又需要随机地选择一台 Server 多次尝试。\ntype Clerk struct { servers []*labrpc.ClientEnd seq int64 // write op index, increasing from 1 id int64 // client uuid leader int } func (ck *Clerk) Get(key string) string { args := GetArgs{ Key: key, ClientId: ck.id, } i := ck.leader defer func() { ck.leader = i }() for { reply := GetReply{} ok := ck.servers[i].Call(\u0026#34;KVServer.Get\u0026#34;, \u0026amp;args, \u0026amp;reply) if !ok || reply.Err == ErrWrongLeader || reply.Err == ErrTimeout { // cannot reach the server, or it\u0026#39;s a wrong leader: retry i = (i + 1) % len(ck.servers) continue } if reply.Err == ErrNoKey { return \u0026#34;\u0026#34; } return reply.Value } } func (ck *Clerk) PutAppend(key string, value string, op string) { args := PutAppendArgs{ Key: key, Value: value, Op: op, Seq: ck.seq, ClientId: ck.id, } i := ck.leader defer func() { ck.seq++ ck.leader = i }() for { reply := PutAppendReply{} ok := ck.servers[i].Call(\u0026#34;KVServer.PutAppend\u0026#34;, \u0026amp;args, \u0026amp;reply) if !ok || reply.Err == ErrWrongLeader || reply.Err == ErrTimeout { // cannot reach the server, or it\u0026#39;s a wrong leader: retry i = (i + 1) % len(ck.servers) continue } // successfully PutAppend return } } 关于 Client 还需要维护的另一些状态，如 id 和 seq，待会儿再讨论。\nServer Server 应该是 Lab3 中最为复杂的部分。我们先讨论一切正常的情况下 Server 的设计。\n读写 RPC Handler 在接收到 Client 的请求后，通过调用 raft.Start() 将请求包含的 command 传递到 Raft 层，达成共识。当然，如果当前 Server 不为 Leader，则向 Client 返回 ErrWrongLeader 错误，Client 在收到回复后重新尝试向另一台 Server 发起请求。Raft 层达成共识后，通过 applyCh 通知 Server 该 command 已达成共识。\n在一开始，可能会这样设计 Server：\n_, _, isLeader := kv.rf.Start(op) // push op to raft layer to reach the agreement if !isLeader { reply.Err = ErrWrongLeader return } \u0026lt;- applyCh // agreed! apply to statemachine kv.apply(op) 对于不出错的单 Client，这样设计似乎没有问题。但如果有多个 Client 并行地向 Server 发起请求时，就显然不能保证从 applyCh 传回的数据恰好是此前提交的 command 了。为了解决这个问题，我们需要在 Server 中对特定的 command 进行等待。如何区分不同的 command？用 command 在 raft log 中的 index 区分即可。Server 需要维护一张 Map，Key 为 index，Value 为 Server 等待此 index 对应 command 的 channel。\ntype Result struct { value string err Err } notifyCh := map[int]chan Result 在 Raft 层，command 一定是按序向 applyCh 传输的。为了能够按序将 command 应用至状态机，Server 应起一后台 goroutine 监听 applyCh，对需要 apply 的 command 进行互斥的处理。同时，这个 goroutine 也负责将 applyCh 传来的信息转发给对应的正在阻塞等待的 RPC Handler：\nfunc (kv *KVServer) notifier() { for !kv.killed() { select { case msg := \u0026lt;-kv.applyCh: op := msg.Command.(Op) result := kv.apply(op)\t// apply to state machine index := msg.CommandIndex ch := kv.getNotifyCh(index)\tch \u0026lt;- result\t// notify the blocked server } } } func (kv *KVServer) getNotifyCh(index int) chan Result { kv.mu.Lock() defer kv.mu.Unlock() if _, ok := kv.notifyCh[index]; !ok { kv.notifyCh[index] = make(chan Result) } return kv.notifyCh[index] } Server 阻塞的代码改写如下：\nindex, _, isLeader := kv.rf.Start(op) if !isLeader { reply.Err = ErrWrongLeader return } ch := kv.getNotifyCh(index) select { case result := \u0026lt;-ch: // agreed! reply to client reply.Value, reply.Err = result.value, result.err case \u0026lt;-time.After(AGREE_TIMEOUT): // too slow response, reply to client and let it retry another server reply.Value, reply.Err = \u0026#34;\u0026#34;, ErrTimeout } go func() { // asynchronously release notifying channel kv.delNotifyCh(index) }() 需要注意的是，如果 Raft 层长时间无法完成共识 (由于网络分区等原因)，不要让 Server 一直阻塞。及时向 Client 返回 Timeout 错误，使其重新选择另一台 Server 重试。\n这样一来，多个 Client 并行发送请求的情况似乎也可以应对了。\n然而我们要实现的系统有一个重要的性质，fault-tolerant。目前为止，fault 还没有出现。\n实际上，Raft 层的各种 fault 我们在 lab2 中已经妥善处理了，因此我们主要需要关注的是 Server 层的 fault。首先不考虑 Server 直接挂掉的情况 (需要在 lab3B 中用 snapshot 解决)，那么剩下的就是 Client 和 Server 之间的 RPC 丢失问题了。\n假如 Client 向 Server 发送请求，因网络问题 Server 无法接收，这种情况 Server 无需应对 (也无力应对)，让 Client 自己慢慢重试就好。比较严重的问题是，Client 发送的请求 Server 成功接收，Server 也将请求中的 command 成功在 Raft 层达成共识并应用至状态机，然而在回复 Client 时出现了问题，RPC 回复丢失。这样就有可能导致一次请求多次重复提交的情况。比如下面一种简单的情况：\nClient 向 Server 发送 Append(x, 1) 的请求 Server 成功接收，Raft 层达成共识，应用至状态机。此时状态机状态 {x: 1} 由于网络原因，Server 向 Client 返回的结果丢失 Client 苦苦等待，也没有收到 Server 返回的结果，于是超时重试。绕了一圈后又回到了这个 Server (此 Server 仍为 Leader) Client 又向 Server 发送 Append(x, 1) 的请求，Server 成功接收，Raft 层达成共识，应用至状态机。此时状态机状态 {x: 11} 这次 Server 成功向 Client 返回了结果。 Client 成功收到了返回的结果，结束请求。然而原本的 Append(x, 1) 请求，造成了 Append(x, 11) 的后果。 出现这种情况的根本原因是，Raft 层允许同样的 command commit 多次 (Raft 层并不知道这是不是相同的 command，只要有 command 来，就尝试共识)，但实际上，同样的 command 只能 apply 一次。这就需要我们在 Server 层对请求进行去重。\n上面只介绍了 Append 请求的情况，Put 请求也类似。虽然在只有一个 Client 时，Put 请求多次执行不会改变结果，但如果有多个 Client，重复的 Put 请求也可能造成互相覆盖的后果。因此也需要进行去重。\n至于 Get 请求，多次重复并不会改变状态机的状态，无需进行去重处理。\n说到 Get 请求，在这里小小地偏一下题：\n按我们目前的实现，Get/Put/Append 请求均需先推至 Raft 层达成共识，记录在 Raft 层的 Log 中。然而 Get 请求并不会改变系统的状态，记录在 Log 中，对崩溃后回放 Log 恢复数据也没有什么帮助。那么实际上是不是不需要将 Get 请求传入 Raft 层进行共识呢？是的。并且这样会使系统效率更高。那么为什么我们要将 Get 请求也传入 Raft 层呢？这么做实际上是为了简化 KV Service 的实现难度。KV Service 要求我们永远不在 minority 中读取数据，因为这样可能会破坏线性一致性。假如我们不将 Get 传入 Raft 层，直接读取 Leader Server 状态机中的数据，试想下面这种情况：\n一共有 5 台 Server。一开始，Server1 为 Leader，Client 发送了一些请求，Raft 成功共识。 此后，Server1、Server2 与 Server3、Server4、Server5 由于网络问题被划分成两个部分。第一部分中，Server1 仍认为自己是 Leader。第二部分中，Server3 成功当选 Leader。 Server3 又接收了一些来自 Client 的请求，且在 Server3、Server4、Server5 间达成了共识。 有两个 Client 希望 Get 同一个 key： Client1 首先联系了 Server1，Server1 认为它自己是 Leader (实际已经 outdated)，便向 Client1 返回了 outdated value。 Client2 首先联系 Server3，Server3 向其返回了 updated value。 这两个 Get 操作间并没有写操作，却读到了不同的数据，违背了线性一致性。 为什么将 Get 传入 Raft 进行共识就可以避免这种错误？依然考虑上述情况：Server1 在接收到 Client1 的 Get 请求后，将其传入 Raft 层试图达成共识。然而 Server1 只能获得 Server2 的响应，无法将 Get 请求同步到大多数节点上，所以迟迟无法达成共识，Server 层也会被长期阻塞。Client1 久久等不到答复，便会更换 Server 重新进行请求，此时就会找到新的 Leader Server3 并成功执行 Get 请求。所以，将 Get 请求一同传入 Raft 层是最简单地避免读取到 minority 数据的方法。\nRaft 论文在 session 8 中提到了 read-only operations 等优化，避免将 Get 写入 Log，同时解决了可能获取 outdated 数据的问题。可以自行参考。\n去重具体的执行方式，就和之前在 Client 中还没有讲到的 id、seq 等变量有关了。\nid 是 Client 的 uuid，用于标识不同的 Client，直接用 skeleton code 中的 nrand() 方法生成即可 (测试时开不了那么多 Client，碰撞概率极低，可以凑合当uuid用)。seq 则是 Client 写操作的最大操作数，从 1 开始递增。每当 Client 完成一次写操作，就将 seq 加 1。\nServer 端则维护一张 map，用于记录不同 Client 成功应用至状态机的最大 seq 数：\nmaxSeq := map[int64]int64 在遇到来自 client x 的 y seq 请求时，如果\nmaxSeq[x] \u0026gt;= y 就表明这是一次重复的请求，需要进行拦截。\n此时又有新的问题出现了，我们应该在哪里拦截重复的请求，在哪里更新 maxSeq？\n我一开始的想法是，直接在 RPC handler 的最开始判断请求是否重复，若是重复请求则直接拦截并返回。并在 RPC handler 返回前更新 maxSeq。然而这种处理方法存在问题。试想如下情况：\nClient 首先向 Leader Server1 发起 Append 请求。Server1 成功完成共识并将请求应用至状态机，也更新了 maxSeq。但在返回时 RPC 结果丢失。 此时，恰好 Server1 由于崩溃或网络隔离等原因，失去 Leader 身份，Server2 当选 Leader。 由于 RPC 结果丢失，Client 长时间得不到响应，便尝试更换 Server 重新发起请求。 Client 向 Server2 发起了同样的 Append 请求。由于 Server2 的 maxSeq 中并没有此 Client 此 Seq 的信息 (上次仅是存储在了 Server1 的 maxSeq)，于是 Server2 再次执行了请求。也导致了一次请求多次应用的后果。 出现这种情况的根本原因是 Server 并不会直接联系，不同 Server 的 maxSeq 无法共享，因此在 Client 切换 Server 提交重复请求时，Server 无法察觉。\n解决方法也比较简单：在 command 达成共识后，将 command 应用至状态机前，对 command 进行去重。并在成功应用 command 后，更新 maxSeq。即 maxSeq 实际上由状态机维护。这样做能成功的原因是，不同的 Server 通过 Raft 层的交流，间接地共享了 maxSeq。所有请求都需要先尝试应用至状态机，而状态机维护的 maxSeq 恰好可以拦截试图应用的重复请求。\nfunc (kv *KVServer) apply(op Op) Result { result := Result{} if op.T == \u0026#34;Get\u0026#34; { result.value, result.err = kv.db.get(op.Key) } else if op.T == \u0026#34;Put\u0026#34; { if kv.maxSeq[op.ClientId] \u0026lt; op.Seq { kv.db.put(op.Key, op.Value) kv.maxSeq[op.ClientId] = op.Seq } result.err = OK } else { if kv.maxSeq[op.ClientId] \u0026lt; op.Seq { kv.db.append(op.Key, op.Value) kv.maxSeq[op.ClientId] = op.Seq } result.err = OK } return result } 到此为止，似乎我们的 KV Service 已经完美无缺了。当时我就是这么认为的，然而它还存在两个逻辑上的小问题 TAT\n我们用来转发 applyCh 信息的 notifier 协程是这样的：\nfunc (kv *KVServer) notifier() { for !kv.killed() { select { case msg := \u0026lt;-kv.applyCh: op := msg.Command.(Op) result := kv.apply(op)\t// apply to state machine index := msg.CommandIndex ch := kv.getNotifyCh(index)\tch \u0026lt;- result\t// notify the blocked server } } } 需要意识到的是，不是所有 Server 都是 Leader 节点，Follower 节点也会通过 applyCh 向 Server 层转递需要 apply 至状态机的数据。此时 Server 层并没有 RPC Handler 在等待 applyCh 的数据。如果我们仍尝试获取对应的 notifyCh 并转发数据，则会造成 notifier 的无限阻塞。改写如下：\nfunc (kv *KVServer) notifier() { for !kv.killed() { select { case msg := \u0026lt;-kv.applyCh: op := msg.Command.(Op) result := kv.apply(op)\t// apply to state machine if _, isLeader := kv.rf.GetState(); !isLeader { continue } index := msg.CommandIndex ch := kv.getNotifyCh(index)\tch \u0026lt;- result\t// notify the blocked server } } } Server 不为 Leader 的情况已经解决。假如 Server 当前是 Leader，有没有可能部分 applyCh 传来的数据也无需转发呢？也有可能，最简单的情况就是新当选的 Leader 的 Log 中还存在已提交未应用的 command。将这个 command 传入 Server 层后，按照上面的写法，也会尝试向并不存在的 RPC Handler 转发数据并造成阻塞。这种情况解决起来也比较简单，不属于当前 term 的 command 无需转发，直接给状态机应用就可以了。\nfunc (kv *KVServer) notifier() { for !kv.killed() { select { case msg := \u0026lt;-kv.applyCh: op := msg.Command.(Op) result := kv.apply(op) if term, isLeader := kv.rf.GetState(); !isLeader || term != msg.CommandTerm { continue } index := msg.CommandIndex ch := kv.getNotifyCh(index) ch \u0026lt;- result } } } 到这里 Lab3A 的要求已经完成了。\nTest \u0026amp; Debug 上面不断改错的经历大致就是我在测试集中不断 fail 并修改的过程。Lab 给出的测试集还是比较详尽的，可以测出各方面的细节。其中有一个测试集比较奇怪：\nTest: ops complete fast enough (3A) 这个测试是需要 command 达成共识并应用至状态机的速度足够快，每次心跳间隔 (100ms) 中至少需要完成 3 次共识。在 Lab2 中，我们已经在每次 Start(command) 时都提起一次复制请求，用不同的 replicator 向各个节点并行地不断尝试复制 Log，而不是完全靠心跳进行复制 (基本每次心跳间隔只能完成一次共识)。按理来说应该能够轻松通过，然而测试结果总是超时。\n我试了试不带 -race 标识的测试，结果很意外，仅仅 3s 左右就通过了测试，而带上 -race 标识足足需要 40s 左右。到这里其实已经基本可以猜到是什么问题了：锁的竞争过于激烈，-race 标识会进行 Data race 的检测， 严重地影响了系统的性能。\n我又在 test 中加入了对 goroutine 数量的监控，发现 goroutine 数量不断增长，高的时候可以达到 300+ goroutine。虽说 goroutine 号称是轻松开启上万个，但这么高的 goroutine 数量显然还是有点问题。\n之后经过排查，发现大量的 goroutine 卡在了 Lab2 Raft 层向 applier 发送 apply 请求的 goroutine 上：\ngo func() { rf.applyCh \u0026lt;- msg }() 这样就比较好解释了，Client 短时间内发起了大量的请求，而 applier 只有一个，大量尝试传递给 applyCh 的 msg 阻塞，导致协程数过大。\n因此需要将 Lab2 中过多的重复 msg 拦截，做法和 replicator 中类似，或者改用 sync.Cond，用 Signal 不阻塞的性质来实现。\nLab3A 部分到这里结束，接下来讲讲 Lab3B。\nSnapshot 前面的工作做好后，加上一个 Snapshot 其实比较简单，在 notifier 中根据 RaftStateSize() 和 MaxStateSize 的大小关系判断一下是否需要进行一次 Snapshot，并且增加一个 commandValid == false 的分支将 Raft 层传递的 Snapshot 应用至状态机就可以了。\n需要注意的是，Snapshot 不仅需要保存 kv database 的信息，还需要保存 maxSeq。因为改变了状态机的状态，就需要状态机相关的 maxSeq 信息来拦截重复请求。在应用 Snapshot 时，状态机状态发生改变，所以也需要将 maxSeq 与 Leader 的 maxSeq 进行同步。\nSummary Lab3 整体坐下来难度比 Lab2 小一些，debug 也很折磨人就是了。其间也遇到了不少概率极低但匪夷所思的小问题，或许 Raft 层还是不太对？不过也不想再去处理了，感觉分布式系统的 debug 更像是一种体力活。\n","permalink":"http://localhost:1313/posts/mit6.824-lab3-kvservice/","summary":"Introduction 摸了一段时间的鱼，去尝试用 SpringBoot + Vue 搭建一个前后端分离的 Web 应用。都说 CS 的学生不能只会用框架 CRUD，但更不能不会用框架 CRUD。大概做出来一个小 demo 后就没有再继续了。接着来做 6.824。\nLab3 和 Lab2 各有各的难处。Lab2 是 Raft 的核心，需要小心地处理各种 corner case。但好在有 Figure2 的引导，最终也是按照其严格的规定成功实现。Lab3 编码难度不如 Lab2，但没有详细的引导，留给个人自由发挥的空间更大 (更有可能不知道从何下手)。\nLab3 需要在 Raft 层上实现一个 fault-tolerant key-value service，满足强一致性，也就是线性一致性 (Linearizable Consistency)。线性一致性保证整个系统看起来好像只有一个副本，其中所有的操作都是原子性的。简单地说，线性一致性系统的读写操作有以下特征：\n读写并不能瞬间完成，而是在一个时间段内进行。 读在写开始前完成，读到的一定是旧值；读在写完成之后开始，读到的一定是新值。(读写操作无重合部分) 读写并发进行，即有重合部分时，既可能读到新值，也可能读到旧值。 一旦有一个客户端读取到了新值，那么之后的客户端一定也都会读取到新值。 关于线性一致性更加详细的定义和解析，可以阅读《数据密集型应用系统》(DDIA) 相关章节。\n先来看看整个系统的架构：\n整个 KV Service 由多个 Server 组成，每个 Server 包含一个 State Machine，具体在 lab 中是一个 KV 数据库；Server 还包含一个 Raft 节点。需要注意的是，各 Server 之间并不会直接通信，而是靠其 Raft 节点进行通信。\n整个系统的理想运行流程是：\nClient 通过 RPC 向 KV Service 发送请求，例如 Put(x,1) KV Service 将请求转发给当前拥有 Leader Raft 节点的 Server Leader Server 将请求包含的 command 传递给 Raft 层 Raft 层对 command 进行共识，生成相同的 log replica 在达成共识后，Raft 层将 command Apply 回 Server Server 收到 Raft 层的 Apply 后，将 command 应用到状态机，即状态机此时状态为 {x: 1} 成功应用至状态机后，Server 对 Client 的 RPC 进行回复，返回结果和错误码。 当系统能够正常运行时，一切看起来都很清晰美好。但是一旦出现问题，如节点挂掉、RPC丢包、网络分区等等，情况就变得比较复杂了。","title":"MIT6.824 Lab3 KVService"},{"content":"趁着暑假有空，把鸽了很久的 MIT6.824 做一下。Lab1 是实现一个 Map-Reduce，因为和 Raft 主线关系不大（因为懒），就略过了。另外，这次尝试实现一个 part 就来记录相关的内容，以免在全部实现后忘记部分细节（以免之后太懒不想写）。因此，不同 part 的代码会变化，请以最终版本的代码为准（但保证每一 part 的代码可以正常通过绝大部分相应的测试）。同时，在写下某一 part 的记录时，我对 Raft 的整体把握也难免有所不足。\nResources Course\u0026rsquo;s Page 课程主页 Students\u0026rsquo; Guide to Raft 一篇引导博客 Debugging by Pretty Printing debug 技巧，强烈推荐阅读和运用 Raft Q\u0026amp;A 关于 Raft 的一些 Q\u0026amp;A Raft Visualization Raft 动画演示 In Search of an Understandable Consensus Algorithm Raft 论文 Lab2A Raft Leader Election Lab2A 实现时间为6.22~6.24。\nLab2A 主要实现 Raft 的选主过程，包括选举出 Leader 和 Leader 通过心跳维持身份。\nDesign 首先是选主过程的状态机模型：\n接下来是 Raft 论文中最为重要的 Figure 2:\nFigure 2 有许多关于日志复制等其他部分的内容，在这里暂时先不考虑（但当然还是推荐先整体熟悉 Raft 所有内容后再开始编码）。关于选举部分的内容已经全部在图中标出。一个一个看：\nState 每个 Raft 节点需要维护的状态：\ncurrentTerm 此节点的任期。 votedFor 在当前任期内，此节点将选票投给了谁。一个任期内，节点只能将选票投给某一个节点。因此当节点任期更新时要将 votedfor 置为 null。 AppendEntries RPC 在领导选举的过程中，AppendEntries RPC 用来实现 Leader 的心跳机制。节点的 AppendEntries RPC 会被 Leader 定期调用。\nArgs\nterm Leader 的任期。 leaderId Client 可能将请求发送至 Follower 节点，得知 leaderId 后 Follower 可将 Client 的请求重定位至 Leader 节点。因为 Raft 的请求信息必须先经过 Leader 节点，再由 Leader 节点流向其他节点进行同步，信息是单向流动的。在选主过程中，leaderId 暂时只有 debug 的作用。 Reply\nterm 此节点的任期。假如 Leader 发现 Follower 的任期高于自己，则会放弃 Leader 身份并更新自己的任期。 success 此节点是否认同 Leader 发送的心跳。 Receiver Implementation\n当 Leader 任期小于当前节点任期时，返回 false。 否则返回 true。 RequestVote RPC RequestVote RPC 会被 Candidate 调用，以此获取选票。\nArgs\nterm Candidate 的任期 candidateId Reply\nterm 此节点的任期。假如 Candidate 发现 Follower 的任期高于自己，则会放弃 Candidate 身份并更新自己的任期。 voteGranted 是否同意 Candidate 当选。 Receiver Implementation\n当 Candidate 任期小于当前节点任期时，返回 false。 如果 votedFor 为 null（即当前任期内此节点还未投票）或者 votedFor为 candidateId（即当前任期内此节点已经向此 Candidate 投过票），则同意投票；否则拒绝投票。 Rules for Servers All Servers\n如果来自其他节点的 RPC 请求中，或发给其他节点的 RPC 的回复中，任期高于自身任期，则更新自身任期，并转变为 Follower。 Followers\n响应来自 Candidate 和 Leader 的 RPC 请求。 如果在 election timeout 到期时，Follower 未收到来自当前 Leader 的 AppendEntries RPC，也没有收到来自 Candidate 的 RequestVote RPC，则转变为 Candidate。 Candidates\n转变 Candidate时，开始一轮选举： currentTerm++ 为自己投票（votedFor = me） 重置 election timer 向其他所有节点并行发送 RequestVote RPC 如果收到了大多数节点的选票（voteCnt \u0026gt; n/2），当选 Leader。 在选举过程中，如果收到了来自新 Leader 的 AppendEntries RPC，停止选举，转变为 Follower。 如果 election timer 超时时，还未当选 Leader，则放弃此轮选举，开启新一轮选举。 Leaders\n刚上任时，向所有节点发送一轮心跳信息 此后，每隔一段固定时间，向所有节点发送一轮心跳信息，重置其他节点的 election timer，以维持自己 Leader 的身份。 至此，选主的流程已经比较清晰，接下来是具体的实现。\nImplementation 需要实现的结构体不再赘述，按照 Figure2 来就行。\n首先实现两个RPC:\nAppendEntries RPC func (rf *Raft) AppendEntries(args *AppendEntriesArgs, reply *AppendEntriesReply) { rf.mu.Lock() defer rf.mu.Unlock() if args.Term \u0026lt; rf.currentTerm { // Reply false if term \u0026lt; currentTerm reply.Success = false reply.Term = rf.currentTerm\treturn } if args.Term \u0026gt; rf.currentTerm { // If RPC request contains term T \u0026gt; currentTerm: // set currentTerm = T, convert to follower rf.currentTerm = args.Term rf.votedFor = -1 rf.state = FOLLOWER } // received AppendEntries RPC from current leader, reset election timer rf.electionTimer.Reset(randomElectionTimeout()) reply.Success = true reply.Term = rf.currentTerm } RequestVote RPC func (rf *Raft) RequestVote(args *RequestVoteArgs, reply *RequestVoteReply) { rf.mu.Lock() defer rf.mu.Unlock() if args.Term \u0026lt; rf.currentTerm { // Reply false if term \u0026lt; currentTerm reply.VoteGranted = false reply.Term = rf.currentTerm return } if args.Term \u0026gt; rf.currentTerm { // If RPC request contains term T \u0026gt; currentTerm: // set currentTerm = T, convert to follower rf.currentTerm = args.Term rf.votedFor = -1 rf.state = FOLLOWER } if rf.votedFor != -1 \u0026amp;\u0026amp; rf.votedFor != args.CandidateId { // If votedFor is null or candidateId, grant vote; otherwise reject reply.VoteGranted = false reply.Term = rf.currentTerm return } // grant vote to candidate, reset election timer rf.electionTimer.Reset(randomElectionTimeout()) rf.votedFor = args.CandidateId reply.VoteGranted = true reply.Term = rf.currentTerm } 可以看到两个 RPC 的实现与 Figure 2 中的规则完全一致。依次实现即可。需要注意的是，处理 RPC 的整个过程中都需要持有锁。另外，在更新节点任期时，一定要同步将votedFor 置为 null。\n实现完两个 RPC 后，再实现较为复杂的 election 和 heartbeat 过程。\nElection 在节点的 election timer 过期后，开始选举。因此，节点需要有一个监控 electon timer 的 go routine，ticker。\nfunc (rf *Raft) ticker() { for !rf.killed() { select { case \u0026lt;-rf.electionTimer.C: rf.mu.Lock() if rf.state == LEADER { rf.mu.Unlock() break } rf.state = CANDIDATE rf.mu.Unlock() go rf.startElection() } } } 选举过程的 go routine 为 startElection。为什么将选举过程也作为一个 go routine，而不是阻塞地调用函数？因为在规则中提到过，如果 election timer 超时时，Candidate 还未当选 Leader，则放弃此轮选举，开启新一轮选举。\n接下来看实际负责选举过程的 go routine， startElection。\nfunc (rf *Raft) startElection() { rf.mu.Lock() rf.currentTerm++ // Increment currentTerm rf.votedFor = rf.me // Vote for self rf.electionTimer.Reset(randomElectionTimeout()) // Reset election timer rf.mu.Unlock() args := RequestVoteArgs{CandidateId: rf.me} rf.mu.RLock() args.Term = rf.currentTerm rf.mu.RUnlock() voteCh := make(chan bool, len(rf.peers)-1) for i := range rf.peers { // Send RequestVote RPCs to all other servers if i == rf.me { // in PARALLEL continue } go func(i int) { reply := RequestVoteReply{} if ok := rf.sendRequestVote(i, \u0026amp;args, \u0026amp;reply); !ok { voteCh \u0026lt;- false return } rf.mu.Lock() if reply.Term \u0026gt; rf.currentTerm { // If RPC response contains term T \u0026gt; currentTerm: // set currentTerm = T, convert to follower rf.currentTerm = reply.Term rf.votedFor = -1 rf.state = FOLLOWER rf.mu.Unlock() return } rf.mu.Unlock() voteCh \u0026lt;- reply.VoteGranted }(i) } voteCnt := 1 voteGrantedCnt := 1 for voteGranted := range voteCh { rf.mu.RLock() state := rf.state rf.mu.RUnlock() if state != CANDIDATE { break } if voteGranted { voteGrantedCnt++ } if voteGrantedCnt \u0026gt; len(rf.peers)/2 { // gain over a half votes, switch to leader rf.mu.Lock() rf.state = LEADER rf.mu.Unlock() go rf.heartbeat() break } voteCnt++ if voteCnt == len(rf.peers) { // election completed without getting enough votes, break break } } } 使用 n-1 个协程向其他节点并行地发送 RequestVote 请求。协程获得 response 后，向 voteCh 发送结果，startElection 协程进行结果统计。统计过程中，若发现失去了 Candidate 身份，则停止统计。若获得票数过半，则成功当选 Leader，启动 heartbeat 协程。若所有成员已投票，且未当选 Leader，则退出统计。\n要注意的是，需要确保所有不再使用的 go routine 能够正常退出，避免占据资源。\n成功当选 Leader 后，开始发送心跳。\nHeartbeat func (rf *Raft) heartbeat() { wakeChPool := make([]chan struct{}, len(rf.peers)) doneChPool := make([]chan struct{}, len(rf.peers)) // allocate each peer with a go routine to send AppendEntries RPCs for i := range rf.peers { if i == rf.me { continue } wakeChPool[i] = make(chan struct{}) doneChPool[i] = make(chan struct{}) go func(i int) { // replicator go routine for { select { case \u0026lt;-wakeChPool[i]: args := AppendEntriesArgs{LeaderId: rf.me} reply := AppendEntriesReply{} rf.mu.RLock() args.Term = rf.currentTerm rf.mu.RUnlock() go func() { if ok := rf.sendAppendEntries(i, \u0026amp;args, \u0026amp;reply); !ok { return } rf.mu.Lock() if reply.Term \u0026gt; rf.currentTerm { rf.currentTerm = reply.Term rf.votedFor = -1 rf.state = FOLLOWER rf.mu.Unlock() return } rf.mu.Unlock() }() case \u0026lt;-doneChPool[i]: return } } }(i) } broadcast := func() { for i := range rf.peers { if i == rf.me { continue } go func(i int) { wakeChPool[i] \u0026lt;- struct{}{} }(i) } } broadcast() rf.heartbeatTimer = time.NewTimer(HEARTBEAT_INTERVAL) for { \u0026lt;-rf.heartbeatTimer.C if rf.killed() || !rf.isLeader() { break } rf.heartbeatTimer.Reset(HEARTBEAT_INTERVAL) broadcast() } // killed or no longer the leader, release go routines for i := range rf.peers { if i == rf.me { continue } go func(i int) { doneChPool[i] \u0026lt;- struct{}{} }(i) } } heartbeat 协程首先为每个节点分配一个 replicator 协程，每个 replicator 协程负责向一个特定的节点发送 AppendEntries RPC。\n这些协程由 wakeChPool[i] 唤醒。实际上也可以用 sync.Cond 条件变量实现，但我不太会用，所以简单地用一组 channel 模拟。\n初始化这些协程后，heartbeat 协程首先进行一个初始的 broadcast，对应 Leader 刚当选时发出的一轮心跳。broadcast 即通过 wakeChPool 唤醒所有 replicator 协程，向所有节点发出一次心跳。\n此后，heartbeat 协程初始化一个 heartbeatTimer，并且在每次 heartbeatTimer 到期时，进行一次 broadcast，通知所有 replicator 协程发送一次心跳。这里需要注意的是，如果节点已经被 kill 或者不再是 Leader，需要中断对 heartbeatTimer 的监听，并且释放所有 replicator 协程。\n至此，选主过程和心跳成功实现。\nDevil in the details Lab2A 难度不算大，然而我还是被一个细节卡住了挺久。\n在 6.824 Raft 实验中，已经给我们提供了 RPC 调用的方法，即\nrf.peers[server].Call(\u0026#34;Raft.RPCName\u0026#34;, args, reply) 其注释提到，\nCall() is guaranteed to return (perhaps after a delay) except if the handler function on the server side does not return. Thus there is no need to implement your own timeouts around Call().\nCall() 是确保一定会返回的，除非在被调用的RPC中阻塞，否则即使模拟的网络中断，Call() 也会正常返回 false。因此不需要再为 Call() 设置一个 Timeout 限制。\n然而，经过测试，Call() 的确会确保返回，但返回的时间可能会非常长（3到4秒，具体数值要阅读 labrpc 源码，我还没有仔细阅读）。因此，在 replicator 协程中，每次发送心跳，我们还要再启动一个协程，将 sendAppendEntries 放在此协程中运行，避免哪怕只有几秒钟的阻塞。因为在这几秒中，Leader 可能又发送了新的 heartbeat，或者 Leader 不再是 Leader。\ngo func(i int) { // replicator go routine for { select { case \u0026lt;-wakeChPool[i]: ... go func() { // launch a new go routine to run sending RPC if ok := rf.sendAppendEntries(i, \u0026amp;args, \u0026amp;reply); !ok { return } }() case \u0026lt;-doneChPool[i]: return } ... } }(i) Summary 个人感觉 Lab2A 难度最大的地方在于合理控制各个 go routine 的生命周期。锁倒是暂时没碰到什么问题，直接一股脑地把可能存在 data race 的地方全部锁上并及时释放就好。整个选主过程的 go routine 生命周期如下：\nLab2A Leader Election 完成。\nLab2B Raft Log Replication Lab2B 开始于 6.28。结束于7.7。\n和 Raft 最核心的部分缠斗了一个多星期，终于敢说完成了一个较为稳定的版本，千次测试无一 fail。这段时间摸摸鱼，陪陪女朋友，玩玩游戏（和朋友们一起玩一款叫 Raft 的海上生存游戏，挺巧），无聊的时候再看看 fail 掉的 log，暑假嘛，开心最重要。\n关于 Lab2B 感触最深的就是 Students\u0026rsquo; Guide to Raft 里的这两段话：\nAt first, you might be tempted to treat Figure 2 as sort of an informal guide; you read it once, and then start coding up an implementation that follows roughly what it says to do. Doing this, you will quickly get up and running with a mostly working Raft implementation. And then the problems start.\nInevitably, the first iteration of your Raft implementation will be buggy. So will the second. And third. And fourth.\n完成第一版可以单次 pass 的代码大概用了5个小时左右，接下来信心满满地进行千次测试。然而随后的大部分时间，我基本都在试图从各种诡异的 log 找出出现概率极低的难以复现的 Bug。\nDesign 首先还是 Figure 2：\nLab2B 中需要完成 Figure 2 中余下的所有内容。顺带一提的是，Figure 2 与其说是一个 Raft 行为的汇总，更像是一个 coding 的 instruction。Figure 2 中很多地方直接给出了代码的具体行为，而不是给出比较抽象和模糊的规则。这样的好处是，coding 更加简单了，严格遵守 Figure 2 即可；但也有一定的坏处，可能实现完所有部分后，学生（特指我）还是对 Raft 的行为，设计和一致性证明等等比较模糊，仅是机械地遵循了 Figure 2 中给出的规则。下面还是一个一个来介绍：\nState log[] 即日志，每条 Entry 包含一条待施加至状态机的命令。Entry 也要记录其被发送至 Leader 时，Leader 当时的任期。Lab2B 中，在内存存储日志即可，不用担心 server 会 down 掉，测试中仅会模拟网络挂掉的情景。 commitIndex 已知的最高的已提交的 Entry 的 index。被提交的定义为，当 Leader 成功在大部分 server 上复制了一条 Entry，那么这条 Entry 就是一条已提交的 Entry。 lastApplied 最高的已应用的 Entry 的 index。已提交和已应用是不同的概念，已应用指这条 Entry 已经被运用到状态机上。已提交先于已应用。同时需要注意的是，Raft 保证了已提交的 Entry 一定会被应用（通过对选举过程增加一些限制，下面会提到）。 commitIndex 和 lastApplied 分别维护 log 已提交和已应用的状态，当节点发现 commitIndex \u0026gt; lastApplied 时，代表着 commitIndex 和 lastApplied 间的 entries 处于已提交，未应用的状态。因此应将其间的 entries 按序应用至状态机。\n对于 Follower，commitIndex 通过 Leader AppendEntries RPC 的参数 leaderCommit 更新。对于 Leader，commitIndex 通过其维护的 matchIndex 数组更新。\nnextIndex[] 由 Leader 维护，nextIndex[i] 代表需要同步给 peer[i] 的下一个 entry 的 index。在 Leader 当选后，重新初始化为 Leader 的 last log index + 1。 matchIndex[] 由 Leader 维护，matchIndex[i] 代表 Leader 已知的已在 peer[i] 上成功复制的最高 entry index。在 Leader 当选后，重新初始化为 0。 不能简单地认为 matchIndex = nextIndex - 1。\nnextIndex 是对追加位置的一种猜测，是乐观的估计。因此，当 Leader 上任时，会将 nextIndex 全部初始化为 last log index + 1，即乐观地估计所有 Follower 的 log 已经与自身相同。AppendEntries PRC 中，Leader 会根据 nextIndex 来决定向 Follower 发送哪些 entry。当返回失败时，则会将 nextIndex 减一，猜测仅有一条 entry 不一致，再次乐观地尝试。实际上，使用 nextIndex 是为了提升性能，仅向 Follower 发送不一致的 entry，减小 RPC 传输量。\nmatchIndex 则是对同步情况的保守确认，为了保证安全性。matchIndex 及此前的 entry 一定都成功地同步。matchIndex 的作用是帮助 Leader 更新自身的 commitIndex。当 Leader 发现一个 N 值，N 大于过半数的 matchIndex，则可将其 commitIndex 更新为 N（需要注意任期号的问题，后文会提到）。matchIndex 在 Leader 上任时被初始化为 0。\nnextIndex 是最乐观的估计，被初始化为最大可能值；matchIndex 是最悲观的估计，被初始化为最小可能值。在一次次心跳中，nextIndex 不断减小，matchIndex 不断增大，直至 matchIndex = nextIndex - 1，则代表该 Follower 已经与 Leader 成功同步。\nAppendEntries RPC Args\nprevLogIndex 添加 Entries 的前一条 Entry 的 index。 prevLogTerm prevLogIndex 对应 entry 的 term。 entries[] 需要同步的 entries。若为空，则代表是一次 heartbeat。需要注意的是，不需要特别判断是否为 heartbeat，即使是 heartbeat，也需要进行一系列的检查。因此本文也不再区分心跳和 AppendEntries RPC。 leaderCommit Leader 的 commitIndex，帮助 Follower 更新自身的 commitIndex。 Receiver Implementation\n若 Follower 在 prevLogIndex 位置的 entry 的 term 与 prevLogTerm 不同（或者 prevLogIndex 的位置没有 entry），返回 false。 如果 Follower 的某一个 entry 与需要同步的 entries 中的一个 entry 冲突，则需要删除冲突 entry 及其之后的所有 entry。需要特别注意的是，假如没有冲突，不能删除任何 entry。因为存在 Follower 的 log 更 up-to-date 的可能。 添加 Log 中不存在的新 entry。 如果 leaderCommit \u0026gt; commitIndex，令 commitIndex = min(leaderCommit, index of last new entry)。此即 Follower 更新 commitIndex 的方式。 RequestVote RPC Args\nlastLogIndex Candidate 最后一个 entry 的 index，是投票的额外判据。 lastLogTerm 上述 entry 的 term。 Receiver Implementation\n只有 Candidate 的 log 至少与 Receiver 的 log 一样新（up-to-date）时，才同意投票。Raft 通过两个日志的最后一个 entry 来判断哪个日志更 up-to-date。假如两个 entry 的 term 不同，term 更大的更新。term 相同时，index 更大的更新。\nRaft determines which of two logs is more up-to-date by comparing the index and term of the last entries in the logs. If the logs have last entries with different terms, then the log with the later term is more up-to-date. If the logs end with the same term, then whichever log is longer is more up-to-date.\n这里投票的额外限制是为了保证已经被 commit 的 entry 一定不会被覆盖。仅有当 Candidate 的 log 包含所有已提交的 entry，才有可能当选为 Leader。\nRules for Servers All Severs\n如果 commitIndex \u0026gt; lastApplied，lastApplied++，将 log[lastApplied] 应用到状态机。即前文提到的 entry 从已提交状态到已应用状态的过程。 Leaders\n如果收到了来自 client 的 command，将 command 以 entry 的形式添加到日志。在 lab2B 中，client 通过 Start() 函数传入 command。\n如果 last log index \u0026gt;= nextIndex[i]，向 peer[i] 发送 AppendEntries RPC，RPC 中包含从 nextIndex[i] 开始的日志。\n如果返回值为 true，更新 nextIndex[i] 和 matchIndex[i]。 如果因为 entry 冲突，RPC 返回值为 false，则将 nextIndex[i] 减1并重试。这里的重试不一定代表需要立即重试，实际上可以仅将 nextIndex[i] 减1，下次心跳时则是以新值重试。 如果存在 index 值 N 满足：\nN \u0026gt; commitIndex 过半数 matchIndex[i] \u0026gt;= N log[N].term == currentTerm 则令 commitIndex = N。\n这里则是 Leader 更新 commitIndex 的方式。前两个要求都比较好理解，第三个要求是 Raft 的一个特性，即 Leader 仅会直接提交其任期内的 entry。存在这样一种情况，Leader 上任时，其最新的一些条目可能被认为处于未被提交的状态（但这些条目实际已经成功同步到了大部分节点上）。Leader 在上任时并不会检查这些 entry 是不是实际上已经可以被提交，而是通过提交此后的 entry 来间接地提交这些 entry。这种做法能够 work 的基础是 Log Matching Property：\nLog Matching: if two logs contain an entry with the same index and term, then the logs are identical in all entries up through the given index.\n原文描述如下：\nTo eliminate problems like the one in Figure 8, Raft never commits log entries from previous terms by counting replicas. Only log entries from the leader’s current term are committed by counting replicas; once an entry from the current term has been committed in this way, then all prior entries are committed indirectly because of the Log Matching Property. There are some situations where a leader could safely conclude that an older log entry is committed (for example, if that entry is stored on every server), but Raft takes a more conservative approach for simplicity.\n这样简化了 Leader 当选的初始化工作，也成功避免了简单地通过 counting replicas 提交时，可能出现的已提交 entry 被覆盖的问题。\n到这里 Figure 2 基本介绍完毕。也大致解释了 Figure 2 中各种规则的缘由。Raft 论文中还有更多 Raft 的设计理念、Properties、安全性证明等内容，这里就不再赘述了。\nImplementation Lab2B 实现的难点应该在于众多的 corner case，以及理想情况与代码执行方式的差异，太多的线程和 RPC 让系统的复杂性骤升，未持有锁的时刻什么都有可能发生。另外还有一个令人纠结的地方，就是各种时机。例如，接收到了 client 的一个请求，什么时候将这条 entry 同步给 Follower？什么时候将已提交的 entry 应用至状态机？更新某一变量时，是起一线程轮询监听，还是用 channel 或者 sync.Cond 唤醒，还是采取 lazy 策略，问到我的时候再去计算？很多实现方式理论上都可以使用，或许也各有各的好处，限于时间，面对很多问题，我也只选择了一种我认为的比较容易实现的方式。\n这部分的代码相较于 Lab2A 有一些变动，除了 Lab2B 中新增的内容，主要是对投票过程进行了一些修改。\n先说 go routine 的使用。对于所有的初始节点（Follower 节点），包含如下后台 go routines：\nalerter：1个。监听 electionTimer 的超时事件和重置事件。超时事件发生时，Follower 转变为 Candidate，发起一轮选举。重置事件发生时，将 electionTimer 重置。 applier：1个。监听 applierCh channel，当节点认为需要一次 apply 时，向 applierCh 发送一次信号，applier 接收信号后会将当前 lastApplied 和 commitIndex 间的所有 entry 提交。 heartbeat：1个。监听 heartbeatTimer 的超时事件，仅在节点为 Leader 时工作。heartbeatTimer 超时后，Leader 立即广播一次心跳命令。 replicator：n-1 个，每一个对于一个 peer。监听心跳广播命令，仅在节点为 Leader 时工作。接收到命令后，向对应的 peer 发送 AppendEntries RPC。 所有节点仅拥有这 4 种长期执行的后台 go routines，以及若干短期执行任务的 go routines。接下来一个一个介绍。\nalerter alerter 代码如下：\nfunc (rf *Raft) alerter() { doneCh := rf.register(\u0026#34;alerter\u0026#34;) defer rf.deregister(\u0026#34;alerter\u0026#34;) for { FORLOOP: select { case \u0026lt;-rf.elecTimer.timer.C: rf.lock(\u0026#34;alerter\u0026#34;) if rf.state == LEADER { rf.unlock(\u0026#34;alerter\u0026#34;) break FORLOOP } select { case \u0026lt;-rf.elecTimer.resetCh: rf.elecTimer.reset() rf.unlock(\u0026#34;alerter\u0026#34;) break FORLOOP default: } // start a new election rf.state = CANDIDATE rf.startElection() rf.unlock(\u0026#34;alerter\u0026#34;) case \u0026lt;-rf.elecTimer.resetCh: if !rf.elecTimer.timer.Stop() { select { case \u0026lt;-rf.elecTimer.timer.C: default: } } rf.elecTimer.timer.Reset(randomElectionTimeout()) case \u0026lt;-doneCh: return } } } 看上去还是有点复杂，下面慢慢来解释。\n首先是 doneCh。关于在节点被 kill 后，如何让各个后台协程优雅退出，有不少方法。原始代码框架中给出了 killed() 方法，希望我们在后台协程长期运行的 for 循环中检查节点是否被 kill。但是这种方法不太好用，原因是 for 循环中常常阻塞在接收 channel 信号的语句。此时虽然进入了 for 循环，但节点可能在阻塞时被 kill，协程无法得知。\n我希望能够有一种方式，在 kill() 方法被调用后，直接通知所有的后台 goroutines 让其停止运行。\n最先想到的是 context。go 的 context 包可以用来处理类似的问题，如超时处理等等。基本思想是构建一颗 goroutine 树，父节点拥有关闭子节点的权力。但这里的场景稍微有点不同，不同的协程间不存在父子关系，只是 Raft 节点的不同后台协程。由 Raft 结构体管理，通过广播的方式通知所有协程较为合适。\n提到广播机制，就想到了 sync.Cond ，条件变量。sync.Cond 的 Broadcast() 方法似乎与需求很契合，但 sync.Cond 的阻塞形式是 cond.Wait()，而不是由 channel 阻塞，不太方便配合 select 语句进行多路复用。\n最后决定实现一个简单的 channel 广播方法。Raft 节点维护一个 doneCh map：\ndoneCh map[string]chan struct{} key 是字符串，为协程的名称。value 是 channel。\n在后台协程初始化时，调用rf.register() 方法：\nfunc (rf *Raft) register(name string) \u0026lt;-chan struct{} { rf.lock() rf.doneCh[name] = make(chan struct{}) doneCh := rf.doneCh[name] rf.unlock() return doneCh } 在节点为协程注册一个 key-value，并返回注册生成的 channel，doneCh。\n此后，在 select 语句中监听 doneCh，收到信号后，立刻退出协程，并执行 rf.deregister()。\nfunc (rf *Raft) deregister(name string) { rf.lock() close(rf.doneCh[name]) delete(rf.doneCh, name) rf.unlock() } 关闭channel，并清除 map 中对应的 key-value。\n当上层调用 Kill() 方法时：\nfunc (rf *Raft) Kill() { atomic.StoreInt32(\u0026amp;rf.dead, 1) rf.lock(\u0026#34;Kill\u0026#34;) defer rf.unlock(\u0026#34;Kill\u0026#34;) for _, ch := range rf.doneCh { go func(ch chan struct{}) { ch \u0026lt;- struct{}{} }(ch) } } 遍历节点维护的 doneCh map，向所有 channel 发送信号，通知其对应的协程立即退出。\n这样就实现了在Kill()被调用时，第一时间主动通知所有后台协程退出，避免占用系统资源。\n接下来是 for 循环中的 select 语句。\ncase \u0026lt;-doneCh: 是刚才介绍的协程退出的通道。 case \u0026lt;-rf.elecTimer.timer.C: 是 electionTimer 超时事件发生的通道。 case \u0026lt;-rf.elecTimer.resetCh: 是 electionTimer 重置事件发生的通道。 需要注意的是，我在这里对 electionTimer 做了一个简单的封装。其拥有一个 reset() 方法。\ntype electionTimer struct { timer *time.Timer resetCh chan struct{} } func (timer *electionTimer) reset() { go func() { timer.resetCh \u0026lt;- struct{}{} }() } 为什么将 electionTimer 设定得这么复杂？按理来说，超时了就开始选举，需要重置的时候直接重置就好。我一开始也是这么想的，然而遇到了一个比较严重的问题。假如将超时事件按照如下处理：\nfunc alerter() { for { select { case \u0026lt;-electionTimer.C: rf.lock() if rf.state == LEADER { rf.unlock() break } rf.state = CANDIDATE rf.startElection() rf.unlock() } } } 假设超时事件发生，程序执行至 rf.lock() ，而此时，节点正在处理 RequestVote RPC，因此 rf.lock() 被阻塞：\nfunc (rf *Raft) RequestVote(args *RequestVoteArgs, reply *RequestVoteReply) { rf.lock(\u0026#34;RequestVote\u0026#34;) defer rf.unlock(\u0026#34;RequestVote\u0026#34;) ... reply.VoteGranted = true reply.Term = rf.currentTerm rf.votedFor = args.CandidateId rf.electionTimer.Reset(randomElectionTimeout()) } 节点将选票投给了另一个 Candidate 节点，退出 RPC handler，然后 alerter 协程成功抢占到了锁——悲剧发生了。刚刚投出选票的节点，立马发起了新一轮的选举。\n这种情况会不会影响系统的 safety？说实话，我暂时还不太清楚。毕竟只是换一个 Leader 而已。但这种情况的确会造成一些测试的 fail，例如发生 split vote，即同时有多个节点 electionTimer 超时时，会使刚刚上任的 Leader 立马变成 Follower，影响了 liveness。而且很显然，这种情况并不是我们希望看到的，我们希望看到的是，要么 electionTimer 超时，发起一轮选举，要么 electionTimer 被重置，选举不会发生。因此我尝试加以解决。\n通过上述分析，可以发现问题的关键在于，超时事件和重置事件不能同时进行，必须互斥进行。因此就有了 alerter 的 select 框架：\nFORLOOP: select { case \u0026lt;-rf.elecTimer.timer.C: rf.lock(\u0026#34;alerter\u0026#34;) if rf.state == LEADER { rf.unlock(\u0026#34;alerter\u0026#34;) break FORLOOP } select { case \u0026lt;-rf.elecTimer.resetCh: rf.elecTimer.reset() rf.unlock(\u0026#34;alerter\u0026#34;) break FORLOOP default: } // start a new election rf.state = CANDIDATE rf.startElection() rf.unlock(\u0026#34;alerter\u0026#34;) case \u0026lt;-rf.elecTimer.resetCh: if !rf.elecTimer.timer.Stop() { select { case \u0026lt;-rf.elecTimer.timer.C: default: } } rf.elecTimer.timer.Reset(randomElectionTimeout()) case \u0026lt;-doneCh: return } 先看重置事件。在封装好的 electionTimer 中，通过调用其 reset 方法将其重置。\nfunc (timer *electionTimer) reset() { timer.resetCh \u0026lt;- struct{}{} } 由于需要重置 electionTimer 时，一般持有锁，而重置 electionTimer 也不需要保证同步，因此这里的 resetCh 使用的是带缓存的 channel，不会阻塞。避免循环等待产生死锁，或发送信号阻塞时间过长，影响系统可用性。\nalerter 监听重置事件。重置事件发生时，对 electionTimer 进行重置。接下来是很经典的 go 重置 timer 的流程：先将 timer stop，假如 stop 时 timer 已经超时，则尝试将 channel 中的信号取出（若信号还未取出的话）。最后再 reset。\nFor a Timer created with NewTimer, Reset should be invoked only on stopped or expired timers with drained channels.\n这样就消除了上述的情况，当 select 语句先进入重置处理，若同时 electionTimer 超时，则将其信号取出，阻止其随后再立刻发起一轮选举。\n再看超时事件。\n如果当前身份已经为 Leader，则忽略超时事件。注意 select 语句中使用 break 的坑。\n随后又有一个 select 语句。这一步的目的是，假如 electionTimer 先超时，进入超时处理，此时 reset 信号来了，则将 reset 信号继续传递，并立刻停止超时处理，再下一次循环中将 electionTimer 重置。若没有 reset 信号，则继续后面的步骤。这样做的原因是，重置步骤是异步进行的，且重置事件与超时事件几乎同时发生时，为了保持 Leader 的 liveness，我们更加偏好优先处理重置事件。毕竟重置的信号已经到了，说明自己已经给其他 Candidate 投了票，或者 Leader 的心跳已经到了，没有必须发起一轮新的选举。\n实际上，这么做也是我的无奈之举。在正常情况下，Leader 发送心跳不会和 Follower 超时同时发生，因为心跳间隔是小于随机超时时间的最小值的。但我的代码有一个诡异的 bug，在一些时候，整个系统（同一时间，所有节点，所以基本可以排除代码阻塞在某处，或者等待 RPC 的问题）可能会同时停顿一段时间（400ms左右），导致 Leader 权力丧失。后面还会尽量详细介绍这个 bug，我有点怀疑是 gc 导致的，不过也实在没有能力继续排查。因此，只能通过偏好重置来增强 Leader 的 liveness。但实际上和我前面介绍的一样，即使没有这个问题，偏好重置也是更合理的选择。\n后面则是发起一轮选举的过程。选举流程相较 Lab2A 有所修改，以下给出代码，就不再做更多的介绍了。\nfunc (rf *Raft) startElection() { rf.currentTerm++ rf.votedFor = rf.me rf.elecTimer.reset() args := RequestVoteArgs{} args.CandidateId = rf.me args.Term = rf.currentTerm args.LastLogIndex = rf.lastLogIndex() args.LastLogTerm = rf.log[rf.lastLogIndex()].Term voteGrantedCnt := 1 // send RequestVote RPCs to all other peers. for i := range rf.peers { if i == rf.me { continue } go func(i int) { reply := RequestVoteReply{} if ok := rf.sendRequestVote(i, \u0026amp;args, \u0026amp;reply); !ok { return } rf.lock(\u0026#34;startElection\u0026#34;) defer rf.unlock(\u0026#34;startElection\u0026#34;) if rf.currentTerm != args.Term || rf.state != CANDIDATE { // outdated reply, or Candidate has been elected as LEADER return } if reply.Term \u0026gt; rf.currentTerm { rf.currentTerm = reply.Term rf.votedFor = -1 rf.state = FOLLOWER rf.elecTimer.reset() return } if !reply.VoteGranted { return } voteGrantedCnt++ if voteGrantedCnt \u0026gt; len(rf.peers)/2 { // gain over a half votes, convert to leader rf.state = LEADER for i := 0; i \u0026lt; len(rf.peers); i++ { // reinitialize upon winning the election rf.nextIndex[i] = rf.lastLogIndex() + 1 rf.matchIndex[i] = 0 } rf.broadcast(true) } }(i) } } 需要注意两点：\n投票是并行异步，前面已经提到过了。需要额外注意的是，各个 voter routines 发送 RPC 使用的 args 要完全一样，在启动 voter routines 前准备好，不可以在 voter routine 内部各自重新加锁读取 args，否则可能会导致发送的 args 不同。未持锁时，任何事情都可能发生。\n在接收到 reply 时，一定要判断一下这是不是过期或无效的 reply，比如当前的 term 已经大于 args 的 term，那么这就是一个过期的 reply。论文中介绍过，对于过期的 reply，直接抛弃即可。Students\u0026rsquo; Guide to Raft 中也提到了这个问题，引用其中的一段话：\nFrom experience, we have found that by far the simplest thing to do is to first record the term in the reply (it may be higher than your current term), and then to compare the current term with the term you sent in your original RPC. If the two are different, drop the reply and return. Only if the two terms are the same should you continue processing the reply. There may be further optimizations you can do here with some clever protocol reasoning, but this approach seems to work well. And not doing it leads down a long, winding path of blood, sweat, tears and despair.\n关于 electionTimer 就介绍到这里。实现最初版本的 electionTimer 逻辑并不困难，但要保证完全地 bug-free (我目前的代码也不能保证)，难度还是很大。其中关于重置和超时同时发生的处理方式，也困扰了我很长时间，最终才得出这个较为稳定的版本。\napplier applier 代码如下：\nfunc (rf *Raft) applier() { doneCh := rf.register(\u0026#34;applier\u0026#34;) defer rf.deregister(\u0026#34;applier\u0026#34;) for { select { case \u0026lt;-rf.applierCh: rf.lock(\u0026#34;applier\u0026#34;) lastApplied := rf.lastApplied rf.lastApplied = rf.commitIndex entries := append([]LogEntry{}, rf.log[lastApplied+1:rf.commitIndex+1]...) rf.unlock(\u0026#34;applier\u0026#34;) for i, entry := range entries { command := entry.Command rf.applyCh \u0026lt;- ApplyMsg{ CommandValid: true, Command: command, CommandIndex: lastApplied + i + 1, } } case \u0026lt;-doneCh: return } } } applier 监听 applierCh，当信号到来时，将 lastApplied 到 commitIndex 间的所有 entry 按序应用至状态机。对于 entry 的 apply，采用一种较懒的方式：在 commitIndex 更新时，向 applierCh 异步发送信号即可。\ngo func() { rf.applierCh \u0026lt;- struct{}{} }() heartbeat heartbeat的代码如下：\nfunc (rf *Raft) heartbeat() { doneCh := rf.register(\u0026#34;heartbeat\u0026#34;) defer rf.deregister(\u0026#34;heartbeat\u0026#34;) for { select { case \u0026lt;-rf.heartbeatTimer.C: rf.lock(\u0026#34;heartbeat\u0026#34;) if rf.state != LEADER { rf.unlock(\u0026#34;heartbeat\u0026#34;) break } rf.broadcast(true) rf.unlock(\u0026#34;heartbeat\u0026#34;) case \u0026lt;-doneCh: return } } } heartbeat 的部分也比较简单。heartbeatTimer 超时后，则 broadcast 一轮心跳信息即可。为什么 heartbeatTimer 不用像 electionTimer 那样制定复杂的规则？本质上是因为 heartbeatTimer 超时和重置的时刻都是已知的，可控的，不像 electionTimer 会并行地随时发生。\nbroadcast 代码如下：\nfunc (rf *Raft) broadcast(isHeartbeat bool) { rf.heartbeatTimer.Stop() rf.heartbeatTimer.Reset(HEARTBEAT_INTERVAL) args := AppendEntriesArgs{} args.LeaderCommit = rf.commitIndex args.LeaderId = rf.me args.Term = rf.currentTerm for i := range rf.peers { if i == rf.me { continue } if isHeartbeat || rf.nextIndex[i] \u0026lt;= rf.lastLogIndex() { go func(i int) { rf.apeChPool[i] \u0026lt;- args }(i) } } } 同样，用于 RPC 的 args 要提前准备好，用 channel 传递给每一个 replicator。需要注意的是，有两种事件会调用 broadcast。\n一是 heartbeatTimer 超时时，此时 Leader 为了维持权力，必须立刻向所有 peer 发送一次 AppendEntries RPC，即使需要同步的 entry 为空（即论文中所说的 heartbeat）。\n二是在上层 client 调用 Start() 函数发送命令时：\nfunc (rf *Raft) Start(command interface{}) (int, int, bool) { rf.lock(\u0026#34;Start\u0026#34;) defer rf.unlock(\u0026#34;Start\u0026#34;) if rf.state != LEADER { return -1, -1, false } index := rf.logLen() + 1 term := rf.currentTerm isLeader := true rf.log = append(rf.log, LogEntry{ Term: term, Command: command, }, ) rf.broadcast(false) return index, term, isLeader } 此时，假如没有需要新同步的 entry，则无需发送一轮空的 AppendEntries RPC。这里的处理参考了 MIT6.824-2021 Lab2 : Raft 的做法。但后来我用 go test cover 的工具简单测试了一下，似乎没有覆盖到无需立即 broadcast 的路径。可能这样的处理是与后续 lab 有关，或者是我的理解有误。（已更新，是我的实现有误）\nreplicator replicator 的代码如下：\nfunc (rf *Raft) replicator(peer int) { doneCh := rf.register(fmt.Sprintf(\u0026#34;replicator%d\u0026#34;, peer)) defer rf.deregister(fmt.Sprintf(\u0026#34;replicator%d\u0026#34;, peer)) for { select { case args := \u0026lt;-rf.apeChPool[peer]: reply := AppendEntriesReply{} rf.rlock(\u0026#34;replicator\u0026#34;) args.PrevLogIndex = rf.nextIndex[peer] - 1 args.PrevLogTerm = rf.log[rf.nextIndex[peer]-1].Term if rf.nextIndex[peer] \u0026lt;= rf.lastLogIndex() { args.Entries = rf.log[rf.nextIndex[peer]:] } rf.runlock(\u0026#34;replicator\u0026#34;) go func() { if ok := rf.sendAppendEntries(peer, \u0026amp;args, \u0026amp;reply); !ok { return } rf.lock(\u0026#34;replicator\u0026#34;) defer rf.unlock(\u0026#34;replicator\u0026#34;) if rf.currentTerm != args.Term || rf.state != LEADER { // outdated reply, or LEADER has no longer been the LEADER return } if reply.Term \u0026gt; rf.currentTerm { rf.currentTerm = reply.Term rf.votedFor = -1 rf.state = FOLLOWER rf.elecTimer.reset() return } if reply.Success { if rf.nextIndex[peer]+len(args.Entries) \u0026gt; rf.lastLogIndex()+1 { // repeated reply, ignore return } rf.nextIndex[peer] = args.PrevLogIndex + len(args.Entries) + 1 rf.matchIndex[peer] = rf.nextIndex[peer] - 1 N := rf.lastLogIndex() for N \u0026gt; rf.commitIndex { if rf.log[N].Term != rf.currentTerm { N-- continue } cnt := 1 for _, matchidx := range rf.matchIndex { if matchidx \u0026gt;= N { cnt++ } } if cnt \u0026lt;= len(rf.peers)/2 { N-- continue } rf.commitIndex = N go func() { rf.applierCh \u0026lt;- struct{}{} }() return } } else { index := -1 found := false for i, entry := range rf.log { if entry.Term == reply.ConflictTerm { index = i found = true } else if found { break } } if found { rf.nextIndex[peer] = index + 1 } else { rf.nextIndex[peer] = reply.ConflictIndex } } }() case \u0026lt;-doneCh: return } } } replicator 也比较复杂。\n由于有多个 replicator 需要注册，在注册是记得根据对应 peer 使用不同的注册名。\nreplicator 监听 broadcast 发送的信号。接收到信号时，向对应 peer 发送 AppendEntries RPC。\n需要注意的是，在接收到 reply 时，如果 reply 已经过期，同样需要直接抛弃。另外，由于 RPC 返回所需的时长不固定，有可能第一个 RPC 还没有返回，第二次心跳已经开始，这时会发送两条相同的 RPC，且都会返回 success（假如 Follower 先处理了第一个 RPC 请求，在处理第二个请求时，log 已经包含了需要同步的 entry，但不会发生冲突）。因此，需要先判断一下 nextIndex 是不是已经被更新过了，假如已经被更新，即 rf.nextIndex[peer]+len(args.Entries) \u0026gt; rf.lastLogIndex()+1，就代表收到了重复的回复，直接抛弃即可。随后则是 Leader 更新其 commitIndex 的流程。\n另外，假如 reply 由于 log 冲突返回了 false，我采用了论文中提到的优化，即 Follower 通过 reply 直接告知 Leader 发生冲突的位置，Leader 不用每次将 nextIndex - 1多次重试。经过测试，这个优化还是挺有必要的，可以显著地缩短 Lab2B 中一项 test 的运行时间。具体方法见 Students\u0026rsquo; Guide to Raft : An aside on optimizations：\nThe Raft paper includes a couple of optional features of interest. In 6.824, we require the students to implement two of them: log compaction (section 7) and accelerated log backtracking (top left hand side of page 8). The former is necessary to avoid the log growing without bound, and the latter is useful for bringing stale followers up to date quickly.\nThese features are not a part of “core Raft”, and so do not receive as much attention in the paper as the main consensus protocol.\nThe accelerated log backtracking optimization is very underspecified, probably because the authors do not see it as being necessary for most deployments. It is not clear from the text exactly how the conflicting index and term sent back from the client should be used by the leader to determine what nextIndex to use. We believe the protocol the authors probably want you to follow is:\nIf a follower does not have prevLogIndex in its log, it should return with conflictIndex = len(log) and conflictTerm = None. If a follower does have prevLogIndex in its log, but the term does not match, it should return conflictTerm = log[prevLogIndex].Term, and then search its log for the first index whose entry has term equal to conflictTerm. Upon receiving a conflict response, the leader should first search its log for conflictTerm. If it finds an entry in its log with that term, it should set nextIndex to be the one beyond the index of the last entry in that term in its log. If it does not find an entry with that term, it should set nextIndex = conflictIndex. A half-way solution is to just use conflictIndex (and ignore conflictTerm), which simplifies the implementation, but then the leader will sometimes end up sending more log entries to the follower than is strictly necessary to bring them up to date.\nRPCs AppendEntries RPC 代码如下：\nfunc (rf *Raft) AppendEntries(args *AppendEntriesArgs, reply *AppendEntriesReply) { rf.lock(\u0026#34;AppendEntries\u0026#34;) defer rf.unlock(\u0026#34;AppendEntries\u0026#34;) if args.Term \u0026lt; rf.currentTerm { reply.Success = false reply.Term = rf.currentTerm return } if args.Term \u0026gt; rf.currentTerm { rf.currentTerm = args.Term rf.votedFor = -1 } if rf.state != FOLLOWER { rf.state = FOLLOWER } rf.elecTimer.reset() if args.PrevLogIndex \u0026gt; rf.lastLogIndex() || args.PrevLogIndex \u0026gt; 0 \u0026amp;\u0026amp; rf.log[args.PrevLogIndex].Term != args.PrevLogTerm { // Reply false if log doesn\u0026#39;t contain an entry at prevLogIndex whose term matches prevLogTerm reply.Success = false reply.Term = rf.currentTerm // accelerated log backtracking optimization if args.PrevLogIndex \u0026gt; rf.lastLogIndex() { reply.ConflictTerm = -1 reply.ConflictIndex = rf.lastLogIndex() + 1 } else { reply.ConflictTerm = rf.log[args.PrevLogIndex].Term index := args.PrevLogIndex - 1 for index \u0026gt; 0 \u0026amp;\u0026amp; rf.log[index].Term == reply.ConflictTerm { index-- } reply.ConflictIndex = index + 1 } return } // If an existing entry conflicts with a new one (same index but different terms), // delete the existing entry and all that follow it for i, entry := range args.Entries { index := args.PrevLogIndex + i + 1 if index \u0026gt; rf.lastLogIndex() || rf.log[index].Term != entry.Term { rf.log = rf.log[:index] rf.log = append(rf.log, append([]LogEntry{}, args.Entries[i:]...)...) break } } if args.LeaderCommit \u0026gt; rf.commitIndex { // If leaderCommit \u0026gt; commitIndex, set commitIndex = min(leaderCommit, index of last new entry) rf.commitIndex = min(args.LeaderCommit, rf.logLen()) go func() { rf.applierCh \u0026lt;- struct{}{} }() } reply.Success = true reply.Term = rf.currentTerm } AppendEntries RPC 没有太多可说的，严格按照 Figure 2 来就好。另外注意这里也需要实现前面说的 accelerated log backtracking optimization。\nRequestVote RPC 代码如下：\nfunc (rf *Raft) RequestVote(args *RequestVoteArgs, reply *RequestVoteReply) { rf.lock(\u0026#34;RequestVote\u0026#34;) defer rf.unlock(\u0026#34;RequestVote\u0026#34;) if args.Term \u0026lt; rf.currentTerm { reply.VoteGranted = false reply.Term = rf.currentTerm return } if args.Term \u0026gt; rf.currentTerm { rf.currentTerm = args.Term rf.votedFor = -1 if rf.state != FOLLOWER { rf.state = FOLLOWER rf.elecTimer.reset() } } if rf.votedFor != -1 \u0026amp;\u0026amp; rf.votedFor != args.CandidateId { reply.VoteGranted = false reply.Term = rf.currentTerm return } if rf.logLen() \u0026gt; 0 { rfLastLogTerm := rf.log[rf.lastLogIndex()].Term rfLastLogIndex := rf.lastLogIndex() if rfLastLogTerm \u0026gt; args.LastLogTerm || rfLastLogTerm == args.LastLogTerm \u0026amp;\u0026amp; rfLastLogIndex \u0026gt; args.LastLogIndex { // If candidate\u0026#39;s log is at least as up-to-date as receiver\u0026#39;s log, grant vote; otherwise reject reply.VoteGranted = false reply.Term = rf.currentTerm return } } reply.VoteGranted = true reply.Term = rf.currentTerm rf.votedFor = args.CandidateId rf.elecTimer.reset() } 同样也没有说明可说的。按照 Figure 2 来。\nLab2B 的全部实现大致就是这样。回过头来看好像也不是特别复杂，但确实折磨了我很久，看了整整几天的 log。\nHappy Debugging 前面也提到了，对于 Lab2B，实现一版能够通过一次 test，甚至能够通过90%百次 test 的代码并不是特别难，严格按照 Figure2 编写就好。然而，前面 90% 的任务需要 90% 的时间完成，后面 10% 的任务需要另一个 90% 的时间来完成（甚至更久）。\n关于 debug，由于 Raft 是个多线程的项目，也有 RPC，因此以往打断点，单步 debug 的方式肯定行不通。实际上，最原始的方法就是最有效的方法，print log。\n在编写代码前，强烈推荐阅读 Debugging by Pretty Printing。这篇博客详细教你如何打日志，并用 python 的 rich 库打印漂亮工整的命令行输出。在编写代码时，记得在关键处增加一些 Debug 语句，时刻掌握系统变化的情况。\n这样各节点的状态清晰很多，方便 debug。\n同时，在 Lab2B 中，我也遭遇了 Lab2A 中没有碰到的死锁问题。为了追踪锁的使用情况，我对锁做了一点封装。\nfunc (rf *Raft) lock(where string) { Debug(dLock, \u0026#34;S%d locked %s\u0026#34;, rf.me, where) rf.mu.Lock() } func (rf *Raft) unlock(where string) { Debug(dLock, \u0026#34;S%d unlocked %s\u0026#34;, rf.me, where) rf.mu.Unlock() } 主要就是增加了一个 debug 语句，对锁的使用情况进行跟踪。有了锁的日志之后，解决死锁问题不算困难。一般都是在同一段代码中不小心锁了两次，或者在发送、接收阻塞 channel 时持有了锁。比较好排查。\nA Confusing Bug 截至 7.19，我已经跑了上万次 Lab2B 的 test。其中仍会出现几次 fail。经过排查，全部都是同一种原因导致，即上文提到过的，整个系统偶尔会出现一次400ms左右的停顿，导致 Leader 失去权力，出现新的 Candidate 并竞选成为 Leader。其中一次日志如下：\n这是 Lab2B test 中最简单的 BasicAgreeTest，内容是成功选出 Leader，然后同步3条 entry 即可。正常情况下不会出现 Leader 变动。\n日志中每条语句前的时间戳单位为 ms。此时 S2 为 Leader。\n可以看到，在 730 ms 时，S2进行了一次心跳，成功将 {1，300} （任期号为1，命令内容为300）同步给 S0 和 S1。我设置的心跳间隔为 150 ms。然而，在 150 ms 后，也就是 880 ms 时，系统没有任何动作。此时 S2 本应该发送一次心跳，告知 S0 和 S1 {1，300} 已提交，可以将其应用至状态机。\n在 731 ms 时，S0 的 electionTimer 被 reset 为 308 ms，S1 的 electionTimer 被 reset 为 331 ms。按理说，即使没有接收到 Leader 的心跳，S0 也会在 308 ms 后，也就是 1039 ms 时，S0 electionTimer 超时，发起一轮选举。然而此时系统仍然没有动作。\n在 1092 ms 时，所有节点似乎同时苏醒了，S0 和 S1 都发起了一轮选举，S2 也接收到了投票请求。于是 S1 成功当选 Leader。\nS1 在当选 Leader 时，所有节点的 log 都是一致的，为 {1，100} {1，200} {1，300}，其中第3条 entry 没有提交。而由于 Raft 的特性，Leader 不会提交不属于其当前任期的 entry，只会在成功同步并提交下一条到来的 entry 时，间接地将第3条 entry 提交。然而不幸的是，第3条 entry 已经是 BasicAgree 会发送的最后一条 entry。因此，在这次 test 中，这条 entry 无法被提交，也就导致了 test fail。\n系统出现诡异停顿的原因是什么？是 timer 的种种坑，还是 gc 的锅？原谅我实在没有能力排查，因为这种 bug 出现的概率极低（应该略高于导致 test fail 的频率，因为可能在出现这种 bug 时，test 仍可以通过，导致 bug 被吞掉），并且这种 bug 实际上可以看成是所有节点同时 down 掉几百毫秒，对于 Raft 系统来说应该是可以容忍的，可能只会造成一次 Leader 更替。导致 test fail 的直接原因是 Raft 不直接提交不属于当前任期 entry 的特性，和 test 刚好没有后续需要同步的 entry。\n这里就留下一个遗憾吧，希望我以后有能力排查，到底是哪里出了问题。\nSummary 做完 Lab2B 的感觉很爽，但过程也真的很痛苦。从自信地通过第一次 test，到好几个痛苦 debug 的深夜，再到最后的成功实现。有种便秘的酣畅淋漓的感觉（？）。Lab2A 和 Lab2B 是 Raft 算法的核心内容，能够成功撸下来还是有一点点小小的成就感的。\n另外想说的是。6.824 Guidance 中提到了，对于计时操作，不要使用 go timer 或者 ticker，而是应该使用 sleep，在醒来时检查各种变量来实现。然而我还是硬着头皮用了 timer，毕竟这样更加直观，或许也更优雅。然而我不知道这是不是一个正确的选择。因为 timer 的各种诡异现象 debug 到破防的时候，我也想过是不是该推倒重来，全部换成 sleep。最终翻了很多篇博客和资料，还是勉强做出了这个能用的版本。是不是真的用 sleep 更容易实现呢？我也不知道。也许选择比努力更重要，但还是要坚持自己的选择，继续努力吧。\nLab2C Raft Persistence 对 lab2C，guidance 中给出了 hard 的难度，但实际上只要认真完成了 lab2B，lab2C 应该是 easy。\nRaft 节点挂掉后，在重新恢复时，会从 disk 中读取其此前的状态。Figure 2 中已经告诉我们哪些状态需要持久化：\ncurrentTerm votedFor log 因此，只要我们对这些变量进行了修改，就需要进行一次持久化，将这些变量记录在 disk 上。（实际上，这样可能对性能有所影响，因为写入 disk 的 IO 操作比较耗时，但对 6.824 来说这样的简单处理没有问题）\n在 lab2C 中，我们不需要真的将状态写入 disk，为了简化代码和方便测试，lab2C 提供了给我们一个 persister 类。在需要对状态进行持久化时，使用 Raft 初始化时传入的 persister 对象对其存储即可。读取状态时也从 persister 中读取。\n需要实现 persist() and readPersist() 两个函数：\nfunc (rf *Raft) persist() { w := new(bytes.Buffer) e := labgob.NewEncoder(w) e.Encode(rf.currentTerm) e.Encode(rf.votedFor) e.Encode(rf.log) data := w.Bytes() rf.persister.SaveRaftState(data) } func (rf *Raft) readPersist(data []byte) { if data == nil || len(data) \u0026lt; 1 { // bootstrap without any state? return } r := bytes.NewBuffer(data) d := labgob.NewDecoder(r) var currentTerm int var votedFor int var log []LogEntry if d.Decode(\u0026amp;currentTerm) != nil || d.Decode(\u0026amp;votedFor) != nil || d.Decode(\u0026amp;log) != nil { panic(\u0026#34;readPersist decode fail\u0026#34;) } rf.currentTerm = currentTerm rf.votedFor = votedFor rf.log = log } 之后在 Raft 改变 currentTerm、votedFor 或 log 时，及时调用 rf.persist() 即可。\nLab2D Raft Log Compaction Lab2D 编写初版 pass 代码大概用了两小时，随后断断续续 debug 修改好几天。\nLab2D 是实现日志压缩。这其实并不是 Raft 算法的核心部分，Raft 算法的强一致性等特性也不依赖于日志压缩。但由于内存容量的限制，日志压缩在 Raft 的工业实现上也很重要。此前我们将 log 全部存储在内存之中，但随着 log 的不断增长，内存总是会被消耗殆尽。因此及时地将过老的已提交的日志压缩成快照很有必要。\nDesign Raft 的 snapshot 包含三个字段：\nstate machine state: 即状态机的快照。假如节点崩溃，随后重放 log 恢复时，以快照为初始状态进行重放。\nlast included index: 快照包含的最后一个 entry 的 index。这个字段是 log index 和 real index 的偏移量。log index 指某个 entry 在当前内存中 log 的位置，real index 则是某个 entry 的全局 index。例如如下情况：\nreal index = last included index + log index\nlast included term: 即 last included index 对应 entry 的 term。用于 AppendEntries RPC 中对于 prevLogIndex 和 prevLogTerm 的检测。\n快照可以由上层应用触发。当上层应用认为可以将一些已提交的 entry 压缩成 snapshot 时，其会调用节点的 Snapshot()函数，将需要压缩的状态机的状态数据传递给节点，作为快照。\n在正常情况下，仅由上层应用命令节点进行快照即可。但如果节点出现落后或者崩溃，情况则变得更加复杂。考虑一个日志非常落后的节点 i，当 Leader 向其发送 AppendEntries RPC 时，nextIndex[i] 对应的 entry 已被丢弃，压缩在快照中。这种情况下， Leader 就无法对其进行 AppendEntries。取而代之的是，这里我们应该实现一个新的 RPC，将 Leader 当前的快照直接发送给非常落后的 Follower。\n在 Raft 论文中，InstallSnapshot RPC 将 snapshot 分块发送，但在 6.824 的实现中，我们直接将整个 snapshot 全部一次发送即可。需要实现的字段如下：\nArgs\nterm Leader 的任期。同样，InstallSnapshot RPC 也要遵循 Figure 2 中的规则。如果节点发现自己的任期小于 Leader 的任期，就要及时更新。 leaderId 用于重定向 client 。 lastIncludedindex \u0026amp; lastIncludedTerm 快照中包含的最后一个 entry 的 index 和 term。 data[] 快照数据。 Reply\nterm 节点的任期。Leader 发现高于自己任期的节点时，更新任期并转变为 Follower。 Receiver Implementation\n如果 term \u0026lt; currentTerm，直接返回。 保存 snapshot。 如果当前 log 中包含 index 和 term 与 last included entry 相同的 entry，则保留此 entry 后的 log，并返回。 丢弃所有 log。 使用 snapshot 重置状态机。 整个日志压缩的设计就是这样，并不算复杂。但实现起来还是有点麻烦，有特别多的 corner case，且需要对之前的代码进行大量改动。\nImplementation index mapping 引入日志压缩后的一大改变是，访问 log 不像之前那么轻松了。\nRaft 论文中约定，log 的索引从 1 开始。在此前的实现中，使用数组保存 log，直接使用索引访问即可。但在引入日志压缩后，需要配合 lastIncludedIndex 进行换算。\n// get an entry with its real index func (rf *Raft) entry(index int) LogEntry { return rf.log[index-rf.lastIncludedIndex] } // switch real index to log index func (rf *Raft) logIndex(realIndex int) int { return realIndex - rf.lastIncludedIndex } // switch log index to real index func (rf *Raft) realIndex(logIndex int) int { return logIndex + rf.lastIncludedIndex } // get the real index of the latest entry in log func (rf *Raft) lastLogIndex() int { return len(rf.log) - 1 + rf.lastIncludedIndex } // get the term of the latest entry in log func (rf *Raft) lastLogTerm() int { // log[0] : last included entry in snapshot return rf.log[len(rf.log)-1].Term } 在这里我实现了一系列的函数，方便索引的换算。其中，real index 指 entry 本身的索引，也就是从 1 递增的索引。log index 指 entry 存放在内存 log 中的位置。\n另外，由于索引从 1 开始，log[0] 的位置始终空出。因此可以将 last included entry 存放在 log[0] 的位置，这样在检测前置 entry 等操作中，需要访问 last included entry 时无需做额外的判断，算是一个小 trick。\n此后，将之前所有访问 log 的操作全部用新接口替换。\nSnapshot() func (rf *Raft) Snapshot(index int, snapshot []byte) { rf.lock(\u0026#34;Snapshot\u0026#34;) defer rf.unlock(\u0026#34;Snapshot\u0026#34;) defer rf.persist() if index \u0026lt;= rf.lastIncludedIndex { // outdated request return } rf.snapshot = snapshot rf.lastIncludedTerm = rf.entry(index).Term rf.lastIncludedIndex = index rf.log = append([]LogEntry{{Term: rf.lastIncludedTerm}}, rf.log[rf.logIndex(index)+1:]...) } Snapshot() 方法由上层调用，代表上层已经成功将给定 index 及其前的 entry 进行了压缩，压缩结果为 snapshot。因此，节点需要丢弃已被压缩的日志。\n需要注意的是，在抛弃日志时，不能简单地截取切片，例如\nlog = log[index+1:] 这和 go slice 的底层实现有关。go slice 的底层是一个定长数组和一个给定的引用范围。在数组容量不足时，会自动扩容，此时是在不同的地址创建了一个新的数组。在截取 slice 时，实际上没有创建新的数组，只是改变了引用的范围。但比较坑的是，即使此后仅会使用某个范围内的元素，整个数组也不会被 gc 回收，而是一直保留，最后造成 oom。\n因此，在抛弃日志时，可以用 append 方法创建新数组，确保之前的底层数组会被 gc 回收。\nInstallSnapshot RPC func (rf *Raft) InstallSnapshot(args *InstallSnapshotArgs, reply *InstallSnapshotReply) { rf.lock(\u0026#34;InstallSnapshot\u0026#34;) defer rf.unlock(\u0026#34;InstallSnapshot\u0026#34;) if args.Term \u0026lt; rf.currentTerm { reply.Term = rf.currentTerm return } defer rf.persist() if args.Term \u0026gt; rf.currentTerm { rf.currentTerm = args.Term rf.votedFor = -1 } if rf.state != FOLLOWER { rf.state = FOLLOWER } rf.elecTimer.reset() reply.Term = rf.currentTerm rf.snapshot = args.Data if args.LastIncludedIndex \u0026lt; rf.lastIncludedIndex { return } if rf.lastIncludedIndex == args.LastIncludedIndex \u0026amp;\u0026amp; rf.lastIncludedTerm == args.LastIncludedTerm { return } defer func() { msg := ApplyMsg{ CommandValid: false, SnapshotValid: true, Snapshot: args.Data, SnapshotTerm: args.LastIncludedTerm, SnapshotIndex: args.LastIncludedIndex, } go func() { rf.applyCh \u0026lt;- msg }() }() for i := 1; i \u0026lt; len(rf.log); i++ { if rf.realIndex(i) == args.LastIncludedIndex \u0026amp;\u0026amp; rf.log[i].Term == args.LastIncludedTerm { rf.lastIncludedTerm = args.LastIncludedTerm rf.lastIncludedIndex = args.LastIncludedIndex rf.log = append([]LogEntry{{Term: rf.lastIncludedTerm}}, rf.log[i+1:]...) rf.lastApplied = rf.lastIncludedIndex rf.commitIndex = rf.lastIncludedIndex return } } rf.lastIncludedIndex = args.LastIncludedIndex rf.lastIncludedTerm = args.LastIncludedTerm rf.log = []LogEntry{{Term: rf.lastIncludedTerm}} rf.lastApplied = rf.lastIncludedIndex rf.commitIndex = rf.lastIncludedIndex } 在实现 InstallSnapshot RPC 时，也要遵守之前 Figure 2 中的规则。另外，InstallRPC 也可以看成 Leader 的一次心跳，Follower 既然接收到了来自 Leader 的 RPC，就代表 Leader 还“活着”。\n在最后，需要更新节点的 lastApplied 和 commitIndex。生成快照实际上是将 entry 应用至状态机。我在这里简单地将lastApplied 和 commitIndex 直接设置为 lastIncludedIndex。实际上对于 commitIndex 的更新应该存在更合理的方式。\nLeader Broadcast 引入日志压缩后，Broadcast 也需要做一些修改，部分情况需要调用 InstallSnapshot RPC 而不是 AppendEntries RPC。同时，我发现了之前 Broadcast 模型存在的问题，在这里一并说明。\nfunc (rf *Raft) broadcast(isHeartbeat bool) { if isHeartbeat { rf.heartbeatTimer.Stop() rf.heartbeatTimer.Reset(HEARTBEAT_INTERVAL) } info := replicateInfo{ term: rf.currentTerm, leaderCommit: rf.commitIndex, } for i := range rf.peers { if i == rf.me { continue } if isHeartbeat { go rf.replicate(i, info) continue } if rf.nextIndex[i] \u0026lt;= rf.lastLogIndex() { go func(peer int) { rf.replicateCh[peer] \u0026lt;- info }(i) } } } Broadcast 存在两种行为，一种为需要立即发送 RPC 维持权力的心跳，另一种则是不那么紧急的 replicate 请求。heartbeatTimer 到期时，立即发送心跳；上层传入新 entry 时，则发送不紧急的 replicate 请求。\n需要立即发送心跳时，直接并行地调用 replicate 函数。\nfunc (rf *Raft) replicate(peer int, info replicateInfo) { rf.rlock(\u0026#34;replicate\u0026#34;) if rf.nextIndex[peer] \u0026gt; rf.lastIncludedIndex { // nextIndex is located in log args := AppendEntriesArgs{ Term: info.term, LeaderId: rf.me, PrevLogIndex: rf.nextIndex[peer] - 1, PrevLogTerm: rf.entry(rf.nextIndex[peer] - 1).Term, LeaderCommit: info.leaderCommit, } reply := AppendEntriesReply{} if rf.nextIndex[peer] \u0026lt;= rf.lastLogIndex() { args.Entries = rf.log[rf.logIndex(rf.nextIndex[peer]):] } rf.runlock(\u0026#34;replicate\u0026#34;) rf.doAppendEntries(peer, \u0026amp;args, \u0026amp;reply) } else { // nextIndex is located in snapshot args := InstallSnapshotArgs{ Term: info.term, LeaderId: rf.me, LastIncludedIndex: rf.lastIncludedIndex, LastIncludedTerm: rf.lastIncludedTerm, Data: rf.snapshot, } reply := InstallSnapshotReply{} rf.runlock(\u0026#34;replicate\u0026#34;) rf.doInstallSnapshot(peer, \u0026amp;args, \u0026amp;reply) } } 可以看到，replicate 也存在两种行为。当需要同步的 entry 位于 log 中时，发送 AppendEntries RPC 即可；当 Follower 过于落后，需要同步的 entry 位于 snapshot 中时，则发送 InstallSnapshot RPC。\n当上层调用 Start() 触发 Broadcast 时，则向 rf.replicateCh[peer] 发送信号，通过常驻在后台的 n-1 个 replicator 协程进行同步。\nfunc (rf *Raft) replicator(peer int) { doneCh := rf.register(fmt.Sprintf(\u0026#34;replicator%d\u0026#34;, peer)) defer rf.deregister(fmt.Sprintf(\u0026#34;replicator%d\u0026#34;, peer)) for { select { case info := \u0026lt;-rf.replicateCh[peer]: replicateDoneCh := make(chan struct{}) go func() { // ignore redundant replicating request for { select { case \u0026lt;-rf.replicateCh[peer]: case \u0026lt;-replicateDoneCh: return } } }() rf.replicate(peer, info) // blocked by RPC replicateDoneCh \u0026lt;- struct{}{} case \u0026lt;-doneCh: return } } } replicator 接收到来自 rf.replicateCh[peer] 的信号后，会调用 replicate 进行一次同步。replicate 方法是阻塞的，会等待 RPC 返回 reply 后才会返回。在调用 RPC 前，replicator 会起一监听 goroutine，监听并抛弃此后重复的 replicate 请求。并在 RPC 处理完成后关闭这个 goroutine。因此，在上层短期连续调用多次 Start() 方法并调用 rf.broadcast(fasle) 时，若此前的 RPC 还没有返回，则这次的 Broadcast 请求会被抛弃，不再发送 RPC。这样做避免了短期内发送大量包含重复 entry 的 RPC，节省了带宽。\n在此前的实现中，短期连续调用 Start() 时，仍会多次发送 RPC。这里进行了更正。\nSummary 到这里，6.824 Lab2 的所有部分全部实现。实现和 debug 时间加起来大概花了10天左右，其余的时间就在写写记录，摸摸鱼。整体做下来还是成就感满满的。体感上最大的困难在于日复一日地对着上万行的日志找出难以察觉的错误，以及努力复现那些概率极低的边界情况。debug 时间还是太长了，稍微有点消磨斗志，到最后也不知道什么时候是个头。我在千次测试全部 pass 之后就没有再进行更多的测试了，希望我写的这个简陋的 Raft 在后续 lab 中不会出什么岔子。\n继续前进吧。\n","permalink":"http://localhost:1313/posts/mit6.824-lab2-raft/","summary":"趁着暑假有空，把鸽了很久的 MIT6.824 做一下。Lab1 是实现一个 Map-Reduce，因为和 Raft 主线关系不大（因为懒），就略过了。另外，这次尝试实现一个 part 就来记录相关的内容，以免在全部实现后忘记部分细节（以免之后太懒不想写）。因此，不同 part 的代码会变化，请以最终版本的代码为准（但保证每一 part 的代码可以正常通过绝大部分相应的测试）。同时，在写下某一 part 的记录时，我对 Raft 的整体把握也难免有所不足。\nResources Course\u0026rsquo;s Page 课程主页 Students\u0026rsquo; Guide to Raft 一篇引导博客 Debugging by Pretty Printing debug 技巧，强烈推荐阅读和运用 Raft Q\u0026amp;A 关于 Raft 的一些 Q\u0026amp;A Raft Visualization Raft 动画演示 In Search of an Understandable Consensus Algorithm Raft 论文 Lab2A Raft Leader Election Lab2A 实现时间为6.22~6.24。\nLab2A 主要实现 Raft 的选主过程，包括选举出 Leader 和 Leader 通过心跳维持身份。\nDesign 首先是选主过程的状态机模型：\n接下来是 Raft 论文中最为重要的 Figure 2:","title":"MIT6.824 Lab2 Raft"},{"content":"chrono库主要包含三种类型的类：时间间隔duration、时钟clocks、时间点time point\n1.duration 用来记录时间长度，可以表示几秒、几分钟、几个小时的时间间隔\n// duration的定义，定义于头文件 \u0026lt;chrono\u0026gt; template\u0026lt; class Rep, class Period = std::ratio\u0026lt;1\u0026gt; \u0026gt; class duration; //表示Rep个Period，一个period是一个ratio类，默认为1s // ratio的定义，定义于头文件 \u0026lt;ratio\u0026gt; template\u0026lt; std::intmax_t Num, std::intmax_t Denom = 1 \u0026gt; class ratio; // 代表 Num / Denom 秒，分母默认为1，ratio\u0026lt;2\u0026gt;代表一个时钟周期是2秒 为了方便使用，在标准库中定义了一些常用的时间间隔,定义如下\n纳秒：using std::chrono::nanoseconds = duration\u0026lt;Rep*/*Rep至少 64 位的有符号整数类型*/*, std::nano\u0026gt;; std::nano 为 ratio\u0026lt;1,10e9\u0026gt; 微秒：std::chrono::microseconds\tduration\u0026lt;Rep*/*至少 55 位的有符号整数类型*/*, std::micro\u0026gt; 毫秒：std::chrono::milliseconds\tduration\u0026lt;Rep*/*至少 45 位的有符号整数类型*/*, std::milli\u0026gt; 秒： std::chrono::seconds\tduration\u0026lt;Rep*/*至少 35 位的有符号整数类型*/*\u0026gt; 分钟：std::chrono::minutes\tduration\u0026lt;Rep*/*至少 29 位的有符号整数类型*/*, std::ratio\u0026lt;60\u0026gt;\u0026gt; std::chrono::minutes m(1);//表示1m 小时：std::chrono::hours\tduration\u0026lt;Rep*/*至少 23 位的有符号整数类型*/*, std::ratio\u0026lt;3600\u0026gt;\u0026gt; 构造函数\n// 1. 拷贝构造函数 duration( const duration\u0026amp; ) = default; // 2. 通过指定时钟周期的类型来构造对象 template\u0026lt; class Rep2 \u0026gt; constexpr explicit duration( const Rep2\u0026amp; r ); // 3. 通过指定时钟周期类型，和时钟周期长度来构造对象 template\u0026lt; class Rep2, class Period2 \u0026gt; constexpr duration( const duration\u0026lt;Rep2,Period2\u0026gt;\u0026amp; d ); // 还重载了以下操作符 operator=; operator+; operator-; operator++; operator++(int); operator--; operator--(int); +=,-=,*=,/=,%=; //获取时间间隔的时钟周期个数 constexpr rep count() const; example\nstd::chrono::hour h(2);// h表示2小时的时间间隔对象 std::chrono::millisecond ms{3};// ms表示3毫秒 std::chrono::duration\u0026lt;int,ratio\u0026lt;60\u0026gt;\u0026gt; ten_m(3); // 3个60秒 std::chrono::duration\u0026lt;double,ratio\u0026lt;1,1000\u0026gt;\u0026gt; ms_(5.5); // 5.5个1ms，也计是5.5ms std::chrono::minute t1(1); std::chrono::second t2(20); std::chrono::second t3 = t1 - t2;//1m - 30s = 30s,t3为30s duration的加减运算有一定的规则，当两个duration时钟周期不相同的时候，会先统一成一种时钟，然后再进行算术运算，统一的规则如下：假设有ratio\u0026lt;x1,y1\u0026gt; 和 ratio\u0026lt;x2,y2\u0026gt;两个时钟周期，首先需要求出x1，x2的最大公约数X，然后求出y1，y2的最小公倍数Y，统一之后的时钟周期ratio为ratio\u0026lt;X,Y\u0026gt;。分子求公约，分母求公倍。因为是x1 / y1 - x2 / y2,就通分呗，化为 X/Y,x1/y1可以表示为多少个 X/Y， x2 / y2同理。\nratio\u0026lt;9, 7\u0026gt;和ratio\u0026lt;6, 5\u0026gt;，统一之后的时钟周期ratio\u0026lt;3, 35\u0026gt;，一个ratio\u0026lt;9, 7\u0026gt;就表示为15个ratio\u0026lt;3, 35\u0026gt;，而ratio\u0026lt;6, 5\u0026gt;可表示为14个ratio\u0026lt;3, 35\u0026gt;。单位就统一了。\n2.时间点 time point 一个表示时间点的类，定义如下\n该类通常配合clock一起使用\n// 定义于头文件 \u0026lt;chrono\u0026gt; template\u0026lt; class Clock, class Duration = typename Clock::duration \u0026gt; class time_point; // Clock：此时间点time_point在此时钟Clock上计量 // 用于计量从纪元起时间的 std::chrono::duration 类型，表示从clock时间持续duration段时间的时间点 // 构造函数 // 1. 构造一个以新纪元(epoch，即：1970.1.1)作为值的对象，需要和时钟类一起使用，不能单独使用该无参构造函数 time_point(); // 2. 构造一个对象，表示一个时间点，这个时间点为从epoch开始持续d这么一个时间间隔，需要和时钟类一起使用，不能单独使用该构造函数 explicit time_point( const duration\u0026amp; d ); // 3. 拷贝构造函数，构造与t相同时间点的对象，使用的时候需要指定模板参数 template\u0026lt; class Duration2 \u0026gt; time_point( const time_point\u0026lt;Clock,Duration2\u0026gt;\u0026amp; t ); //用来获得1970年1月1日到time_point对象中记录的时间点经过的时间间隔（duration），函数原型如下： duration time_since_epoch() const; // 此外还有很多重载operator 3.时钟Clock chrono库中提供了获取当前的系统时间的时钟类，包含的时钟一共有三种：\nsystem_clock：系统的时钟，系统的时钟可以修改，甚至可以网络对时，因此使用系统时间计算时间差可能不准。 steady_clock：是固定的时钟，相当于秒表。开始计时后，时间只会增长并且不能修改，适合用于记录程序耗时 high_resolution_clock：和时钟类 steady_clock 是等价的，精度更高（是它的别名）。\n每个时钟类内部成员有time_point、duration、Rep、Period等信息，基于这些信息来获取当前时间，以及实现time_t和time_point之间的相互转换。\n在使用chrono提供的时钟类的时候，不需要创建类对象，直接调用类的静态方法就可以得到想要的时间了。\n3.1system_clock 定义\nstruct system_clock { // using 定义别名 using rep = long long; using period = ratio\u0026lt;1, 10\u0026#39;000\u0026#39;000\u0026gt;; // 100 纳秒 using duration = chrono::duration\u0026lt;rep, period\u0026gt;;//时间间隔为rep*period 100纳秒 using time_point = chrono::time_point\u0026lt;system_clock\u0026gt;; //时间点通过系统时钟做了初始化 static constexpr bool is_steady = false; _NODISCARD static time_point now() noexcept { // get current time，返回表示当前时间的时间点。 return time_point(duration(_Xtime_get_ticks())); } _NODISCARD static __time64_t to_time_t(const time_point\u0026amp; _Time) noexcept { // convert to __time64_t，将 time_point 时间点类型转换为 std::time_t 类型 return duration_cast\u0026lt;seconds\u0026gt;(_Time.time_since_epoch()).count(); } _NODISCARD static time_point from_time_t(__time64_t _Tm) noexcept { // convert from __time64_t，将 std::time_t 类型转换为 time_point 时间点类型 return time_point{seconds{_Tm}}; } }; example\n#include \u0026lt;chrono\u0026gt; #include \u0026lt;iostream\u0026gt; int main() { // 新纪元1970.1.1时间 std::chrono::system_clock::time_point epoch; std::chrono::duration\u0026lt;int,std::ratio\u0026lt;60 * 60 * 24\u0026gt;\u0026gt; day(1); // 新纪元1970.1.1时间 + 1天 std::chrono::system_clock::time_point ppt(day); using day_t = std::chrono::duration\u0026lt;int, std::ratio\u0026lt;60 * 60 * 24\u0026gt;\u0026gt;; // 新纪元1970.1.1时间 + 10天 // std::chrono::time_point需要指定模板参数 std::chrono::time_point\u0026lt;std::chrono::system_clock,day_t\u0026gt; t(day_t(10)); // 系统当前时间 // std::chrono::system_clock::time_point = chrono::time_point\u0026lt;system_clock\u0026gt; std::chrono::system_clock::time_point today = std::chrono::system_clock::now(); // 转换为time_t时间类型 time_t tm = std::chrono::system_clock::to_time_t(today); std::cout \u0026lt;\u0026lt; \u0026#34;今天的日期是: \u0026#34; \u0026lt;\u0026lt; ctime(\u0026amp;tm); time_t tm1 = std::chrono::system_clock::to_time_t(today+day); std::cout \u0026lt;\u0026lt; \u0026#34;明天的日期是: \u0026#34; \u0026lt;\u0026lt; ctime(\u0026amp;tm1); time_t tm2 = std::chrono::system_clock::to_time_t(epoch); std::cout \u0026lt;\u0026lt; \u0026#34;新纪元时间: \u0026#34; \u0026lt;\u0026lt; ctime(\u0026amp;tm2); time_t tm3 = std::chrono::system_clock::to_time_t(ppt); std::cout \u0026lt;\u0026lt; \u0026#34;新纪元时间+1天: \u0026#34; \u0026lt;\u0026lt; ctime(\u0026amp;tm3); time_t tm4 = std::chrono::system_clock::to_time_t(t); std::cout \u0026lt;\u0026lt; \u0026#34;新纪元时间+10天: \u0026#34; \u0026lt;\u0026lt; ctime(\u0026amp;tm4); } 3.2 steady_clock 想要获取程序耗时的时长，可以使用syetem_clock，因为这个时间可以跟随系统的设置发生变化。\nsteady_clock相当于秒表，只要启动就会进行时间的累加，并且不能被修改，\n定义\nstruct steady_clock { // wraps QueryPerformanceCounter using rep = long long;// 通过long long整形来记录时钟周期的个数 using period = nano;// 时钟周期为1纳秒 using duration = nanoseconds; // 时间间隔为1ns using time_point = chrono::time_point\u0026lt;steady_clock\u0026gt;; // 通过steady_clock对时间点进行初始化 static constexpr bool is_steady = true; // get current time _NODISCARD static time_point now() noexcept { // doesn\u0026#39;t change after system boot const long long _Freq = _Query_perf_frequency(); const long long _Ctr = _Query_perf_counter(); static_assert(period::num == 1, \u0026#34;This assumes period::num == 1.\u0026#34;); const long long _Whole = (_Ctr / _Freq) * period::den; const long long _Part = (_Ctr % _Freq) * period::den / _Freq; return time_point(duration(_Whole + _Part)); } }; example\n#include \u0026lt;chrono\u0026gt; #include \u0026lt;iostream\u0026gt; int main() { // 获取开始时间点 std::chrono::steady_clock::time_point start = std::chrono::steady_clock::now(); // 需要获取程序耗时的代码段 std::cout \u0026lt;\u0026lt; \u0026#34;print 1000 stars ....\u0026#34; \u0026lt;\u0026lt; std::endl; for (int i = 0; i \u0026lt; 1000; ++i) { std::cout \u0026lt;\u0026lt; \u0026#34;*\u0026#34;; } std::cout \u0026lt;\u0026lt; std::endl; // 获取结束时间点 std::chrono::steady_clock::time_point last = std::chrono::steady_clock::now(); // 计算差值，是一个时间间隔 auto dt = last - start; // dt.count()返回时间间隔中有多少个时钟周期 std::cout \u0026lt;\u0026lt; \u0026#34;总共耗时: \u0026#34; \u0026lt;\u0026lt; dt.count() \u0026lt;\u0026lt; \u0026#34;纳秒\u0026#34; \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; \u0026#34;总共耗时: \u0026#34; \u0026lt;\u0026lt; dt.count() / (double)1000000 \u0026lt;\u0026lt; \u0026#34;ms\u0026#34; \u0026lt;\u0026lt; std::endl; } 3.3 high_resolution_clock high_resolution_clock提供的时钟精度比system_clock要高，它也是不可以修改的。在底层源码中，这个类其实是steady_clock类的别名\nusing high_resolution_clock = steady_clock; 因此使用方式和steady_clock是一样的\n4.转换函数 4.1duration_cast duration_cast是chrono库提供的一个模板函数，这个函数不属于duration类。通过这个函数可以对duration类对象内部的时钟周期Period，和周期次数的类型Rep进行修改。\n定义如下：\ntemplate \u0026lt;class ToDuration, class Rep, class Period\u0026gt; constexpr ToDuration duration_cast (const duration\u0026lt;Rep,Period\u0026gt;\u0026amp; dtn); // 返回目标类型ToDuration的时间间隔 注意：\n如果是对时钟周期进行转换：源时钟周期必须能够整除目的时钟周期（比如：小时到分钟）。 如果是对时钟周期次数的类型进行转换：低等类型默认可以向高等类型进行转换（比如：int 转 double）。 如果时钟周期和时钟周期次数类型都变了，根据第二点进行推导（也就是看时间周期次数类型）。 以上条件都不满足，那么就需要使用 duration_cast 进行显示转换，比如小的时钟周期转大的时钟周期。\nexample\n#include \u0026lt;chrono\u0026gt; #include \u0026lt;iostream\u0026gt; void f(){ std::cout \u0026lt;\u0026lt; \u0026#34;print 1000 stars ....\u0026#34; \u0026lt;\u0026lt; std::endl; for (int i = 0; i \u0026lt; 1000; ++i) { std::cout \u0026lt;\u0026lt; \u0026#34;*\u0026#34;; } std::cout \u0026lt;\u0026lt; std::endl; } int main() { // 获取开始时间点 std::chrono::steady_clock::time_point start = std::chrono::steady_clock::now(); // 需要获取程序耗时的代码段 f(); // 获取结束时间点 std::chrono::steady_clock::time_point last = std::chrono::steady_clock::now(); // 计算差值，是一个为多少ns的时间间隔 auto dt = last - start; // dt.count()返回时间间隔中有多少个时钟周期 std::cout \u0026lt;\u0026lt; \u0026#34;总共耗时: \u0026#34; \u0026lt;\u0026lt; dt.count() \u0026lt;\u0026lt; \u0026#34;纳秒\u0026#34; \u0026lt;\u0026lt; std::endl; // 转换 // 整数时长：时钟周期纳秒转毫秒，小转大，并且是int转int，所以不能直接转，要求 duration_cast auto int_ms = std::chrono::duration_cast\u0026lt;std::chrono::milliseconds\u0026gt;(dt); // 小数时长：int转double，符合第二点，虽然是小转大但不要求 duration_cast std::chrono::duration\u0026lt;double, std::ratio\u0026lt;1, 1000\u0026gt;\u0026gt; fp_ms = dt; std::cout \u0026lt;\u0026lt; \u0026#34;f() took \u0026#34; \u0026lt;\u0026lt; fp_ms.count() \u0026lt;\u0026lt; \u0026#34; ms, \u0026#34; \u0026lt;\u0026lt; \u0026#34;or \u0026#34; \u0026lt;\u0026lt; int_ms.count() \u0026lt;\u0026lt; \u0026#34; whole milliseconds\\n\u0026#34;\u0026lt;\u0026lt; std::endl; } 4.2 time_point_cast time_point_cast也是chrono库提供的一个模板函数，这个函数不属于time_point类。函数的作用是对时间点进行转换，因为不同的时间点对象内部的时钟周期Period，和周期次数的类型Rep可能也是不同的，一般情况下它们之间可以进行隐式类型转换，也可以通过该函数显示的进行转换。\n定义：\ntemplate \u0026lt;class ToDuration, class Clock, class Duration\u0026gt; time_point\u0026lt;Clock, ToDuration\u0026gt; time_point_cast(const time_point\u0026lt;Clock, Duration\u0026gt; \u0026amp;t); example\n#include \u0026lt;chrono\u0026gt; #include \u0026lt;iostream\u0026gt; // 定义别名 using Clock = std::chrono::high_resolution_clock; using Ms = std::chrono::milliseconds; using Sec = std::chrono::seconds; template\u0026lt;class Duration\u0026gt; using TimePoint = std::chrono::time_point\u0026lt;Clock, Duration\u0026gt;;//clock类型为high_resolution_clock void print_ms(const TimePoint\u0026lt;Ms\u0026gt;\u0026amp; time_point) { std::cout \u0026lt;\u0026lt; time_point.time_since_epoch().count() \u0026lt;\u0026lt; \u0026#34; ms\\n\u0026#34;; } int main() { TimePoint\u0026lt;Sec\u0026gt; time_point_sec(Sec(6)); // 无精度损失, 可以进行隐式类型转换 TimePoint\u0026lt;Ms\u0026gt; time_point_ms(time_point_sec); print_ms(time_point_ms); // 6000 ms time_point_ms = TimePoint\u0026lt;Ms\u0026gt;(Ms(6789)); // error，会损失精度，不允许进行隐式的类型转换 TimePoint\u0026lt;Sec\u0026gt; sec(time_point_ms); // 显示类型转换,会损失精度。6789 truncated to 6000 time_point_sec = std::chrono::time_point_cast\u0026lt;Sec\u0026gt;(time_point_ms); print_ms(time_point_sec); // 6000 ms } ","permalink":"http://localhost:1313/posts/chrono/","summary":"chrono库主要包含三种类型的类：时间间隔duration、时钟clocks、时间点time point\n1.duration 用来记录时间长度，可以表示几秒、几分钟、几个小时的时间间隔\n// duration的定义，定义于头文件 \u0026lt;chrono\u0026gt; template\u0026lt; class Rep, class Period = std::ratio\u0026lt;1\u0026gt; \u0026gt; class duration; //表示Rep个Period，一个period是一个ratio类，默认为1s // ratio的定义，定义于头文件 \u0026lt;ratio\u0026gt; template\u0026lt; std::intmax_t Num, std::intmax_t Denom = 1 \u0026gt; class ratio; // 代表 Num / Denom 秒，分母默认为1，ratio\u0026lt;2\u0026gt;代表一个时钟周期是2秒 为了方便使用，在标准库中定义了一些常用的时间间隔,定义如下\n纳秒：using std::chrono::nanoseconds = duration\u0026lt;Rep*/*Rep至少 64 位的有符号整数类型*/*, std::nano\u0026gt;; std::nano 为 ratio\u0026lt;1,10e9\u0026gt; 微秒：std::chrono::microseconds\tduration\u0026lt;Rep*/*至少 55 位的有符号整数类型*/*, std::micro\u0026gt; 毫秒：std::chrono::milliseconds\tduration\u0026lt;Rep*/*至少 45 位的有符号整数类型*/*, std::milli\u0026gt; 秒： std::chrono::seconds\tduration\u0026lt;Rep*/*至少 35 位的有符号整数类型*/*\u0026gt; 分钟：std::chrono::minutes\tduration\u0026lt;Rep*/*至少 29 位的有符号整数类型*/*, std::ratio\u0026lt;60\u0026gt;\u0026gt; std::chrono::minutes m(1);//表示1m 小时：std::chrono::hours\tduration\u0026lt;Rep*/*至少 23 位的有符号整数类型*/*, std::ratio\u0026lt;3600\u0026gt;\u0026gt; 构造函数","title":"chrono库的使用"},{"content":"Git Local 1.Check the Version $ git --version 2.Configure Git 我们通常会将 git 配置为我们在 github 上注册的用户名/电子邮件/密码。global 关键字会为系统中的每个版本库设置配置。我们可以去掉 global 关键字，只对当前仓库进行配置。\n# 配置 $ git config --global user.name \u0026#34;Dueplay\u0026#34; $ git config --global user.email \u0026#34;2289535823@qq.com\u0026#34; $ git config --global user.password \u0026#34;your passwd\u0026#34; # 查看配置 $ git config user.name Dueplay $ git config user.email 2289535823@qq.com $ git config user.password hello123 3. Initialize Git 创建一个新的 repo，并如下初始化 git 以跟踪一个文件夹：\n$ mkdir myproject \u0026amp;\u0026amp; cd myproject $ git init 在myproject有个隐藏文件夹 .git ，这是 git 为我们存储所有跟踪信息的地方。\n4. Check Status $ git status On branch master No commits yet Untracked files: (use \u0026#34;git add \u0026lt;file\u0026gt;...\u0026#34; to include in what will be committed) index.html nothing added to commit but untracked files present (use \u0026#34;git add\u0026#34; to track) 5.暂存新的改变到工作区 在Git中，\u0026ldquo;暂存\u0026rdquo;（Staging）指的是将工作目录中的修改或新文件添加到Git的索引中（也称为暂存区），以便随后commit这些更改。暂存的主要目的是允许选择性地commit文件而不是全部文件的修改，通过使用暂存区，可以控制哪些修改被包含在下次commit中。\n在 git 中，每个文件都可能处于两个阶段中的一个：\n已跟踪\u0026ndash;git 会主动监控该文件的任何更改，并将其作为 repo 的一部分 未跟踪\u0026ndash;虽然文件存在，但 git 会 \u0026ldquo;忽略 \u0026ldquo;它的存在和变化\n# $ git add index.html # $ git restore --staged [filename] 6.Commit Changes $ git commit -m \u0026#34;First release of Git Helloworld Project\u0026#34; 可以跳过暂存阶段，一步到位地comiit变更。不建议这样做\ngit commit -a -m [commit message] git tag 用于给 Git 中的commit打上标签（tag），这些标签通常用于标识某个特殊的commit，比如软件版本发布。标签提供了一个稳定的引用，使得方便地回溯到某个特定的commit，常用的命令选项有\n• -a：用于创建一个带注释的标签 • -m：指定标签的注释信息 • -l：列出已有的标签 7. Commit History $ git log # 精简log $ git log --oneline 8.Help git有这么多的标志选项和命令\ngit help \u0026ndash;all 会显示所有可用的 git 命令。\ngit [command] -help 会显示该命令可设置的所有标志，而 git [command] \u0026ndash;help 则会打开该命令的手册。(单\u0026ndash;和双\u0026ndash;）\n9.Git Branch 创建新分支\n$ git branch hello-world-image 查看这个仓库所有可用的分支\n$ git branch hello-world-image * master 如果我们切换master主分支，新快照就不是主分支的一部分。我们在另一个分支中的新更改不会影响主分支。\n通过 checkout 命令从主分支转移到新创建的分支：\n$ git checkout hello-world-image Switched to branch \u0026#39;hello-world-image\u0026#39; 创建和切换到新分支可一步完成\n$ git checkout -b hello-world-image 删除分支\ngit branch -d \u0026lt;branch-name\u0026gt; 如果分支有未合并的更改，Git会拒绝删除，并提醒先合并或解决冲突。当然也可以强制删除分支，包括未合并的修改。\ngit branch -D \u0026lt;branch-name\u0026gt; 注意，无法删除主分支、当前所在分支或非分支的内容\n10.Merge Branch git merge 是 Git 中用于合并不同分支的命令。将两个或多个分支的历史和更改集成到一个新的commit中的过程。合并操作通常用于将一个分支的变更合并到另一个分支，以确保这两个分支包含了相同的代码更改。假设我们对 hello-world-image 分支中的新开发非常满意，决定将其合并回主分支。注意master上是没有新提交的。\n既然要合并到主分支，我们首先要确保自己是站在主分支上的：\n$ git checkout master Switched to branch \u0026#39;master\u0026#39; # 使用merge合并分支，将指定分支中的更改合并到当前分支master $ git merge hello-world-image Updating 2daa287..c31a2c0 Fast-forward img_hello_world.png | Bin 0 -\u0026gt; 48630 bytes 1 file changed, 0 insertions(+), 0 deletions(-) create mode 100644 img_hello_world.png 我们看到 git 说这次合并是 \u0026ldquo;Fast-forward\u0026rdquo;，因为它没有发现这两个分支有任何冲突，合并进行得很顺利。\n然而，生活并不总是一帆风顺。有时会发生合并冲突。\n假设现在我们回到 hello-world-image，在 index.html 中添加一行新内容。同时，我们在主分支中删除 index.html 中的一行，并在两个分支中都提交更改。\n现在，当我们尝试将此提交与主分支合并时，这种叫做Three-way Merge，冲突就会发生：\n$ git merge hello-world-image Auto-merging index.html CONFLICT (content): Merge conflict in index.html Automatic merge failed; fix conflicts and then commit the result. 我们可以打开 index.html，看看 git 对冲突发生的原因和方式做了哪些标记：\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;Hello World!\u0026lt;/title\u0026gt; \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;bluestyle.css\u0026#34;\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;Hello world!\u0026lt;/h1\u0026gt; \u0026lt;p\u0026gt;This is the first file in my new Git Repo.\u0026lt;/p\u0026gt; \u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt; HEAD ======= \u0026lt;p\u0026gt;A old line in our file!\u0026lt;/p\u0026gt; \u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt; hello-world-image \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 我们可以选择保留 \u0026laquo;\u0026laquo;\u0026laquo;\u0026lt; HEAD 至 ======= 之间的所有内容，或者保留 ======= 至 \u0026raquo;\u0026raquo;\u0026raquo;\u0026gt; hello-world-image 之间的所有内容。\n在对 index.html 中的冲突部分做出选择后，我们将文件暂存并提交，以结束这次合并操作。\n$ git add index.html $ git commit -m \u0026#34;after fix the conflict\u0026#34; [master bdfc2b1] after fix the conflict 这样就完成了两个冲突分支的合并，通过 -d 标志，我们可以删除合并后的分支，以保持工作区的整洁：\n$ git branch -d hello-world-images Deleted branch hello-world-image (was 9e7a8ee). --no-ff 选项用于强制创建一个新的合并commit，即使可以执行快速前进合并，这样可以保留每个分支的独立历史\ngit merge --no-ff \u0026lt;branch-name\u0026gt; 要执行Fast-forward 合并：\ngit merge --ff \u0026lt;branch-name\u0026gt; 11.Revert revert 命令用于删除之前的提交，并将删除内容变成新的提交，而不修改日志。\n首先，我们要检查哪个提交是我们想要返回的：（使用 \u0026ndash;oneline 关键字显示简洁的 git 日志）\n$ git log --oneline bdfc2b1 (HEAD -\u0026gt; master) fix conflicts: 9e7a8ee add a line 17fd1f5 remove a line 5ec2abb a small change c31a2c0 Added image to Hello World 2daa287 Another changes 48d7a59 First release of Git Helloworld Project $ git revert 9e7a8ee --no-edit 12.Reset 用于将分支的 HEAD 指针和工作目录重置到指定的commit，可以选择是否保留未commit的更改，reset 会将 repo 全部移回之前的提交，会删除该提交和最新版本之间的所有更改。\n现在，假设我们添加了两个文件 file1.txt、file2.txt 和 file3.txt，并将它们包含在两个不同的提交中：\n$ touch file1.txt file2.txt file3.txt $ git add file1.txt \u0026amp;\u0026amp; git commit -m \u0026#34;Add file1\u0026#34; $ git add file2.txt \u0026amp;\u0026amp; git commit -m \u0026#34;Add file2\u0026#34; $ git add file3.txt \u0026amp;\u0026amp; git commit -m \u0026#34;Add file3\u0026#34; $ git log --oneline 327ae72 (HEAD -\u0026gt; master) Add file3 8b159b4 Add file2 cf9f3bf Add file1 ...(more)... 现在我们不需要文件 2 和文件 3，但希望保留文件 1。我们可以分别revert最近的 2 次提交，或者reset回添加 file1 的提交。\n$ git reset cf9f3bf $ git log cf9f3bf (HEAD -\u0026gt; master) Add file1 ...(more)... 警告：通常情况下，乱动版本库的提交历史是很危险的，尤其是在与他人合作时。\n如果我们知道 git 的提交哈希值，就有办法撤销reset。在前面的例子中，即使我们reset回 file1 的提交，我们仍然可以返回，因为我们知道上次添加文件 3 的提交哈希值是 327ae72。\n$ git reset 327ae72 $ git log 327ae72 (HEAD -\u0026gt; master) Add file3 8b159b4 Add file2 cf9f3bf Add file1 ...(more)... reset其实有三个主要的选项：--soft、--mixed 和 --hard，对应于不同的重置模式\ngit reset \u0026ndash;soft ：回退 HEAD 指针到指定的commit，但保留所有的更改。即不会修改工作目录或暂存区，所有的更改都被标记为未commit的更改，可以直接重新commit\ngit reset \u0026ndash;mixed ：默认的reset模式。回退 HEAD 指针到指定的commit，并且重置暂存区，但保留工作目录中的更改。即未commit的更改会保留在工作目录，但不会被标记为暂存区的更改，需要重新add并commit\ngit reset \u0026ndash;hard ：最彻底的reset模式。回退 HEAD 指针到指定的commit，重置暂存区，并删除工作目录中未commit的更改，慎用这个玩意，因为它会永久性地删除未commit的更改\n13.Amend commit \u0026ndash;amend 可用于修改最近的提交，并交换更改其提交信息。\n它将暂存区域的改动与最新提交结合起来，并从中创建一个新提交，取代最新提交。\n例如，我们对 README.md 稍作改动，想要提交，但在提交信息中输入了不少错别字。\n$ git add README.md $ git commit -m \u0026#34;Upated: RMEADE.md (ugly typos)\u0026#34; $ git log --oneline b0dfb07 (HEAD -\u0026gt; master) Upated: RMEADE.md (ugly typos) 327ae72 Add file3 ...(more)... 我们的错别字让 git 历史看起来很糟糕。使用amend修改提交语句\n$ git commit --amend -m \u0026#34;Update: README.md (beautiful)\u0026#34; $ git log --oneline d4bf700 (HEAD -\u0026gt; master) Update: README.md (beautiful) 327ae72 Add file3 ...(more)... 14.stash git stash 是一个用于保存当前工作目录和暂存区的临时状态的命令。允许在切换分支、应用补丁或执行其他操作之前，将当前的修改存储起来，以便稍后重新应用，非常非常实用，常见的使用场景如\n\\1. 保存当前工作目录和暂存区的状态 git stash save \u0026#34;Work in progress\u0026#34; \\2. 切换到其他分支进行操作 git checkout other-branch \\3. 在其他分支进行操作 # 在 other-branch 上进行一些操作 \\4. 切回原始分支并恢复 stash git checkout original-branch git stash apply 或者，如果想同时删除 stash，可以使用：\ngit stash pop 此外，还有一些其他常用命令\ngit stash list # 显示 Git 存储库中所有存储的列表，以及有关每个存储的一些信息 git stash branch \u0026lt;branch-name\u0026gt; # 将更改应用到不同的分支 2.Git Remote 首先需要创建一个新的 github 仓库，然后上传我们目前正在开发的本地仓库，以便同步。\n为了方便起见，我们将远程仓库也命名为 myproject。\n1.与远程仓库同步 在本地项目仓库中，我们需要添加一个远程跟踪链接：\ngit remote add origin https://github.com/Dueplay/myproject.git 通过 git remote -v 检查是否与 github 上的 repo 远程同步\n$ git remote -v origin\thttps://github.com/[username]/myproject.git (fetch) origin\thttps://github.com/[username]/myproject.git (push) 然后，我们就可以将所有本地开发的内容推送到远程版本库：\ngit push：将本地更改推送到远程仓库的命令，完整格式 ：git push \u0026lt;remote\u0026gt; 是远程仓库的名称，通常是 \u0026ldquo;origin\u0026rdquo; 或其他你设置的别名。 \u0026lt;branch\u0026gt; 是本地分支的名称，它将被推送到远程仓库的同名分支。 \u0026ndash;set-upstream（或者简写为 -u）: 这部分告诉Git为本地分支与远程分支建立关联关系。关联关系的作用是在将来的推送或拉取操作中，Git会自动识别要使用的远程分支。设置关联关系后，你就可以使用git push和git pull而不需要每次都指定远程仓库和分支,只需输入 git push，Git 将自动使用关联的远程和分支。\n$ git push --set-upstream origin master Enumerating objects: 34, done. Counting objects: 100% (34/34), done. Delta compression using up to 8 threads Compressing objects: 100% (33/33), done. Writing objects: 100% (34/34), 49.37 KiB | 12.34 MiB/s, done. Total 34 (delta 17), reused 0 (delta 0), pack-reused 0 remote: Resolving deltas: 100% (17/17), done. To https://github.com/[username]/myproject.git * [new branch] master -\u0026gt; master Branch \u0026#39;master\u0026#39; set up to track remote branch \u0026#39;master\u0026#39; from \u0026#39;origin\u0026#39;. /*你的本地 master 分支现在已设置为跟踪远程仓库 \u0026#39;origin\u0026#39; 上的远程 master 分支*/ 现在，我们已将本地所有开发成果上传到远程版本库\n2.拉取远程仓库新东西到本地 现在，假设远程 repo 上出现了新情况。在此，我们将模拟这种情况，直接从 github 上的 README.md 中移除一行并提交。\n我们如何更新本地版本库以包含这些更改呢？\n我们有两个选择：\nfetch + merge pull 从第一个组合开始。我们首先需要使用 fetch 从远程下载所有新更改\n$ git fetch origin remote: Enumerating objects: 5, done. remote: Counting objects: 100% (5/5), done. remote: Compressing objects: 100% (1/1), done. remote: Total 3 (delta 2), reused 2 (delta 2), pack-reused 0 Unpacking objects: 100% (3/3), 689 bytes | 344.00 KiB/s, done. From https://github.com/[username]/myproject d4bf700..6d4ad42 master -\u0026gt; origin/master # 现在我们有了来自远程的新改动，可以检查一下 git 状态了： $ git status On branch master Your branch is behind \u0026#39;origin/master\u0026#39; by 1 commit, and can be fast-forwarded. (use \u0026#34;git pull\u0026#34; to update your local branch) 我们看到本地仓库比上游主仓库晚提交了 1 次，即 README.md 上的一行改动。我们可以使用 git diff 命令仔细检查具体的差异\n$ git diff origin/master diff --git a/README.md b/README.md index f3fa9a9..cf28200 100644 --- a/README.md +++ b/README.md @@ -3,3 +3,5 @@ Hello World repository for Git tutorial This is an example repository for the Git tutoial on https://www.w3schools.com This repository is built step by step in the tutorial. + +a new line 合并提交\n$ git merge origin/master Updating d4bf700..6d4ad42 Fast-forward README.md | 2 -- 1 file changed, 2 deletions(-) $ git status On branch master Your branch is up to date with \u0026#39;origin/master\u0026#39;. 现在我们的本地 git 已经是最新的了。\n上述方法可行，但有点繁琐。其实我们可以用 pull 命令一步完成更新，它是 fetch 和 merge 的结合。\n让我们把从远程 github 上的 README.md 中删除的新行添加回去，并尝试把更改拉入本地 git。\n$ git pull origin remote: Enumerating objects: 5, done. remote: Counting objects: 100% (5/5), done. remote: Compressing objects: 100% (3/3), done. remote: Total 3 (delta 2), reused 0 (delta 0), pack-reused 0 Unpacking objects: 100% (3/3), 696 bytes | 232.00 KiB/s, done. From https://github.com/[username]/myproject 6d4ad42..b2bb9ae master -\u0026gt; origin/master Updating 6d4ad42..b2bb9ae Fast-forward README.md | 2 ++ 1 file changed, 2 insertions(+) 可以看到我们已经更新了远程主分支：\n$ git log --oneline b2bb9ae (HEAD -\u0026gt; master, origin/master) Add back a new line from github directly 6d4ad42 Remove the new line README.md GitHub directly d4bf700 Update: README.md (beautiful) 327ae72 Add file3 8b159b4 Add file2 cf9f3bf Add file1 ...(more)... git pull 和 git fetch 都是用于从远程仓库获取更新的 Git 命令，但区别为\ngit fetch origin • 从远程仓库获取更新的信息，但并不自动合并或更新本地工作目录， 只是把远程分支的引用和相关对象（commit、tree等）下载到本地，需要手动合并或者在需要的时候将远程分支的变更整合到本地分支上 git pull origin master • 从远程仓库获取更新的信息，并尝试将本地工作目录自动合并到获取的更新中 • git pull 实际上包含了 git fetch，比如在执行 git fetch 之后，立即执行 git merge 也可以将远程分支的更改合并到当前本地分支 3.推送本地新修改到远程 现在，我们将通过 push 命令为远程仓库做出贡献。\n让我们在 README.md 中再添加一行，然后尝试更新远程版本库。\n$ git commit -a -m \u0026#34;Update readme locally and try push\u0026#34; [master f8986b8] Update readme locally and try push 1 file changed, 1 insertion(+) $ git status On branch master Your branch is ahead of \u0026#39;origin/master\u0026#39; by 1 commit. (use \u0026#34;git push\u0026#34; to publish your local commits) Git 显示我们比远程主分支早提交 1 次。让我们把更改推送到远程仓库。\n$ git push origin 4.Remote Branch Pull 可以通过github图形用户界面直接在远程仓库创建一个新分支。我们从主分支创建了一个名为 secondary 的新分支，并对 README.md 做了一些修改，直接在 github 上提交。\n我们可以将新分支拉到本地 git 并检查它：\n$ git pull remote: Enumerating objects: 5, done. remote: Counting objects: 100% (5/5), done. remote: Compressing objects: 100% (3/3), done. remote: Total 3 (delta 2), reused 0 (delta 0), pack-reused 0 Unpacking objects: 100% (3/3), 697 bytes | 232.00 KiB/s, done. From https://github.com/[username]/myproject * [new branch] secondary -\u0026gt; origin/secondary Already up to date. 我们可以像往常一样通过 git 分支查看新分支。但默认情况下，它只显示本地分支。我们需要使用 -a 标志来查看所有本地和远程分支，或者使用 -r 标志来查看远程分支。\n$ git branch // only local branches * master $ git branch -a * master remotes/origin/master remotes/origin/secondary $ git branch -r origin/master origin/secondary 删除远程仓库中的分支\ngit push origin --delete \u0026lt;branch-name\u0026gt; 5.将本地分支推送到远程 我们也可以将本地新分支的变更推送到远程 repo。\n$ git checkout -b local-new-branch ... (do some changes to README.md) ... $ git commit -a -m \u0026#34;Update from local-new-branch\u0026#34; [local-new-branch 40e9ee3] Update: local-new-branch 1 file changed, 2 insertions(+) $ git push origin local-new-brancch Enumerating objects: 5, done. Counting objects: 100% (5/5), done. Delta compression using up to 8 threads Compressing objects: 100% (3/3), done. Writing objects: 100% (3/3), 334 bytes | 334.00 KiB/s, done. Total 3 (delta 2), reused 0 (delta 0), pack-reused 0 remote: Resolving deltas: 100% (2/2), completed with 2 local objects. remote: remote: Create a pull request for \u0026#39;local-new-branch\u0026#39; on GitHub by visiting: remote: https://github.com/[username]/myproject/pull/new/local-new-branch remote: To https://github.com/[username]/myproject.git * [new branch] local-new-branch -\u0026gt; local-new-branch 现在，如果我们访问 github 远程仓库，就会发现有一个新推送的分支，名为 local-new-branch\n6.Merge Into Master 如上所述，在 github repo 页面上，我们希望将本地-新分支中的更改合并到主分支中。网页上有 \u0026quot; Compare \u0026amp; Pull Request.\u0026ldquo;选项。\n我们可以点击它并创建一个pull request请求。\n因为这是我们自己的 repo，所以我们是 \u0026ldquo;权威\u0026rdquo;，可以直接点击 \u0026ldquo;Merge pull request \u0026ldquo;将更改合并到主分支。\n但在现实生活中，拉取请求通常需要经过代码审查和测试流程，并由合作者验证。如果获得批准，拉取请求才会通过并被合并。\n7.clone and fork $ git clone [the repo url] [the folder path we want to clone into] 8.Git Ignore 我们并不一定希望 git 追踪本地仓库中的每一个文件。可能有一些日志文件、临时文件或个人文件不应该被纳入 git 工作流。\n为了解决这个问题，我们可以在 git 仓库中创建一个 .gitignore 文件，这样 git 就会忽略其中指定的文件。不过，.gitignore 文件本身会被 git 追踪。\n常见的用法包括\ncommand Description blank lines are ignored # something lines start with # is comment and ignored name All name files and folders name/ All folders called name name.file All name.file in repo *.file any file with extension .file !*.file negate any previous ignore on this file 8.remove origin 使用下面命令可将指向仓库的远程 URL 先去除，就能添加其他仓库的地址\ngit remote remove origin git remote add origin https://github.com/xxx ","permalink":"http://localhost:1313/posts/git/","summary":"Git Local 1.Check the Version $ git --version 2.Configure Git 我们通常会将 git 配置为我们在 github 上注册的用户名/电子邮件/密码。global 关键字会为系统中的每个版本库设置配置。我们可以去掉 global 关键字，只对当前仓库进行配置。\n# 配置 $ git config --global user.name \u0026#34;Dueplay\u0026#34; $ git config --global user.email \u0026#34;2289535823@qq.com\u0026#34; $ git config --global user.password \u0026#34;your passwd\u0026#34; # 查看配置 $ git config user.name Dueplay $ git config user.email 2289535823@qq.com $ git config user.password hello123 3. Initialize Git 创建一个新的 repo，并如下初始化 git 以跟踪一个文件夹：\n$ mkdir myproject \u0026amp;\u0026amp; cd myproject $ git init 在myproject有个隐藏文件夹 .","title":"Git Tutorial"},{"content":"ssh方式A主机免密登录B\n1.首先在A主机上执行命令\nssh-keygen -t rsa 会在执行命令的当前用户的家目录下的.ssh中生成公钥和私钥，id_rsa和id_rsa.pub分别存放私钥和公钥。\n2.将公钥加入到B主机的~/.ssh/authorized_keys文件中\nscp方式or手动复制粘贴。\nscp ~/.ssh/id_rsa.pub root@B主机ip:~/ B主机上执行：\ncat ~/id_rsa.pub\u0026gt;\u0026gt;~/.ssh/authorized_keys 3.如果不能登录检查以下注意的点和检查/etc/ssh/sshd_config，确保以下配置打开。\nRSAAuthentication yes PubkeyAuthentication yes AuthorizedKeysFile .ssh/authorized_keys 需要注意的几点： 1、确保A机器私钥文件名是id_rsa，否则会因为识别不到私钥文件而不会执行免密rsa登录；\n2、确保B机器上.ssh/authorized_keys文件的属性是600，否则要使用命令、\nchmod 600 ~/.ssh/authorized_keys 更改属性。 3、authorized_keys存放的目录需要与登录用户对应，比如使用root用户登录，则是在/home/root/.ssh/authorized_keys\n","permalink":"http://localhost:1313/posts/ssh%E6%96%B9%E5%BC%8Fa%E4%B8%BB%E6%9C%BA%E5%85%8D%E5%AF%86%E7%99%BB%E5%BD%95b/","summary":"ssh方式A主机免密登录B\n1.首先在A主机上执行命令\nssh-keygen -t rsa 会在执行命令的当前用户的家目录下的.ssh中生成公钥和私钥，id_rsa和id_rsa.pub分别存放私钥和公钥。\n2.将公钥加入到B主机的~/.ssh/authorized_keys文件中\nscp方式or手动复制粘贴。\nscp ~/.ssh/id_rsa.pub root@B主机ip:~/ B主机上执行：\ncat ~/id_rsa.pub\u0026gt;\u0026gt;~/.ssh/authorized_keys 3.如果不能登录检查以下注意的点和检查/etc/ssh/sshd_config，确保以下配置打开。\nRSAAuthentication yes PubkeyAuthentication yes AuthorizedKeysFile .ssh/authorized_keys 需要注意的几点： 1、确保A机器私钥文件名是id_rsa，否则会因为识别不到私钥文件而不会执行免密rsa登录；\n2、确保B机器上.ssh/authorized_keys文件的属性是600，否则要使用命令、\nchmod 600 ~/.ssh/authorized_keys 更改属性。 3、authorized_keys存放的目录需要与登录用户对应，比如使用root用户登录，则是在/home/root/.ssh/authorized_keys","title":"配置ssh免密登录"},{"content":"一、gcc编译流程 源文件-\u0026gt;预处理-\u0026gt;编译-\u0026gt;汇编-\u0026gt;链接-\u0026gt;可执行文件\n1.预处理：cpp，宏替换，头文件展开，去掉注释。gcc -E hello.c -o hello.i\n2.编译：将.c文件通过gcc编译成汇编语言文件。gcc -S hello.i -o hello.s\n3.汇编：将汇编文件通过汇编器as变成二进制文件。gcc -c hello.s -o hello.o\n4.链接：将hello.o中所调用的库文件通过链接器ld链接到一起，成可执行文件。gcc hello.o -o hello\n一步到位：gcc hello.c -o hello 或gcc -o hello hello.c\n生成目标文件（.o文件）gcc -c hello.c -o hello.o（不写-o就默认生成hello.o）\n二、库的制作 1.静态库 ​\t将源文件编译成目标文件 gcc -c add.c sub.c div.c mul.c\n​\t将.o文件打包成库 ar rcs libmath.a add.o sub.o div.o mul.o\n​\t使用库文件 gcc -o main main.c -I头文件的路径 -L库的路径 -l库名\n2.动态库 ​\t将源文件编译成目标文件 gcc -fpic -c add.c sub.c div.c mul.c\n​\t将.o文件打包成库gcc -shared add.o sub.o div.o mul.o -o libmath.so\n​\t使用库文件 gcc -o main main.c -I头文件的路径 -L库的路径 -l库名（链接器ld）\n3.加载动态库时报错 ​\t系统加载可执行代码时候, 能够知道其所依赖的库的名字, 但是还需要知道所依赖的库的绝对路径。此时就需要系统动态载入器ldd。\n​\t在~/.bashrc文件中添加你的动态库的路径（配置环境变量LD_LIBRARY_PATH）\n​ export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:库路径\n​\n","permalink":"http://localhost:1313/posts/%E5%88%B6%E4%BD%9Cc%E5%BA%93/","summary":"一、gcc编译流程 源文件-\u0026gt;预处理-\u0026gt;编译-\u0026gt;汇编-\u0026gt;链接-\u0026gt;可执行文件\n1.预处理：cpp，宏替换，头文件展开，去掉注释。gcc -E hello.c -o hello.i\n2.编译：将.c文件通过gcc编译成汇编语言文件。gcc -S hello.i -o hello.s\n3.汇编：将汇编文件通过汇编器as变成二进制文件。gcc -c hello.s -o hello.o\n4.链接：将hello.o中所调用的库文件通过链接器ld链接到一起，成可执行文件。gcc hello.o -o hello\n一步到位：gcc hello.c -o hello 或gcc -o hello hello.c\n生成目标文件（.o文件）gcc -c hello.c -o hello.o（不写-o就默认生成hello.o）\n二、库的制作 1.静态库 ​\t将源文件编译成目标文件 gcc -c add.c sub.c div.c mul.c\n​\t将.o文件打包成库 ar rcs libmath.a add.o sub.o div.o mul.o\n​\t使用库文件 gcc -o main main.c -I头文件的路径 -L库的路径 -l库名\n2.动态库 ​\t将源文件编译成目标文件 gcc -fpic -c add.c sub.c div.","title":"gcc和c库的制作"},{"content":"一、目录 1./bin：可执行二进制文件的目录，绿色是可执行文件，\n输入命名./date，date可执行文件执行。cat命令，查看文本文件内容，ctrl+c退出。\n2./boot：linux启动时用到的文件。reboot：重启。\n3./dev：存放设备文件，一切皆文件。\nsudo cat mice鼠标移动，输出。\nsudo临时获得一次管理员权限，cat是查看文件，mice是鼠标文件。\n4./etc：os相关的一些配置文件。cat passwd查看密码。\n5./home：用户的家目录会存在这。Linux系统支持多用户访问。~表示当前用户的家目录。\n6./lib：系统使用的函数库的目录。\n7./root：系统管理员的家目录。普通用户的家目录：/home/cookie。\n切换成管理员账户，sudu su。退出 exit。\n切换普通用户：su 用户名。退出 exit。\ncookie（用户名）@（at在）主机名：当前工作目录$(普通用户)#（管理员）\ncd空格 回车：回到当前用户的“家”目录，宿主目录，这个用户的所有数据。不是home。\ncd空格 - 回到上次工作目录。\n8./tmp：一般用户或正在执行的程序临时存放文件的目录。\n9./usr：unix system resource，应用程序存放目录。\n二、文件类型 linux下不以后缀名区分文件类型。ls -l 查看文件详细信息。\n普通文件-\n目录文件d\n套接字文件s\n软链接文件l\n字符设备文件c\n块设备文件b\n管道文件p\n第一个为文件类型，后面9个，三个一组，r可读，w可写，x可执行。分别为文件所有者权限，所属组权限，其他人的权限。数字2代表硬链接计数。第一个cookie为文件所有者，第二个是所属组。文件所占用的空间大小（byte），最后一次修改时间，文件名。\ngedit 文件名：用记事本编辑文件。\n三、命令 命令格式：命令 -可选 参数\n查看帮助文档：ls \u0026ndash;help；man 1 xxx：1是标准命令，2是系统调用，3是库函数\nctrl+p/n 上/下一条命令\nctrl+u 清空\nctrl+b 光标向前移动一个字符\nctrl+a 光标移动到最前\nctrl+e 光标移动到最后\n通配符：ls std*.h ls std??.h *代表一堆，？代表一个字符。\n输出重定向：\u0026gt;\n追加\u0026raquo;\n删除：rm -f强制删 ；rm -r 递归删（无敌），删目录时必须用这个。\n建立链接文件ln\n查看或合并文件内容：cat，合并要借助重定向。\n拷贝文件：cp 文件名 目录/新名字\n拷贝目录，cp -a保留原有文件格式，创建时间没变；cp -r递归的拷贝，重新创建新的。\n移动文件：mv（移动文件和改名作用） mv 文件名 目录（目录不存在则把文件名改为目录的名字）\nfile：查看文件类型。\n归档管理（压缩打包）：tar zcvf（gzip格式压缩） xxx.tar.gz（压缩包名） yyy1 yyy2 yyy3（yyy为打包材料）\ntar.gz可以不加，但不直观。 z是gzip方式压缩，c是创建，v是展示压缩列表啥东西被打包了，f是指定压缩文件名。\ntar jcvf（bzip2格式压缩） xxx.tar.bz2（压缩包名） yyy1 yyy2 yyy3（yyy为打包材料）\n解压：tar z(j)xvf 压缩包名\n查看命令位置：which ls\n修改文件权限：r：4 w：2 x：1\n7==rwx 5==w-x\nchmod 755 file1\n修改目录里面的所有文件的权限\nchmod 777 dir -R：将dir里面的文件权限全部改为rwx\n查看进程：ps aux\n杀掉经常：kill -9 进程id\n四、vim ","permalink":"http://localhost:1313/posts/linux%E5%85%A5%E9%97%A8/","summary":"一、目录 1./bin：可执行二进制文件的目录，绿色是可执行文件，\n输入命名./date，date可执行文件执行。cat命令，查看文本文件内容，ctrl+c退出。\n2./boot：linux启动时用到的文件。reboot：重启。\n3./dev：存放设备文件，一切皆文件。\nsudo cat mice鼠标移动，输出。\nsudo临时获得一次管理员权限，cat是查看文件，mice是鼠标文件。\n4./etc：os相关的一些配置文件。cat passwd查看密码。\n5./home：用户的家目录会存在这。Linux系统支持多用户访问。~表示当前用户的家目录。\n6./lib：系统使用的函数库的目录。\n7./root：系统管理员的家目录。普通用户的家目录：/home/cookie。\n切换成管理员账户，sudu su。退出 exit。\n切换普通用户：su 用户名。退出 exit。\ncookie（用户名）@（at在）主机名：当前工作目录$(普通用户)#（管理员）\ncd空格 回车：回到当前用户的“家”目录，宿主目录，这个用户的所有数据。不是home。\ncd空格 - 回到上次工作目录。\n8./tmp：一般用户或正在执行的程序临时存放文件的目录。\n9./usr：unix system resource，应用程序存放目录。\n二、文件类型 linux下不以后缀名区分文件类型。ls -l 查看文件详细信息。\n普通文件-\n目录文件d\n套接字文件s\n软链接文件l\n字符设备文件c\n块设备文件b\n管道文件p\n第一个为文件类型，后面9个，三个一组，r可读，w可写，x可执行。分别为文件所有者权限，所属组权限，其他人的权限。数字2代表硬链接计数。第一个cookie为文件所有者，第二个是所属组。文件所占用的空间大小（byte），最后一次修改时间，文件名。\ngedit 文件名：用记事本编辑文件。\n三、命令 命令格式：命令 -可选 参数\n查看帮助文档：ls \u0026ndash;help；man 1 xxx：1是标准命令，2是系统调用，3是库函数\nctrl+p/n 上/下一条命令\nctrl+u 清空\nctrl+b 光标向前移动一个字符\nctrl+a 光标移动到最前\nctrl+e 光标移动到最后\n通配符：ls std*.h ls std??.h *代表一堆，？代表一个字符。\n输出重定向：\u0026gt;\n追加\u0026raquo;\n删除：rm -f强制删 ；rm -r 递归删（无敌），删目录时必须用这个。","title":"linux基础知识"},{"content":"1.::作用域运算符 可用::对被屏蔽的同名的全局变量进行访问\n后面有::的名称一定是类名或命名空间名。直接::代表全局作用域下\n通常情况下，如果有两个同名变量，一个是全局变量，另一个是局部变量，那么局部变量在其作用域内具有较高的优先权，它将屏蔽全局变量（就近原则）。\n//全局变量 int a = 10; void test(){ //局部变量 int a = 20; //全局a被隐藏 cout \u0026lt;\u0026lt; \u0026#34;a:\u0026#34; \u0026lt;\u0026lt; a \u0026lt;\u0026lt; endl; } 程序的输出结果是a:20。在test函数的输出语句中，使用的变量a是test函数内定义的局部变量，因此输出的结果为局部变量a的值。\n作用域运算符可以用来解决局部变量与全局变量的重名问题\n//全局变量 int a = 10; //1. 局部变量和全局变量同名 void test(){ int a = 20; //打印局部变量a cout \u0026lt;\u0026lt; \u0026#34;局部变量a:\u0026#34; \u0026lt;\u0026lt; a \u0026lt;\u0026lt; endl; //打印全局变量a cout \u0026lt;\u0026lt; \u0026#34;全局变量a:\u0026#34; \u0026lt;\u0026lt; ::a \u0026lt;\u0026lt; endl; } 这个例子可以看出，作用域运算符可以用来解决局部变量与全局变量的重名问题，即在局部变量的作用域内，可用::对被屏蔽的同名的全局变量进行访问。\n2.namespace 1.命名空间用途：解决名称冲突\n在game1和game2中都有相同名称的goAtk函数，如果不使用命名空间，会有二义性，编译报错。\n#include \u0026lt;iostream\u0026gt; using namespace std; #include \u0026#34;game1.h\u0026#34; #include \u0026#34;game2.h\u0026#34; void test01(){ LOL::goAtk(); KingGlory::goAtk(); } int main() { test01(); system(\u0026#34;pause\u0026#34;); return 0; } game1.h中\n#pragma once #include \u0026lt;iostream\u0026gt; using namespace std; //lol namespace LOL { void goAtk(); } game1.cpp中\n#include \u0026#34;game1.h\u0026#34; void LOL::goAtk() { cout \u0026lt;\u0026lt; \u0026#34;lol的攻击函数\u0026#34; \u0026lt;\u0026lt; endl; } game2.h中\n//王者荣耀 namespace KingGlory { void goAtk(); } 运行结果：\n2.命名空间下可以存放：变量，函数，结构体，类。\n3.命名空间必须声明在全局的作用域下。\n4.命名空间可以嵌套命名空间。\n5.命名空间是开放的，可以随时添加新的成员。\n6.命名空间可以是匿名的\n7.命名空间可以取别名\n//2.命名空间下可以存放：变量，函数，结构体，类 namespace A { int m_A = 10; void func(); struct Person{}; class Animal{}; } //3.命名空间必须声明在全局的作用域下。在局部中定义会报错:不允许进行命名空间定义 void test02() { /*namespace b { };*/ } //4.命名空间可以嵌套命名空间。 namespace B { int m_A = 20; namespace C { int m_A = 30; } } void test03() { cout \u0026lt;\u0026lt; \u0026#34;B命名空间下的m_A = \u0026#34; \u0026lt;\u0026lt; B::m_A \u0026lt;\u0026lt; endl;//20 cout \u0026lt;\u0026lt; \u0026#34;C命名空间下的m_A = \u0026#34; \u0026lt;\u0026lt; B::C::m_A \u0026lt;\u0026lt; endl;//30 } //5.命名空间是开放的，可以随时添加新的成员。 namespace B { int m_B = 40; }//这段代码不会与上面的B冲突，而是合二为一 void test04() { cout \u0026lt;\u0026lt; \u0026#34;B命名空间下的m_A = \u0026#34; \u0026lt;\u0026lt; B::m_A \u0026lt;\u0026lt; endl;//20 cout \u0026lt;\u0026lt; \u0026#34;B命名空间下的m_B = \u0026#34; \u0026lt;\u0026lt; B::m_B \u0026lt;\u0026lt; endl;//40 } //6.命名空间可以是匿名的 namespace { int m_C = 50; int m_D = 50; } void test05() { cout \u0026lt;\u0026lt; \u0026#34;m_C = \u0026#34; \u0026lt;\u0026lt; m_C \u0026lt;\u0026lt; endl;//50 cout \u0026lt;\u0026lt; \u0026#34;m_D = \u0026#34; \u0026lt;\u0026lt; ::m_D \u0026lt;\u0026lt; endl;//50 } //7.命名空间可以取别名 namespace veryLongName { int m_A = 100; } void test06() { namespace veryShortName = veryLongName; cout \u0026lt;\u0026lt; veryLongName::m_A \u0026lt;\u0026lt; endl;//100 cout \u0026lt;\u0026lt; veryShortName::m_A \u0026lt;\u0026lt; endl;//100 } 3.using声明和using编译指令 在开发中通常不自己写命名空间\n#include \u0026lt;iostream\u0026gt; using namespace std; namespace LOL { int sunWuKongId = 1; } namespace KingGlory { int sunWuKongId = 3; } void test01() { //int sunWuKongId = 2; //1.using声明 //注意：using声明和就近原则不要同时出现，尽量避免 //using声明导致“LOL::sunWuKongId”的多次声明 using LOL::sunWuKongId;//告诉编译器使用的是sunWuKongId是LOL里的。 cout \u0026lt;\u0026lt; sunWuKongId \u0026lt;\u0026lt; endl; } void test02() { //int sunWuKongId = 2; //2.using编译指令 //注意：using编译指令和就近原则同时出现，优先使用就近原则 //当使用多个using编译指令，并且出现同名情况，使用数据依然加作用域,不加则不明确 using namespace LOL; using namespace KingGlory; cout \u0026lt;\u0026lt; LOL::sunWuKongId \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; KingGlory::sunWuKongId \u0026lt;\u0026lt; endl; } int main() { test02(); system(\u0026#34;pause\u0026#34;); return 0; } 报错：无法解析的外部命令。是在链接阶段出错了.\n4.函数重载原理 编译器为了实现函数重载，也是默认为我们做了一些幕后的工作，编译器用不同的参数类型来修饰不同的函数名，比如void func();编译器可能将函数名修饰成_func,当编译器碰到void func(int x)，编译器可能将函数名修饰为__func_int;当编译器碰到void func(int x,char c)；编译器可能会将函数名修饰为_func_int_char;我这里使用”可能”这个字眼是因为编译器如何修饰重载的函数名称并没有一个统一的标准，所以不同的编译器可能会产生不同的内部名。\nvoid func(){} void func(int x){} void func(int x,char y){} 以上三个函数在linux下生成的编译之后的函数名为:\n_Z4funcv //v 代表void,无参数\n_Z4funci //i 代表参数为int类型\n_Z4funcic //i 代表第一个参数为int类型，第二个参数为char类型\n5.extern “C”浅析 主要用途：c++中调用c语言的文件\n以下在Linux下测试:\nc函数: void MyFunc(){} ,被编译成函数: MyFunc c++函数: void MyFunc(){},被编译成函数: _Z6Myfuncv 通过这个测试，由于c++中需要支持函数重载，所以c和c++中对同一个函数经过编译后生成的函数名是不相同的，这就导致了一个问题，如果在c++中调用一个使用c语言编写模块中的某个函数，那么c++是根据c++的名称修饰方式来查找并链接这个函数，那么就会发生链接错误，以上例，在c++中调用MyFunc函数，在链接阶段会去找Z6Myfuncv，结果是没有找到的，因为这个MyFunc函数是c语言编写的，生成的符号是MyFunc。\n那么如果我想在c++调用c的函数怎么办？\nextern \u0026ldquo;C\u0026quot;的主要作用就是为了实现c++代码能够调用其他c语言代码。加上extern \u0026ldquo;C\u0026quot;后，这部分代码编译器按c语言的方式进行编译和链接，而不是按c++的方式。\n#ifdef __cplusplus//如果c++编译器在编译这个文件的时候，会有__cplusplus宏，就会将下面代码用c方式链接 extern \u0026#34;C\u0026#34; {//告诉编译器，这个{}中的代码都用c语言的方式来链接 #endif #include \u0026lt;stdio.h\u0026gt; void show(); #ifdef __cplusplus } #endif #include \u0026#34;test.h\u0026#34; void show() { printf(\u0026#34;hello world\\n\u0026#34;); } #include \u0026lt;iostream\u0026gt; using namespace std; #include \u0026#34;test.h\u0026#34; //解决方法1. //告诉编译器 利用c语言的方式链接show函数，这种方式就不用包含头文件了,适合一个函数的情况 //extern \u0026#34;C\u0026#34; void show(); //解决方法2：在.h中添加6行代码 void test01() { show();//show函数是在c语言编写的模块中，编译器如果按照c++的方式去找show， //可能将函数名称修饰为_Z4showv的形式，再去调用。在编译时用c++得方式去链接这个函数 //找的其实是_Z4showv这个名称，找不到这个函数的实现体。 } int main() { test01(); system(\u0026#34;pause\u0026#34;); return 0; } ","permalink":"http://localhost:1313/posts/namespace%E5%91%BD%E5%90%8D%E7%A9%BA%E9%97%B4/","summary":"1.::作用域运算符 可用::对被屏蔽的同名的全局变量进行访问\n后面有::的名称一定是类名或命名空间名。直接::代表全局作用域下\n通常情况下，如果有两个同名变量，一个是全局变量，另一个是局部变量，那么局部变量在其作用域内具有较高的优先权，它将屏蔽全局变量（就近原则）。\n//全局变量 int a = 10; void test(){ //局部变量 int a = 20; //全局a被隐藏 cout \u0026lt;\u0026lt; \u0026#34;a:\u0026#34; \u0026lt;\u0026lt; a \u0026lt;\u0026lt; endl; } 程序的输出结果是a:20。在test函数的输出语句中，使用的变量a是test函数内定义的局部变量，因此输出的结果为局部变量a的值。\n作用域运算符可以用来解决局部变量与全局变量的重名问题\n//全局变量 int a = 10; //1. 局部变量和全局变量同名 void test(){ int a = 20; //打印局部变量a cout \u0026lt;\u0026lt; \u0026#34;局部变量a:\u0026#34; \u0026lt;\u0026lt; a \u0026lt;\u0026lt; endl; //打印全局变量a cout \u0026lt;\u0026lt; \u0026#34;全局变量a:\u0026#34; \u0026lt;\u0026lt; ::a \u0026lt;\u0026lt; endl; } 这个例子可以看出，作用域运算符可以用来解决局部变量与全局变量的重名问题，即在局部变量的作用域内，可用::对被屏蔽的同名的全局变量进行访问。\n2.namespace 1.命名空间用途：解决名称冲突\n在game1和game2中都有相同名称的goAtk函数，如果不使用命名空间，会有二义性，编译报错。\n#include \u0026lt;iostream\u0026gt; using namespace std; #include \u0026#34;game1.h\u0026#34; #include \u0026#34;game2.h\u0026#34; void test01(){ LOL::goAtk(); KingGlory::goAtk(); } int main() { test01(); system(\u0026#34;pause\u0026#34;); return 0; } game1.","title":"namespace，using，重载，extern c"},{"content":"First time here, just a test. 测试。\n","permalink":"http://localhost:1313/posts/hugo-test/","summary":"First time here, just a test. 测试。","title":"Hugo Test"}]